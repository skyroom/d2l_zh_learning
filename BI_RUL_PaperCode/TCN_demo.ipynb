{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db88bd91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T02:55:22.004123Z",
     "start_time": "2023-12-18T02:55:21.722121Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib_inline import backend_inline\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from pytorch_tcn.tcn import TCN\n",
    "\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "# device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba32c85",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81dc654c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T02:55:29.809751Z",
     "start_time": "2023-12-18T02:55:27.007961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Dataset B0005.mat ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coyle\\AppData\\Local\\Temp\\ipykernel_15284\\3199085973.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  d1['type'], d1['temp'], d1['time'], d1['data'] = str(col[i][0][0]), int(col[i][1][0]), str(convert_to_time(col[i][2][0])), d2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Dataset B0006.mat ...\n",
      "Load Dataset B0007.mat ...\n",
      "Load Dataset B0018.mat ...\n"
     ]
    }
   ],
   "source": [
    "# convert str to datatime\n",
    "# 将字符串转换为时间\n",
    "def convert_to_time(hmm):\n",
    "    year, month, day, hour, minute, second = int(hmm[0]), int(hmm[1]), int(hmm[2]), int(hmm[3]), int(hmm[4]), int(hmm[5])\n",
    "    return datetime(year=year, month=month, day=day, hour=hour, minute=minute, second=second)\n",
    "\n",
    "\n",
    "# load .mat data\n",
    "# 加载.mat格式的数据\n",
    "def loadMat(matfile):\n",
    "    data_mat = scipy.io.loadmat(matfile)\n",
    "    filename = matfile.split(\"/\")[-1].split(\".\")[0]\n",
    "    col = data_mat[filename]\n",
    "    col = col[0][0][0][0]\n",
    "    size = col.shape[0]\n",
    "\n",
    "    data_mat = []\n",
    "    for i in range(size):\n",
    "        k = list(col[i][3][0].dtype.fields.keys())\n",
    "        d1, d2 = {}, {}\n",
    "        if str(col[i][0][0]) != 'impedance':\n",
    "            for j in range(len(k)):\n",
    "                t = col[i][3][0][0][j][0];\n",
    "                l = [t[m] for m in range(len(t))]\n",
    "                d2[k[j]] = l\n",
    "        d1['type'], d1['temp'], d1['time'], d1['data'] = str(col[i][0][0]), int(col[i][1][0]), str(convert_to_time(col[i][2][0])), d2\n",
    "        data_mat.append(d1)\n",
    "\n",
    "    return data_mat\n",
    "\n",
    "# get capacity data\n",
    "# 得到电池容量的数据\n",
    "def getBatteryCapacity(Battery):\n",
    "    cycle, capacity = [], []\n",
    "    i = 1\n",
    "    for Bat in Battery:\n",
    "        if Bat['type'] == 'discharge':\n",
    "            capacity.append(Bat['data']['Capacity'][0])\n",
    "            cycle.append(i)\n",
    "            i += 1\n",
    "    return [cycle, capacity]\n",
    "\n",
    "Battery_list = ['B0005', 'B0006', 'B0007', 'B0018']\n",
    "dir_path = './datasets/NASA/'\n",
    "\n",
    "Battery = {}\n",
    "for name in Battery_list:\n",
    "    print('Load Dataset ' + name + '.mat ...')\n",
    "    path = dir_path + name + '.mat'\n",
    "    data_mat = loadMat(path)\n",
    "    Battery[name] = getBatteryCapacity(data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f428a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T02:55:31.710693Z",
     "start_time": "2023-12-18T02:55:31.695762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 168)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Battery['B0006'][0]), len(Battery['B0006'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd08b17",
   "metadata": {},
   "source": [
    "## 画出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90eb42aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T02:55:35.930651Z",
     "start_time": "2023-12-18T02:55:34.488439Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"607.764796pt\" height=\"264.386563pt\" viewBox=\"0 0 607.764796 264.386563\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-12-18T10:55:35.860609</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 264.386563 \n",
       "L 607.764796 264.386563 \n",
       "L 607.764796 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 42.41875 228.96 \n",
       "L 600.41875 228.96 \n",
       "L 600.41875 7.2 \n",
       "L 42.41875 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mab8a4ba277\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"67.782386\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(65.282386 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-30\" d=\"M 2975 2250 \n",
       "Q 2975 1350 2650 700 \n",
       "Q 2325 50 1600 50 \n",
       "Q 875 50 537 700 \n",
       "Q 200 1350 200 2250 \n",
       "Q 200 3150 537 3787 \n",
       "Q 875 4425 1600 4425 \n",
       "Q 2325 4425 2650 3787 \n",
       "Q 2975 3150 2975 2250 \n",
       "z\n",
       "M 2375 2250 \n",
       "Q 2375 3050 2187 3500 \n",
       "Q 2000 3950 1600 3950 \n",
       "Q 1200 3950 1000 3500 \n",
       "Q 800 3050 800 2250 \n",
       "Q 800 1450 1000 987 \n",
       "Q 1200 525 1600 525 \n",
       "Q 2000 525 2187 987 \n",
       "Q 2375 1450 2375 2250 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"142.822731\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(137.822731 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-32\" d=\"M 2850 100 \n",
       "L 300 100 \n",
       "L 300 500 \n",
       "Q 450 900 712 1237 \n",
       "Q 975 1575 1475 2000 \n",
       "Q 1850 2325 2012 2600 \n",
       "Q 2175 2875 2175 3200 \n",
       "Q 2175 3525 2037 3737 \n",
       "Q 1900 3950 1600 3950 \n",
       "Q 1350 3950 1162 3725 \n",
       "Q 975 3500 975 2925 \n",
       "L 400 2925 \n",
       "Q 425 3650 737 4037 \n",
       "Q 1050 4425 1625 4425 \n",
       "Q 2175 4425 2475 4087 \n",
       "Q 2775 3750 2775 3175 \n",
       "Q 2775 2700 2500 2350 \n",
       "Q 2225 2000 1825 1650 \n",
       "Q 1375 1250 1200 1050 \n",
       "Q 1025 850 875 575 \n",
       "L 2850 575 \n",
       "L 2850 100 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"SimHei-35\" d=\"M 2825 1650 \n",
       "Q 2825 900 2462 475 \n",
       "Q 2100 50 1500 50 \n",
       "Q 975 50 637 400 \n",
       "Q 300 750 275 1350 \n",
       "L 850 1350 \n",
       "Q 850 975 1025 750 \n",
       "Q 1200 525 1525 525 \n",
       "Q 1850 525 2037 800 \n",
       "Q 2225 1075 2225 1650 \n",
       "Q 2225 2150 2062 2387 \n",
       "Q 1900 2625 1625 2625 \n",
       "Q 1400 2625 1237 2525 \n",
       "Q 1075 2425 925 2175 \n",
       "L 425 2175 \n",
       "L 575 4375 \n",
       "L 2725 4375 \n",
       "L 2725 3900 \n",
       "L 1050 3900 \n",
       "L 950 2750 \n",
       "Q 1100 2900 1275 2975 \n",
       "Q 1450 3050 1750 3050 \n",
       "Q 2225 3050 2525 2687 \n",
       "Q 2825 2325 2825 1650 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"217.863075\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(212.863075 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-35\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"292.903419\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 75 -->\n",
       "      <g transform=\"translate(287.903419 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-37\" d=\"M 2775 3850 \n",
       "L 1600 100 \n",
       "L 1025 100 \n",
       "L 2225 3900 \n",
       "L 400 3900 \n",
       "L 400 4375 \n",
       "L 2775 4375 \n",
       "L 2775 3850 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-37\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"367.943763\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(360.443763 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-31\" d=\"M 1950 100 \n",
       "L 1375 100 \n",
       "L 1375 3425 \n",
       "L 625 3425 \n",
       "L 625 3725 \n",
       "Q 1075 3725 1325 3900 \n",
       "Q 1575 4075 1650 4425 \n",
       "L 1950 4425 \n",
       "L 1950 100 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"442.984108\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 125 -->\n",
       "      <g transform=\"translate(435.484108 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-32\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"518.024452\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(510.524452 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mab8a4ba277\" x=\"593.064796\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 175 -->\n",
       "      <g transform=\"translate(585.564796 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-37\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- 循环次数 -->\n",
       "     <g transform=\"translate(301.41875 255.8975)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-5faa\" d=\"M 5500 5100 \n",
       "Q 5675 4750 5850 4550 \n",
       "Q 5375 4525 4625 4425 \n",
       "L 4575 3725 \n",
       "L 5325 3725 \n",
       "Q 5725 3725 6075 3750 \n",
       "L 6075 3350 \n",
       "Q 5725 3375 5325 3375 \n",
       "L 4550 3375 \n",
       "L 4500 2725 \n",
       "L 5675 2725 \n",
       "Q 5650 2300 5650 1162 \n",
       "Q 5650 25 5675 -500 \n",
       "L 5225 -500 \n",
       "L 5225 -100 \n",
       "L 3650 -100 \n",
       "L 3650 -550 \n",
       "L 3200 -550 \n",
       "Q 3225 25 3225 1150 \n",
       "Q 3225 2275 3200 2725 \n",
       "L 4025 2725 \n",
       "L 4075 3375 \n",
       "Q 3450 3375 3050 3350 \n",
       "L 3050 3750 \n",
       "Q 3450 3725 4125 3725 \n",
       "L 4150 4400 \n",
       "Q 3550 4375 2750 4350 \n",
       "Q 2750 2925 2725 2275 \n",
       "Q 2700 1625 2587 950 \n",
       "Q 2475 275 2200 -425 \n",
       "Q 2025 -175 1750 -25 \n",
       "Q 1975 300 2100 800 \n",
       "Q 2225 1300 2275 1812 \n",
       "Q 2325 2325 2325 3275 \n",
       "Q 2325 4225 2300 4750 \n",
       "Q 2950 4725 3887 4800 \n",
       "Q 4825 4875 5500 5100 \n",
       "z\n",
       "M 3650 2375 \n",
       "L 3650 1925 \n",
       "L 5225 1925 \n",
       "L 5225 2375 \n",
       "L 3650 2375 \n",
       "z\n",
       "M 3650 1600 \n",
       "L 3650 1100 \n",
       "L 5225 1100 \n",
       "L 5225 1600 \n",
       "L 3650 1600 \n",
       "z\n",
       "M 3650 775 \n",
       "L 3650 250 \n",
       "L 5225 250 \n",
       "L 5225 775 \n",
       "L 3650 775 \n",
       "z\n",
       "M 1475 5125 \n",
       "Q 1700 4975 1950 4825 \n",
       "Q 1325 3900 650 3200 \n",
       "Q 500 3375 350 3575 \n",
       "Q 925 4100 1475 5125 \n",
       "z\n",
       "M 1650 3750 \n",
       "Q 1875 3625 2150 3500 \n",
       "Q 1900 3200 1500 2550 \n",
       "L 1500 525 \n",
       "Q 1500 0 1525 -550 \n",
       "L 1050 -550 \n",
       "Q 1075 0 1075 525 \n",
       "L 1075 2100 \n",
       "Q 800 1725 600 1500 \n",
       "Q 450 1775 300 1900 \n",
       "Q 750 2300 1050 2737 \n",
       "Q 1350 3175 1650 3750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-73af\" d=\"M 375 4675 \n",
       "Q 700 4650 1000 4650 \n",
       "L 1850 4650 \n",
       "Q 2100 4650 2425 4675 \n",
       "L 2425 4225 \n",
       "Q 2100 4250 1850 4250 \n",
       "L 1675 4250 \n",
       "L 1675 3100 \n",
       "Q 2025 3100 2450 3125 \n",
       "L 2450 2675 \n",
       "Q 2000 2700 1675 2700 \n",
       "L 1675 1350 \n",
       "Q 1925 1400 2325 1525 \n",
       "Q 2275 1275 2275 1075 \n",
       "Q 1750 950 1262 812 \n",
       "Q 775 675 325 500 \n",
       "Q 250 750 150 1025 \n",
       "Q 400 1050 1225 1225 \n",
       "L 1225 2700 \n",
       "Q 825 2700 450 2650 \n",
       "L 450 3125 \n",
       "Q 825 3100 1225 3100 \n",
       "L 1225 4250 \n",
       "L 1025 4250 \n",
       "Q 700 4250 375 4225 \n",
       "L 375 4675 \n",
       "z\n",
       "M 2625 4675 \n",
       "Q 3050 4650 3425 4650 \n",
       "L 5100 4650 \n",
       "Q 5450 4650 5850 4675 \n",
       "L 5850 4225 \n",
       "Q 5450 4250 5100 4250 \n",
       "L 4425 4250 \n",
       "Q 4375 3850 4275 3400 \n",
       "L 4275 375 \n",
       "Q 4275 -175 4300 -575 \n",
       "L 3775 -575 \n",
       "Q 3825 -200 3825 375 \n",
       "L 3825 2300 \n",
       "Q 3500 1625 3100 1075 \n",
       "Q 2700 525 2425 225 \n",
       "Q 2200 425 1950 550 \n",
       "Q 2300 800 2625 1187 \n",
       "Q 2950 1575 3225 2087 \n",
       "Q 3500 2600 3675 3162 \n",
       "Q 3850 3725 3925 4250 \n",
       "L 3425 4250 \n",
       "Q 3050 4250 2625 4225 \n",
       "L 2625 4675 \n",
       "z\n",
       "M 4525 2550 \n",
       "Q 4725 2675 4925 2850 \n",
       "Q 5200 2425 5400 2100 \n",
       "Q 5600 1775 6125 925 \n",
       "Q 5900 825 5650 625 \n",
       "Q 5325 1275 5050 1725 \n",
       "Q 4775 2175 4525 2550 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6b21\" d=\"M 525 4300 \n",
       "Q 725 4425 1000 4550 \n",
       "Q 1150 4300 1350 3950 \n",
       "Q 1550 3600 1750 3250 \n",
       "Q 1475 3125 1250 2975 \n",
       "Q 1100 3275 937 3625 \n",
       "Q 775 3975 525 4300 \n",
       "z\n",
       "M 1475 2225 \n",
       "Q 1650 2075 1950 1925 \n",
       "Q 1800 1700 1512 1150 \n",
       "Q 1225 600 900 -50 \n",
       "Q 675 125 400 300 \n",
       "Q 775 700 1037 1237 \n",
       "Q 1300 1775 1475 2225 \n",
       "z\n",
       "M 3000 5075 \n",
       "Q 3275 4975 3650 4825 \n",
       "Q 3500 4725 3387 4450 \n",
       "Q 3275 4175 3150 3900 \n",
       "L 5800 3900 \n",
       "Q 5725 3700 5600 3337 \n",
       "Q 5475 2975 5325 2450 \n",
       "Q 5050 2525 4775 2575 \n",
       "Q 4875 2800 4950 3025 \n",
       "Q 5025 3250 5100 3500 \n",
       "L 2975 3500 \n",
       "Q 2850 3300 2712 3000 \n",
       "Q 2575 2700 2400 2400 \n",
       "Q 2225 2550 1950 2650 \n",
       "Q 2125 2875 2287 3175 \n",
       "Q 2450 3475 2587 3800 \n",
       "Q 2725 4125 2825 4450 \n",
       "Q 2925 4775 3000 5075 \n",
       "z\n",
       "M 3500 3050 \n",
       "Q 3800 3025 4100 2975 \n",
       "Q 4025 2725 4012 2250 \n",
       "Q 4000 1775 4212 1375 \n",
       "Q 4425 975 4725 700 \n",
       "Q 5025 425 5375 262 \n",
       "Q 5725 100 6000 25 \n",
       "Q 5850 -75 5775 -212 \n",
       "Q 5700 -350 5625 -550 \n",
       "Q 5075 -250 4750 12 \n",
       "Q 4425 275 4237 525 \n",
       "Q 4050 775 3950 1012 \n",
       "Q 3850 1250 3775 1475 \n",
       "Q 3650 1100 3512 812 \n",
       "Q 3375 525 3162 300 \n",
       "Q 2950 75 2675 -137 \n",
       "Q 2400 -350 2025 -600 \n",
       "Q 1850 -325 1600 -150 \n",
       "Q 2225 75 2600 412 \n",
       "Q 2975 750 3175 1100 \n",
       "Q 3375 1450 3437 1787 \n",
       "Q 3500 2125 3512 2362 \n",
       "Q 3525 2600 3500 3050 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6570\" d=\"M 700 4850 \n",
       "Q 950 4925 1100 5025 \n",
       "Q 1300 4700 1475 4375 \n",
       "Q 1250 4275 1075 4175 \n",
       "Q 925 4550 700 4850 \n",
       "z\n",
       "M 2875 5025 \n",
       "Q 3150 4900 3400 4800 \n",
       "Q 3250 4700 3150 4525 \n",
       "Q 3050 4350 2925 4125 \n",
       "Q 2725 4225 2525 4275 \n",
       "Q 2725 4600 2875 5025 \n",
       "z\n",
       "M 2450 3175 \n",
       "Q 2675 3275 2825 3425 \n",
       "Q 3125 3000 3325 2650 \n",
       "Q 3100 2550 2900 2400 \n",
       "Q 2700 2875 2450 3175 \n",
       "z\n",
       "M 525 3950 \n",
       "Q 925 3925 1800 3925 \n",
       "Q 1800 4650 1775 5175 \n",
       "L 2275 5175 \n",
       "Q 2250 4650 2250 3925 \n",
       "Q 3075 3925 3450 3950 \n",
       "L 3450 3500 \n",
       "Q 3075 3525 2250 3525 \n",
       "Q 2250 2950 2275 2525 \n",
       "L 1775 2525 \n",
       "Q 1800 2900 1800 3325 \n",
       "Q 1675 3075 1387 2787 \n",
       "Q 1100 2500 750 2300 \n",
       "Q 650 2525 425 2675 \n",
       "Q 650 2750 987 3000 \n",
       "Q 1325 3250 1475 3525 \n",
       "Q 950 3525 525 3500 \n",
       "L 525 3950 \n",
       "z\n",
       "M 1725 1550 \n",
       "Q 1600 1300 1450 1050 \n",
       "Q 1750 975 2250 850 \n",
       "Q 2425 1075 2575 1550 \n",
       "L 1725 1550 \n",
       "z\n",
       "M 1550 2450 \n",
       "Q 1825 2350 2100 2275 \n",
       "Q 2000 2175 1875 1950 \n",
       "L 2850 1950 \n",
       "L 3125 1950 \n",
       "Q 2975 1300 2700 725 \n",
       "Q 3125 600 3375 525 \n",
       "Q 3175 250 3075 25 \n",
       "Q 2850 175 2400 350 \n",
       "Q 1800 -250 600 -650 \n",
       "Q 500 -400 300 -250 \n",
       "Q 1375 0 2000 525 \n",
       "Q 1300 700 850 825 \n",
       "Q 1000 1025 1250 1550 \n",
       "Q 850 1550 300 1525 \n",
       "L 300 1975 \n",
       "Q 775 1950 1400 1950 \n",
       "Q 1475 2150 1550 2450 \n",
       "z\n",
       "M 4075 5150 \n",
       "Q 4375 5025 4700 4975 \n",
       "Q 4575 4825 4512 4625 \n",
       "Q 4450 4425 4350 4050 \n",
       "L 5475 4050 \n",
       "Q 5700 4050 6050 4075 \n",
       "L 6050 3625 \n",
       "Q 5775 3650 5600 3650 \n",
       "Q 5575 3125 5475 2262 \n",
       "Q 5375 1400 5000 750 \n",
       "Q 5250 400 5575 175 \n",
       "Q 5900 -50 6150 -150 \n",
       "Q 5800 -375 5700 -600 \n",
       "Q 5275 -300 5075 -87 \n",
       "Q 4875 125 4700 375 \n",
       "Q 4400 75 4137 -125 \n",
       "Q 3875 -325 3300 -650 \n",
       "Q 3175 -425 2900 -250 \n",
       "Q 3375 -75 3775 200 \n",
       "Q 4175 475 4450 775 \n",
       "Q 4175 1325 4025 1862 \n",
       "Q 3875 2400 3850 2625 \n",
       "Q 3800 2450 3725 2225 \n",
       "Q 3500 2325 3225 2425 \n",
       "Q 3525 2975 3775 3750 \n",
       "Q 4025 4525 4075 5150 \n",
       "z\n",
       "M 4250 3650 \n",
       "Q 4150 3400 4100 3237 \n",
       "Q 4050 3075 4287 2350 \n",
       "Q 4525 1625 4750 1225 \n",
       "Q 4975 1825 5062 2475 \n",
       "Q 5150 3125 5150 3650 \n",
       "L 4250 3650 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-5faa\"/>\n",
       "      <use xlink:href=\"#SimHei-73af\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-6b21\" x=\"200\"/>\n",
       "      <use xlink:href=\"#SimHei-6570\" x=\"300\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path id=\"ma7d60254ba\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma7d60254ba\" x=\"42.41875\" y=\"208.318433\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1.2 -->\n",
       "      <g transform=\"translate(20.41875 211.736402)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-2e\" d=\"M 1100 100 \n",
       "L 525 100 \n",
       "L 525 650 \n",
       "L 1100 650 \n",
       "L 1100 100 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-32\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma7d60254ba\" x=\"42.41875\" y=\"162.579217\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.4 -->\n",
       "      <g transform=\"translate(20.41875 165.997186)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-34\" d=\"M 2975 1200 \n",
       "L 2450 1200 \n",
       "L 2450 100 \n",
       "L 1875 100 \n",
       "L 1875 1200 \n",
       "L 200 1200 \n",
       "L 200 1675 \n",
       "L 1875 4425 \n",
       "L 2450 4425 \n",
       "L 2450 1675 \n",
       "L 2975 1675 \n",
       "L 2975 1200 \n",
       "z\n",
       "M 1875 1675 \n",
       "L 1875 3525 \n",
       "L 750 1675 \n",
       "L 1875 1675 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-34\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma7d60254ba\" x=\"42.41875\" y=\"116.840001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.6 -->\n",
       "      <g transform=\"translate(20.41875 120.25797)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-36\" d=\"M 2850 1550 \n",
       "Q 2850 850 2550 450 \n",
       "Q 2250 50 1650 50 \n",
       "Q 1050 50 700 550 \n",
       "Q 350 1050 350 2175 \n",
       "Q 350 3200 712 3812 \n",
       "Q 1075 4425 1750 4425 \n",
       "Q 2225 4425 2512 4075 \n",
       "Q 2800 3725 2800 3300 \n",
       "L 2225 3300 \n",
       "Q 2225 3550 2087 3750 \n",
       "Q 1950 3950 1725 3950 \n",
       "Q 1350 3950 1150 3562 \n",
       "Q 950 3175 925 2375 \n",
       "Q 1100 2700 1300 2825 \n",
       "Q 1500 2950 1775 2950 \n",
       "Q 2250 2950 2550 2575 \n",
       "Q 2850 2200 2850 1550 \n",
       "z\n",
       "M 2250 1550 \n",
       "Q 2250 2000 2100 2250 \n",
       "Q 1950 2500 1675 2500 \n",
       "Q 1350 2500 1162 2250 \n",
       "Q 975 2000 975 1650 \n",
       "Q 975 1100 1162 800 \n",
       "Q 1350 500 1675 500 \n",
       "Q 1900 500 2075 725 \n",
       "Q 2250 950 2250 1550 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-36\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma7d60254ba\" x=\"42.41875\" y=\"71.100785\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.8 -->\n",
       "      <g transform=\"translate(20.41875 74.518754)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-38\" d=\"M 2875 1325 \n",
       "Q 2875 700 2525 375 \n",
       "Q 2175 50 1575 50 \n",
       "Q 975 50 625 375 \n",
       "Q 275 700 275 1325 \n",
       "Q 275 1650 475 1912 \n",
       "Q 675 2175 1025 2300 \n",
       "Q 725 2425 562 2650 \n",
       "Q 400 2875 400 3225 \n",
       "Q 400 3775 750 4100 \n",
       "Q 1100 4425 1575 4425 \n",
       "Q 2050 4425 2400 4100 \n",
       "Q 2750 3775 2750 3225 \n",
       "Q 2750 2875 2587 2650 \n",
       "Q 2425 2425 2125 2300 \n",
       "Q 2475 2175 2675 1912 \n",
       "Q 2875 1650 2875 1325 \n",
       "z\n",
       "M 2200 3225 \n",
       "Q 2200 3625 2025 3800 \n",
       "Q 1850 3975 1575 3975 \n",
       "Q 1300 3975 1125 3800 \n",
       "Q 950 3625 950 3225 \n",
       "Q 950 2825 1137 2662 \n",
       "Q 1325 2500 1575 2500 \n",
       "Q 1825 2500 2012 2662 \n",
       "Q 2200 2825 2200 3225 \n",
       "z\n",
       "M 2300 1325 \n",
       "Q 2300 1675 2112 1875 \n",
       "Q 1925 2075 1575 2075 \n",
       "Q 1225 2075 1037 1875 \n",
       "Q 850 1675 850 1325 \n",
       "Q 850 925 1050 712 \n",
       "Q 1250 500 1575 500 \n",
       "Q 1900 500 2100 712 \n",
       "Q 2300 925 2300 1325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-38\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma7d60254ba\" x=\"42.41875\" y=\"25.361569\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(20.41875 28.779537)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- 容量 -->\n",
       "     <g transform=\"translate(15.129688 128.08)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-5bb9\" d=\"M 1125 2475 \n",
       "Q 1000 2725 800 2875 \n",
       "Q 1875 3325 2250 3800 \n",
       "Q 2425 3650 2675 3425 \n",
       "Q 1725 2775 1125 2475 \n",
       "z\n",
       "M 3725 3425 \n",
       "Q 3925 3625 4000 3800 \n",
       "Q 5150 3125 5525 2900 \n",
       "Q 5325 2700 5200 2475 \n",
       "Q 4375 3075 3725 3425 \n",
       "z\n",
       "M 800 3400 \n",
       "Q 825 3675 825 3937 \n",
       "Q 825 4200 800 4425 \n",
       "L 3175 4425 \n",
       "Q 3100 4625 2900 5050 \n",
       "Q 3025 5125 3300 5250 \n",
       "Q 3400 5075 3575 4650 \n",
       "Q 3400 4575 3200 4425 \n",
       "L 5650 4425 \n",
       "Q 5650 4200 5650 3962 \n",
       "Q 5650 3725 5650 3475 \n",
       "L 5225 3475 \n",
       "L 5225 4075 \n",
       "L 1250 4075 \n",
       "L 1250 3400 \n",
       "L 800 3400 \n",
       "z\n",
       "M 3075 3350 \n",
       "Q 3350 3200 3675 3075 \n",
       "L 3425 2750 \n",
       "Q 4050 2175 4700 1875 \n",
       "Q 5350 1575 6100 1525 \n",
       "Q 5875 1325 5775 975 \n",
       "Q 5325 1100 4850 1300 \n",
       "Q 4850 -175 4875 -575 \n",
       "L 4400 -575 \n",
       "L 4400 -200 \n",
       "L 2050 -200 \n",
       "L 2050 -650 \n",
       "L 1575 -650 \n",
       "Q 1600 -300 1600 1300 \n",
       "Q 1100 975 550 700 \n",
       "Q 500 1000 225 1250 \n",
       "Q 1425 1675 2137 2250 \n",
       "Q 2850 2825 3075 3350 \n",
       "z\n",
       "M 3150 2525 \n",
       "Q 2550 1875 1750 1425 \n",
       "L 4600 1425 \n",
       "Q 3900 1650 3150 2525 \n",
       "z\n",
       "M 2050 1050 \n",
       "L 2050 175 \n",
       "L 4400 175 \n",
       "L 4400 1050 \n",
       "L 2050 1050 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-91cf\" d=\"M 3450 2175 \n",
       "L 3450 1800 \n",
       "L 4750 1800 \n",
       "L 4750 2175 \n",
       "L 3450 2175 \n",
       "z\n",
       "M 3450 1525 \n",
       "L 3450 1175 \n",
       "L 4750 1175 \n",
       "L 4750 1525 \n",
       "L 3450 1525 \n",
       "z\n",
       "M 1675 2175 \n",
       "L 1675 1800 \n",
       "L 3000 1800 \n",
       "L 3000 2175 \n",
       "L 1675 2175 \n",
       "z\n",
       "M 1675 1525 \n",
       "L 1675 1175 \n",
       "L 3000 1175 \n",
       "L 3000 1525 \n",
       "L 1675 1525 \n",
       "z\n",
       "M 1200 2450 \n",
       "L 5250 2450 \n",
       "Q 5200 2150 5200 1737 \n",
       "Q 5200 1325 5250 900 \n",
       "L 3450 900 \n",
       "L 3450 500 \n",
       "L 4600 500 \n",
       "Q 5000 525 5375 525 \n",
       "L 5375 175 \n",
       "Q 5000 225 4600 225 \n",
       "L 3450 225 \n",
       "L 3450 -225 \n",
       "L 5125 -225 \n",
       "Q 5550 -200 5950 -200 \n",
       "L 5950 -525 \n",
       "Q 5550 -500 5125 -500 \n",
       "L 1300 -500 \n",
       "Q 900 -500 475 -525 \n",
       "L 475 -200 \n",
       "Q 925 -200 1300 -225 \n",
       "L 3000 -225 \n",
       "L 3000 225 \n",
       "L 1750 225 \n",
       "Q 1375 225 1000 175 \n",
       "L 1000 525 \n",
       "Q 1400 525 1750 500 \n",
       "L 3000 500 \n",
       "L 3000 900 \n",
       "L 1200 900 \n",
       "Q 1225 1300 1225 1712 \n",
       "Q 1225 2125 1200 2450 \n",
       "z\n",
       "M 1675 4775 \n",
       "L 1675 4350 \n",
       "L 4750 4350 \n",
       "L 4750 4775 \n",
       "L 1675 4775 \n",
       "z\n",
       "M 1675 4075 \n",
       "L 1675 3675 \n",
       "L 4750 3675 \n",
       "L 4750 4075 \n",
       "L 1675 4075 \n",
       "z\n",
       "M 1200 5050 \n",
       "L 5250 5050 \n",
       "Q 5200 4650 5200 4300 \n",
       "Q 5200 3950 5250 3400 \n",
       "L 1200 3400 \n",
       "Q 1225 3950 1212 4300 \n",
       "Q 1200 4650 1200 5050 \n",
       "z\n",
       "M 475 3150 \n",
       "Q 1100 3125 1750 3100 \n",
       "L 4825 3100 \n",
       "Q 5400 3125 5900 3150 \n",
       "L 5900 2800 \n",
       "Q 5400 2825 4850 2825 \n",
       "L 1750 2825 \n",
       "Q 1100 2825 475 2800 \n",
       "L 475 3150 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-5bb9\"/>\n",
       "      <use xlink:href=\"#SimHei-91cf\" x=\"100\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 67.782386 58.182333 \n",
       "L 70.784 60.505924 \n",
       "L 73.785614 63.016563 \n",
       "L 76.787228 63.036383 \n",
       "L 79.788841 63.177493 \n",
       "L 82.790455 62.945103 \n",
       "L 85.792069 63.063 \n",
       "L 88.793683 65.210308 \n",
       "L 91.795297 65.435102 \n",
       "L 97.798524 65.47039 \n",
       "L 100.800138 67.852858 \n",
       "L 106.803365 68.026997 \n",
       "L 109.804979 70.506632 \n",
       "L 112.806593 70.618945 \n",
       "L 118.80982 70.399073 \n",
       "L 121.811434 70.465553 \n",
       "L 124.813048 60.346124 \n",
       "L 127.814662 60.256632 \n",
       "L 130.816276 62.82715 \n",
       "L 133.817889 65.204829 \n",
       "L 136.819503 65.357393 \n",
       "L 139.821117 65.250395 \n",
       "L 142.822731 67.891921 \n",
       "L 145.824344 67.723128 \n",
       "L 148.825958 67.90604 \n",
       "L 151.827572 70.468288 \n",
       "L 154.829186 70.168382 \n",
       "L 157.830799 59.253744 \n",
       "L 160.832413 64.078936 \n",
       "L 166.835641 68.97209 \n",
       "L 169.837255 70.046518 \n",
       "L 172.838868 71.243248 \n",
       "L 175.840482 73.743772 \n",
       "L 178.842096 75.006217 \n",
       "L 181.84371 77.267868 \n",
       "L 184.845323 77.266945 \n",
       "L 190.848551 79.71918 \n",
       "L 193.850165 78.506583 \n",
       "L 196.851779 79.638385 \n",
       "L 199.853392 82.139833 \n",
       "L 202.855006 84.399552 \n",
       "L 205.85662 85.716442 \n",
       "L 208.858234 72.558948 \n",
       "L 211.859847 74.945389 \n",
       "L 214.861461 78.564463 \n",
       "L 220.864689 83.251266 \n",
       "L 226.867916 85.640709 \n",
       "L 232.871144 90.355499 \n",
       "L 235.872758 91.561457 \n",
       "L 238.874371 92.5949 \n",
       "L 244.877599 95.209958 \n",
       "L 247.879213 97.423039 \n",
       "L 250.880826 99.808053 \n",
       "L 253.88244 99.786306 \n",
       "L 256.884054 102.268316 \n",
       "L 262.887281 104.523789 \n",
       "L 265.888895 107.085248 \n",
       "L 274.893737 110.493023 \n",
       "L 277.89535 111.779989 \n",
       "L 280.896964 114.249867 \n",
       "L 286.900192 116.493704 \n",
       "L 289.901805 119.04252 \n",
       "L 292.903419 120.090002 \n",
       "L 295.905033 120.283462 \n",
       "L 298.906647 117.863098 \n",
       "L 301.90826 122.619111 \n",
       "L 304.909874 124.866777 \n",
       "L 307.911488 126.041371 \n",
       "L 310.913102 126.106408 \n",
       "L 313.914716 127.202368 \n",
       "L 316.916329 128.532292 \n",
       "L 322.919557 133.325728 \n",
       "L 325.921171 133.185993 \n",
       "L 328.922784 134.530255 \n",
       "L 331.924398 135.710631 \n",
       "L 334.926012 115.509242 \n",
       "L 337.927626 125.10756 \n",
       "L 343.930853 132.305445 \n",
       "L 346.932467 133.545603 \n",
       "L 349.934081 135.831541 \n",
       "L 358.938922 139.356193 \n",
       "L 361.940536 141.803458 \n",
       "L 367.943763 144.188924 \n",
       "L 370.945377 145.379079 \n",
       "L 376.948605 140.603392 \n",
       "L 379.950219 144.100438 \n",
       "L 382.951832 146.626676 \n",
       "L 385.953446 150.252218 \n",
       "L 388.95506 150.196192 \n",
       "L 391.956674 149.995501 \n",
       "L 394.958287 151.363467 \n",
       "L 397.959901 153.735325 \n",
       "L 400.961515 154.930378 \n",
       "L 403.963129 154.941708 \n",
       "L 415.969584 159.741275 \n",
       "L 418.971198 159.702497 \n",
       "L 421.972811 160.841499 \n",
       "L 424.974425 154.942587 \n",
       "L 427.976039 153.830445 \n",
       "L 430.977653 158.610261 \n",
       "L 433.979266 160.982538 \n",
       "L 436.98088 162.303918 \n",
       "L 439.982494 163.333726 \n",
       "L 451.988949 168.242552 \n",
       "L 454.990563 169.322824 \n",
       "L 457.992177 169.323795 \n",
       "L 460.99379 170.644068 \n",
       "L 466.997018 165.755459 \n",
       "L 469.998632 169.474403 \n",
       "L 473.000245 170.633254 \n",
       "L 476.001859 173.025586 \n",
       "L 482.005087 172.938253 \n",
       "L 491.009928 176.53165 \n",
       "L 494.011542 176.549226 \n",
       "L 500.014769 178.897956 \n",
       "L 506.017997 181.29361 \n",
       "L 512.021224 181.265279 \n",
       "L 515.022838 179.989296 \n",
       "L 518.024452 171.699233 \n",
       "L 521.026066 176.408312 \n",
       "L 524.02768 178.810085 \n",
       "L 533.032521 182.367115 \n",
       "L 536.034135 182.429565 \n",
       "L 539.035748 183.665912 \n",
       "L 542.037362 184.755209 \n",
       "L 548.04059 184.668962 \n",
       "L 551.042203 185.932042 \n",
       "L 554.043817 185.889407 \n",
       "L 557.045431 186.943671 \n",
       "L 560.047045 188.192402 \n",
       "L 563.048659 188.318384 \n",
       "L 566.050272 183.387047 \n",
       "L 569.051886 179.713281 \n",
       "L 569.051886 179.713281 \n",
       "\" clip-path=\"url(#ped1828c869)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 67.782386 17.28 \n",
       "L 70.784 19.612093 \n",
       "L 73.785614 22.31388 \n",
       "L 76.787228 22.323418 \n",
       "L 79.788841 25.24074 \n",
       "L 82.790455 22.182904 \n",
       "L 85.792069 22.365397 \n",
       "L 88.793683 32.499213 \n",
       "L 91.795297 32.641839 \n",
       "L 94.79691 35.142719 \n",
       "L 97.798524 37.802829 \n",
       "L 103.801752 42.907142 \n",
       "L 115.808207 53.198828 \n",
       "L 118.80982 55.647856 \n",
       "L 121.811434 55.643386 \n",
       "L 124.813048 30.020897 \n",
       "L 127.814662 35.069738 \n",
       "L 130.816276 37.753462 \n",
       "L 133.817889 42.686186 \n",
       "L 136.819503 37.715472 \n",
       "L 139.821117 47.909188 \n",
       "L 142.822731 53.1083 \n",
       "L 145.824344 55.47944 \n",
       "L 148.825958 58.288222 \n",
       "L 151.827572 60.763769 \n",
       "L 154.829186 58.012762 \n",
       "L 157.830799 42.564982 \n",
       "L 160.832413 52.294705 \n",
       "L 163.834027 58.459223 \n",
       "L 166.835641 62.12426 \n",
       "L 169.837255 66.860849 \n",
       "L 172.838868 68.018646 \n",
       "L 178.842096 75.444952 \n",
       "L 184.845323 80.140856 \n",
       "L 187.846937 82.468952 \n",
       "L 190.848551 84.938612 \n",
       "L 193.850165 81.466056 \n",
       "L 196.851779 78.89038 \n",
       "L 199.853392 86.24304 \n",
       "L 202.855006 90.922809 \n",
       "L 205.85662 93.419743 \n",
       "L 208.858234 65.676237 \n",
       "L 211.859847 69.24185 \n",
       "L 214.861461 76.644127 \n",
       "L 217.863075 83.738305 \n",
       "L 220.864689 87.290859 \n",
       "L 223.866302 92.115975 \n",
       "L 226.867916 94.52031 \n",
       "L 229.86953 98.072411 \n",
       "L 235.872758 102.944624 \n",
       "L 238.874371 105.148825 \n",
       "L 244.877599 110.162089 \n",
       "L 247.879213 114.816125 \n",
       "L 250.880826 116.033964 \n",
       "L 253.88244 117.07528 \n",
       "L 256.884054 119.669586 \n",
       "L 259.885668 120.734244 \n",
       "L 262.887281 124.355495 \n",
       "L 265.888895 125.680336 \n",
       "L 271.892123 130.407588 \n",
       "L 274.893737 133.920425 \n",
       "L 277.89535 132.812814 \n",
       "L 280.896964 134.070722 \n",
       "L 283.898578 136.382242 \n",
       "L 289.901805 138.795412 \n",
       "L 292.903419 141.191516 \n",
       "L 295.905033 142.538053 \n",
       "L 298.906647 132.782949 \n",
       "L 301.90826 138.777442 \n",
       "L 304.909874 142.280299 \n",
       "L 307.911488 144.677362 \n",
       "L 310.913102 144.635727 \n",
       "L 316.916329 147.13846 \n",
       "L 319.917943 150.771806 \n",
       "L 322.919557 150.704454 \n",
       "L 325.921171 151.796547 \n",
       "L 328.922784 151.863934 \n",
       "L 331.924398 153.048493 \n",
       "L 334.926012 118.306707 \n",
       "L 337.927626 129.100344 \n",
       "L 340.92924 136.346498 \n",
       "L 346.932467 143.57204 \n",
       "L 352.935695 148.226151 \n",
       "L 355.937308 150.72442 \n",
       "L 361.940536 153.115682 \n",
       "L 364.94215 155.441442 \n",
       "L 370.945377 157.893772 \n",
       "L 373.946991 157.845066 \n",
       "L 376.948605 150.62852 \n",
       "L 379.950219 155.36211 \n",
       "L 382.951832 159.145174 \n",
       "L 388.95506 161.454646 \n",
       "L 391.956674 163.685124 \n",
       "L 394.958287 163.829182 \n",
       "L 400.961515 166.275415 \n",
       "L 403.963129 168.598172 \n",
       "L 406.964742 167.471944 \n",
       "L 409.966356 168.580196 \n",
       "L 412.96797 169.838475 \n",
       "L 421.972811 173.266393 \n",
       "L 424.974425 166.201632 \n",
       "L 427.976039 161.402169 \n",
       "L 430.977653 167.446093 \n",
       "L 436.98088 172.34108 \n",
       "L 442.984108 174.606364 \n",
       "L 445.985721 176.985352 \n",
       "L 451.988949 179.518649 \n",
       "L 454.990563 180.513851 \n",
       "L 457.992177 180.594734 \n",
       "L 460.99379 181.870068 \n",
       "L 463.995404 180.66849 \n",
       "L 466.997018 174.601112 \n",
       "L 469.998632 179.499798 \n",
       "L 473.000245 183.134723 \n",
       "L 479.003473 185.35593 \n",
       "L 482.005087 185.394913 \n",
       "L 488.008314 190.19357 \n",
       "L 491.009928 190.203916 \n",
       "L 494.011542 191.386516 \n",
       "L 497.013156 191.365789 \n",
       "L 500.014769 193.73587 \n",
       "L 503.016383 195.022645 \n",
       "L 506.017997 196.138111 \n",
       "L 509.019611 196.144637 \n",
       "L 512.021224 197.321012 \n",
       "L 515.022838 196.09796 \n",
       "L 518.024452 187.78041 \n",
       "L 521.026066 193.787038 \n",
       "L 527.029293 200.972649 \n",
       "L 533.032521 203.346636 \n",
       "L 536.034135 205.779294 \n",
       "L 539.035748 207.034082 \n",
       "L 542.037362 208.114065 \n",
       "L 545.038976 210.470372 \n",
       "L 554.043817 214.128392 \n",
       "L 557.045431 218.88 \n",
       "L 560.047045 216.459795 \n",
       "L 563.048659 217.741285 \n",
       "L 566.050272 214.041579 \n",
       "L 569.051886 211.594452 \n",
       "L 569.051886 211.594452 \n",
       "\" clip-path=\"url(#ped1828c869)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 67.782386 50.277482 \n",
       "L 70.784 52.659413 \n",
       "L 76.787228 52.628796 \n",
       "L 79.788841 52.930682 \n",
       "L 82.790455 52.644931 \n",
       "L 85.792069 52.819906 \n",
       "L 88.793683 52.460039 \n",
       "L 91.795297 55.162775 \n",
       "L 97.798524 55.081942 \n",
       "L 100.800138 57.458629 \n",
       "L 103.801752 57.590642 \n",
       "L 112.806593 57.668196 \n",
       "L 115.808207 60.165158 \n",
       "L 118.80982 60.003241 \n",
       "L 121.811434 60.036708 \n",
       "L 124.813048 52.626591 \n",
       "L 127.814662 52.468421 \n",
       "L 130.816276 52.554577 \n",
       "L 133.817889 54.861313 \n",
       "L 136.819503 55.046431 \n",
       "L 139.821117 54.938481 \n",
       "L 142.822731 57.467648 \n",
       "L 145.824344 57.371265 \n",
       "L 148.825958 57.56991 \n",
       "L 151.827572 60.091397 \n",
       "L 154.829186 59.848548 \n",
       "L 157.830799 52.012039 \n",
       "L 160.832413 56.733843 \n",
       "L 163.834027 59.18914 \n",
       "L 166.835641 60.363397 \n",
       "L 169.837255 62.678267 \n",
       "L 172.838868 62.60199 \n",
       "L 175.840482 63.857463 \n",
       "L 178.842096 66.264527 \n",
       "L 184.845323 68.497867 \n",
       "L 187.846937 68.446622 \n",
       "L 190.848551 69.716054 \n",
       "L 193.850165 68.08104 \n",
       "L 196.851779 69.668188 \n",
       "L 202.855006 74.328771 \n",
       "L 205.85662 75.599955 \n",
       "L 208.858234 67.653034 \n",
       "L 211.859847 67.509681 \n",
       "L 214.861461 71.045162 \n",
       "L 220.864689 75.596256 \n",
       "L 226.867916 77.901526 \n",
       "L 232.871144 82.616183 \n",
       "L 235.872758 82.615615 \n",
       "L 238.874371 83.672497 \n",
       "L 241.875985 84.903566 \n",
       "L 244.877599 87.437866 \n",
       "L 247.879213 88.504482 \n",
       "L 250.880826 90.773478 \n",
       "L 253.88244 90.775463 \n",
       "L 256.884054 93.135168 \n",
       "L 259.885668 93.052465 \n",
       "L 262.887281 95.440539 \n",
       "L 265.888895 96.79302 \n",
       "L 268.890509 97.841203 \n",
       "L 289.901805 106.041552 \n",
       "L 292.903419 108.512335 \n",
       "L 295.905033 108.548526 \n",
       "L 298.906647 107.436206 \n",
       "L 301.90826 109.620048 \n",
       "L 304.909874 111.988606 \n",
       "L 307.911488 113.083137 \n",
       "L 310.913102 113.221226 \n",
       "L 313.914716 113.015247 \n",
       "L 316.916329 114.355084 \n",
       "L 319.917943 116.688984 \n",
       "L 322.919557 117.773664 \n",
       "L 325.921171 117.704941 \n",
       "L 328.922784 117.799035 \n",
       "L 331.924398 118.97813 \n",
       "L 334.926012 96.52696 \n",
       "L 337.927626 110.895314 \n",
       "L 346.932467 117.989269 \n",
       "L 352.935695 120.190008 \n",
       "L 355.937308 121.419934 \n",
       "L 358.938922 122.507422 \n",
       "L 361.940536 123.746969 \n",
       "L 364.94215 123.642214 \n",
       "L 367.943763 124.787219 \n",
       "L 370.945377 126.071562 \n",
       "L 373.946991 124.848468 \n",
       "L 376.948605 122.562091 \n",
       "L 379.950219 124.780074 \n",
       "L 382.951832 126.043761 \n",
       "L 385.953446 128.298204 \n",
       "L 388.95506 129.675076 \n",
       "L 391.956674 129.413998 \n",
       "L 394.958287 129.511133 \n",
       "L 397.959901 131.86335 \n",
       "L 400.961515 133.13222 \n",
       "L 406.964742 133.056463 \n",
       "L 415.969584 136.588313 \n",
       "L 421.972811 136.519971 \n",
       "L 424.974425 131.943109 \n",
       "L 427.976039 130.759067 \n",
       "L 430.977653 134.306711 \n",
       "L 433.979266 136.603618 \n",
       "L 436.98088 137.929193 \n",
       "L 439.982494 138.978681 \n",
       "L 445.985721 141.345121 \n",
       "L 448.987335 141.444408 \n",
       "L 454.990563 143.703752 \n",
       "L 457.992177 143.646056 \n",
       "L 460.99379 144.97621 \n",
       "L 463.995404 143.848652 \n",
       "L 466.997018 140.135757 \n",
       "L 469.998632 143.80841 \n",
       "L 476.001859 146.095426 \n",
       "L 479.003473 146.05638 \n",
       "L 491.009928 150.834536 \n",
       "L 494.011542 150.774857 \n",
       "L 497.013156 151.872551 \n",
       "L 500.014769 151.886061 \n",
       "L 506.017997 154.289985 \n",
       "L 509.019611 154.159676 \n",
       "L 512.021224 154.278804 \n",
       "L 515.022838 153.006564 \n",
       "L 518.024452 147.209389 \n",
       "L 521.026066 150.718115 \n",
       "L 524.02768 151.798947 \n",
       "L 527.029293 153.021874 \n",
       "L 530.030907 155.345343 \n",
       "L 533.032521 155.304755 \n",
       "L 536.034135 156.574514 \n",
       "L 539.035748 156.61305 \n",
       "L 545.038976 158.845233 \n",
       "L 548.04059 158.787852 \n",
       "L 551.042203 160.100112 \n",
       "L 554.043817 160.064712 \n",
       "L 557.045431 161.167836 \n",
       "L 560.047045 161.130234 \n",
       "L 563.048659 162.475106 \n",
       "L 566.050272 157.596729 \n",
       "L 569.051886 155.156824 \n",
       "L 569.051886 155.156824 \n",
       "\" clip-path=\"url(#ped1828c869)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 67.782386 58.521466 \n",
       "L 70.784 61.222136 \n",
       "L 73.785614 62.043999 \n",
       "L 76.787228 64.085852 \n",
       "L 79.788841 63.622376 \n",
       "L 82.790455 64.576341 \n",
       "L 85.792069 66.252156 \n",
       "L 88.793683 67.631463 \n",
       "L 91.795297 70.117837 \n",
       "L 94.79691 65.817853 \n",
       "L 97.798524 68.327764 \n",
       "L 100.800138 70.027826 \n",
       "L 103.801752 73.194646 \n",
       "L 106.803365 74.880966 \n",
       "L 109.804979 75.460049 \n",
       "L 112.806593 77.685165 \n",
       "L 115.808207 78.274889 \n",
       "L 118.80982 81.705312 \n",
       "L 121.811434 83.400119 \n",
       "L 124.813048 85.356616 \n",
       "L 127.814662 86.762653 \n",
       "L 130.816276 92.004752 \n",
       "L 133.817889 91.347259 \n",
       "L 136.819503 92.254683 \n",
       "L 139.821117 82.709808 \n",
       "L 142.822731 86.476088 \n",
       "L 148.825958 91.261191 \n",
       "L 151.827572 94.137836 \n",
       "L 154.829186 95.334189 \n",
       "L 157.830799 98.109173 \n",
       "L 160.832413 99.235649 \n",
       "L 163.834027 101.855164 \n",
       "L 166.835641 103.76031 \n",
       "L 172.838868 107.97342 \n",
       "L 175.840482 110.516854 \n",
       "L 178.842096 111.773536 \n",
       "L 181.84371 113.636735 \n",
       "L 184.845323 99.447295 \n",
       "L 187.846937 105.565137 \n",
       "L 190.848551 109.434138 \n",
       "L 193.850165 113.085733 \n",
       "L 196.851779 114.346565 \n",
       "L 199.853392 117.877396 \n",
       "L 202.855006 87.862506 \n",
       "L 205.85662 90.181495 \n",
       "L 208.858234 94.925529 \n",
       "L 211.859847 99.052404 \n",
       "L 214.861461 102.967596 \n",
       "L 217.863075 101.652082 \n",
       "L 220.864689 106.129336 \n",
       "L 223.866302 110.947877 \n",
       "L 226.867916 114.059573 \n",
       "L 229.86953 115.528044 \n",
       "L 232.871144 99.997606 \n",
       "L 235.872758 107.592708 \n",
       "L 238.874371 113.806272 \n",
       "L 241.875985 118.647516 \n",
       "L 244.877599 119.904258 \n",
       "L 247.879213 121.396393 \n",
       "L 250.880826 125.033428 \n",
       "L 253.88244 126.989928 \n",
       "L 256.884054 130.514991 \n",
       "L 259.885668 132.354445 \n",
       "L 262.887281 132.477498 \n",
       "L 265.888895 134.618927 \n",
       "L 268.890509 138.216975 \n",
       "L 274.893737 140.54357 \n",
       "L 277.89535 132.065168 \n",
       "L 280.896964 134.25629 \n",
       "L 283.898578 139.436981 \n",
       "L 289.901805 143.523379 \n",
       "L 292.903419 144.114826 \n",
       "L 295.905033 145.768276 \n",
       "L 298.906647 147.023473 \n",
       "L 304.909874 151.632428 \n",
       "L 307.911488 150.508437 \n",
       "L 310.913102 152.851484 \n",
       "L 313.914716 153.598028 \n",
       "L 316.916329 156.027631 \n",
       "L 319.917943 156.884073 \n",
       "L 322.919557 146.613593 \n",
       "L 325.921171 150.553928 \n",
       "L 328.922784 152.783204 \n",
       "L 331.924398 156.089724 \n",
       "L 334.926012 159.044769 \n",
       "L 337.927626 150.097747 \n",
       "L 340.92924 156.103012 \n",
       "L 343.930853 158.07329 \n",
       "L 346.932467 159.020555 \n",
       "L 349.934081 161.280215 \n",
       "L 352.935695 160.647626 \n",
       "L 355.937308 163.298517 \n",
       "L 358.938922 164.050411 \n",
       "L 361.940536 165.011531 \n",
       "L 364.94215 167.481285 \n",
       "L 367.943763 166.032274 \n",
       "L 370.945377 169.365732 \n",
       "L 373.946991 168.674782 \n",
       "L 376.948605 169.909217 \n",
       "L 379.950219 172.478531 \n",
       "L 382.951832 148.75888 \n",
       "L 385.953446 151.121568 \n",
       "L 388.95506 153.856591 \n",
       "L 391.956674 156.091521 \n",
       "L 394.958287 159.197385 \n",
       "L 397.959901 159.40282 \n",
       "L 400.961515 162.823198 \n",
       "L 403.963129 163.646711 \n",
       "L 406.964742 164.855628 \n",
       "L 409.966356 165.774754 \n",
       "L 412.96797 165.274341 \n",
       "L 418.971198 170.648326 \n",
       "L 421.972811 171.959079 \n",
       "L 424.974425 174.876005 \n",
       "L 427.976039 156.440378 \n",
       "L 430.977653 161.104551 \n",
       "L 433.979266 164.067857 \n",
       "L 436.98088 165.266545 \n",
       "L 439.982494 169.397143 \n",
       "L 442.984108 167.222853 \n",
       "L 445.985721 169.746865 \n",
       "L 448.987335 171.101079 \n",
       "L 451.988949 170.948324 \n",
       "L 454.990563 173.587594 \n",
       "L 457.992177 172.916972 \n",
       "L 460.99379 176.060522 \n",
       "L 460.99379 176.060522 \n",
       "\" clip-path=\"url(#ped1828c869)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #bfbf00; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 67.782386 162.579217 \n",
       "L 575.055114 162.579217 \n",
       "L 575.055114 162.579217 \n",
       "\" clip-path=\"url(#ped1828c869)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 42.41875 228.96 \n",
       "L 42.41875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 600.41875 228.96 \n",
       "L 600.41875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 42.41875 228.96 \n",
       "L 600.41875 228.96 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 42.41875 7.2 \n",
       "L 600.41875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 536.41875 68.35625 \n",
       "L 593.41875 68.35625 \n",
       "Q 595.41875 68.35625 595.41875 66.35625 \n",
       "L 595.41875 14.2 \n",
       "Q 595.41875 12.2 593.41875 12.2 \n",
       "L 536.41875 12.2 \n",
       "Q 534.41875 12.2 534.41875 14.2 \n",
       "L 534.41875 66.35625 \n",
       "Q 534.41875 68.35625 536.41875 68.35625 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 538.41875 19.7 \n",
       "L 548.41875 19.7 \n",
       "L 558.41875 19.7 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- B0005 -->\n",
       "     <g transform=\"translate(566.41875 23.2)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-42\" d=\"M 2975 1375 \n",
       "Q 2975 650 2575 375 \n",
       "Q 2175 100 1550 100 \n",
       "L 300 100 \n",
       "L 300 4375 \n",
       "L 1600 4375 \n",
       "Q 2225 4375 2537 4050 \n",
       "Q 2850 3725 2850 3275 \n",
       "Q 2850 2825 2637 2612 \n",
       "Q 2425 2400 2200 2325 \n",
       "Q 2500 2250 2737 2012 \n",
       "Q 2975 1775 2975 1375 \n",
       "z\n",
       "M 2275 3275 \n",
       "Q 2275 3600 2087 3750 \n",
       "Q 1900 3900 1625 3900 \n",
       "L 875 3900 \n",
       "L 875 2575 \n",
       "L 1600 2575 \n",
       "Q 1875 2575 2075 2737 \n",
       "Q 2275 2900 2275 3275 \n",
       "z\n",
       "M 2375 1375 \n",
       "Q 2375 1775 2112 1937 \n",
       "Q 1850 2100 1525 2100 \n",
       "L 875 2100 \n",
       "L 875 575 \n",
       "L 1450 575 \n",
       "Q 1900 575 2137 750 \n",
       "Q 2375 925 2375 1375 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-35\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <path d=\"M 538.41875 32.989063 \n",
       "L 548.41875 32.989063 \n",
       "L 558.41875 32.989063 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- B0006 -->\n",
       "     <g transform=\"translate(566.41875 36.489063)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-36\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_21\">\n",
       "     <path d=\"M 538.41875 46.278125 \n",
       "L 548.41875 46.278125 \n",
       "L 558.41875 46.278125 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- B0007 -->\n",
       "     <g transform=\"translate(566.41875 49.778125)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-37\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 538.41875 59.567188 \n",
       "L 548.41875 59.567188 \n",
       "L 558.41875 59.567188 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #bfbf00; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- B0018 -->\n",
       "     <g transform=\"translate(566.41875 63.067188)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-31\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-38\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"ped1828c869\">\n",
       "   <rect x=\"42.41875\" y=\"7.2\" width=\"558\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 800x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def matplot_battery_list(battery_data_list):\n",
    "    color_list = ['b:', 'g--', 'r-.', 'y:']\n",
    "    # 1.创建画布\n",
    "    plt.figure(figsize=(10, 4), dpi=80)\n",
    "    plt.xlabel('循环次数')\n",
    "    plt.ylabel('容量')\n",
    "\n",
    "    # 2.绘制折线图\n",
    "    for index, data in enumerate(battery_data_list):\n",
    "        plt.plot([i for i in range(len(battery_data_list[index]))], battery_data_list[index], color_list[index])\n",
    "\n",
    "    plt.plot([i for i in range(170)], [1.4] * 170)\n",
    "\n",
    "    # 图例\n",
    "    plt.legend([name for name in Battery_list])\n",
    "\n",
    "Battery_data_list = [Battery['B0005'][1], Battery['B0006'][1], Battery['B0007'][1], Battery['B0018'][1]]\n",
    "matplot_battery_list(Battery_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84323438",
   "metadata": {},
   "source": [
    "## 创建评估指标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8358962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T02:55:38.666332Z",
     "start_time": "2023-12-18T02:55:38.652369Z"
    }
   },
   "outputs": [],
   "source": [
    "# 平均绝对误差、均方根误差\n",
    "def evaluation(y_test, y_predict):\n",
    "    mae = mean_absolute_error(y_test, y_predict)\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_predict))\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# 相对误差\n",
    "# B0005 第125次循环后达到阈值1.4\n",
    "# B0006 第109次循环后达到阈值1.4\n",
    "# B0007 数据集中无任何值小于1.4，所以无法达到阈值1.4\n",
    "# B0018 第97次循环后达到阈值1.4\n",
    "def relative_error(y_test, y_predict, threshold):\n",
    "    true_re, pred_re = len(y_test), len(y_predict)\n",
    "    for i in range(len(y_test) - 1):\n",
    "        if y_test[i] <= threshold >= y_test[i + 1]:\n",
    "            true_re = i + 1\n",
    "            break\n",
    "    for i in range(len(y_predict) - 1):\n",
    "        if y_predict[i] <= threshold >= y_predict[i + 1]:\n",
    "            pred_re = i + 1\n",
    "            break\n",
    "    return abs(true_re - pred_re) / true_re\n",
    "\n",
    "# relative_error(Battery['B0006'][1], Battery['B0006'][1], 1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff09a6",
   "metadata": {},
   "source": [
    "## 构建训练序列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f166cb72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:00:13.618098Z",
     "start_time": "2023-12-18T03:00:13.599017Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构建数据\n",
    "# 采用 留一评估：一组数据为测试集，其他所有数据全部拿来训练\n",
    "# train_x 的维度是 window_size ，总样本数为 421\n",
    "# train_y 的维度是1，总样本数为421\n",
    "# train_data 是模型预测时的真实数据，用来预测下一时刻的容量，长度为 window_size\n",
    "# test_data 是 真实的容量数据，用来检验模型的各种参数\n",
    "\n",
    "def build_seq(text, window_size):\n",
    "    # text:list of capacity\n",
    "    x, y = [], []\n",
    "    for i in range(len(text) - window_size):\n",
    "        sequence = text[i:i + window_size]\n",
    "        target = text[i + 1:i + window_size + 1]\n",
    "        x.append(sequence)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def get_train_test_data(data_list, battery_i, window_size=16):\n",
    "    data_sequence = Battery[Battery_list[battery_i]][1]\n",
    "    train_data, test_data = data_sequence[:window_size], data_sequence[window_size:]\n",
    "    \n",
    "    train_x, train_y = None, None\n",
    "    for i, v in enumerate(data_list):\n",
    "        if i != battery_i:\n",
    "            data_x, data_y = build_seq(text=v, window_size=window_size)\n",
    "            if train_x is None:\n",
    "                train_x = data_x\n",
    "                train_y = data_y\n",
    "            else:\n",
    "                train_x, train_y = np.r_[train_x, data_x], np.r_[train_y, data_y]\n",
    "\n",
    "    return train_x, train_y, list(train_data), list(test_data)\n",
    "\n",
    "def load_capacity_data(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b2708",
   "metadata": {},
   "source": [
    "## 检验 train_iter 数据是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23bd1d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:00:17.267959Z",
     "start_time": "2023-12-18T03:00:16.379835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "tensor([[2.0353, 2.0251, 2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682,\n",
      "         1.9572, 1.9456, 1.9348, 1.9233, 1.9119, 1.9011, 1.8892],\n",
      "        [2.0251, 2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682, 1.9572,\n",
      "         1.9456, 1.9348, 1.9233, 1.9119, 1.9011, 1.8892, 1.8783]])\n",
      "tensor([[2.0251, 2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682, 1.9572,\n",
      "         1.9456, 1.9348, 1.9233, 1.9119, 1.9011, 1.8892, 1.8783],\n",
      "        [2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682, 1.9572, 1.9456,\n",
      "         1.9348, 1.9233, 1.9119, 1.9011, 1.8892, 1.8783, 1.8676]])\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, train_data, test_data = get_train_test_data(Battery_data_list, 0, window_size=16)\n",
    "train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "train_iter = load_capacity_data((train_x, train_y), 2, is_train=False)\n",
    "\n",
    "# 测试 train_iter 的数据是否正确\n",
    "def validate_train_iter(train_iter):\n",
    "    for x, y in train_iter:\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        \n",
    "        print(x)\n",
    "        print(y)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "validate_train_iter(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29d90d",
   "metadata": {},
   "source": [
    "## 绘制 out 和  tgt_y的对比图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f571c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:00:20.457777Z",
     "start_time": "2023-12-18T03:00:20.442816Z"
    }
   },
   "outputs": [],
   "source": [
    "# 绘制 out  tgt_y的对比图\n",
    "def matlab_make(out, tgt_y):\n",
    "    color_list = ['b:', 'g:']\n",
    "    # 1.创建画布\n",
    "    fig = plt.figure(figsize=(7, 2), dpi=80)\n",
    "    plt.xlabel('循环次数')\n",
    "    plt.ylabel('容量')\n",
    "    \n",
    "    data_list = [\n",
    "        {\n",
    "            'name': 'out',\n",
    "            'x': [i for i in range(len(out))],\n",
    "            'y': out\n",
    "        },\n",
    "        {\n",
    "            'name': 'tgt_y',\n",
    "            'x': [i for i in range(len(tgt_y))],\n",
    "            'y': tgt_y\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 2.绘制折线图\n",
    "    for data,color in zip(data_list, color_list):\n",
    "        plt.plot(data['x'], data['y'], color)\n",
    "\n",
    "\n",
    "    # 图例\n",
    "    plt.legend([data['name'] for data in data_list])\n",
    "    \n",
    "    display(fig)\n",
    "    plt.close() \n",
    "\n",
    "# out_t = [1,2,3,4,5,6,7,8,9,10]\n",
    "# tgt_y_t = [11,21,31,41,51,61,71,81,91,110]\n",
    "\n",
    "# matlab_make(out_t, tgt_y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106cef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T07:01:58.886526Z",
     "start_time": "2023-10-15T07:01:58.880522Z"
    }
   },
   "source": [
    "## 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8690b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:00:22.994173Z",
     "start_time": "2023-12-18T03:00:22.983202Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 为了禁止hash随机化，使得实验可复现。\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0f092",
   "metadata": {},
   "source": [
    "## TCN 模型 源自论文源码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067e7133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T05:42:14.713538Z",
     "start_time": "2023-11-30T05:42:14.672622Z"
    }
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862823ee",
   "metadata": {},
   "source": [
    "## TCN模型 源自pytorch-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TCN(num_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c3db8",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cb0147c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:05:58.383897Z",
     "start_time": "2023-12-18T03:05:58.363773Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, num_channels, kernel_size, dropout):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.tcn = TCN(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        \n",
    "        self.linear = nn.Linear(num_channels[-1], 1)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "        # print('x.shape', x.shape)\n",
    "        y1 = self.tcn(x)\n",
    "        # print('y1.shape', y1.shape)\n",
    "        # print('y1[:, :, -1].shape', y1[:, :, -1].shape)\n",
    "        return self.linear(y1[:, :, -1])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa74dc",
   "metadata": {},
   "source": [
    "## 测试模型的输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8faef20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:06:00.509058Z",
     "start_time": "2023-12-18T03:06:00.397356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# 测试模型的输出形状\n",
    "net = Net(1, [30, 30, 30, 30, 30, 30, 30, 30], 3, 0.0).to(device)\n",
    "\n",
    "# src = torch.LongTensor([[0, 3, 4, 5, 6, 1, 2, 2]])\n",
    "x = torch.ones((32, 16), dtype=torch.float32).to(device)\n",
    "\n",
    "out = net(x)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0335b",
   "metadata": {},
   "source": [
    "## 一个批次的训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083c9efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:06:55.629608Z",
     "start_time": "2023-12-18T03:06:55.623597Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss, updater): \n",
    "    # 将模型设置为训练模式\n",
    "    net.train()\n",
    "    \n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    for x, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        x = torch.reshape(x, (-1, x.shape[-1])).type(torch.float32)\n",
    "        \n",
    "        y = y[:, -1:].type(torch.float32)\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #print(src.device)\n",
    "        #print(tgt.device)\n",
    "        \n",
    "        updater.zero_grad()\n",
    "        \n",
    "        out = net(x)\n",
    "        # print('out.shape is', out.shape)\n",
    "        # print('y.shape is', y.shape)\n",
    "        \n",
    "    \n",
    "        #print('111out', out.shape) # (50, 153, 1)\n",
    "        # print('111tgt_y', tgt_y.shape) # (50, 153)\n",
    "        \n",
    "        l = loss(out.reshape(-1), y.reshape(-1))\n",
    "        \n",
    "        #print('222out', out[-1, :, :].cpu().data.numpy().shape) # (50, 153, 1)\n",
    "        #print('222tgt_y', tgt_y.shape) # (50, 153)\n",
    "        \n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        updater.step()\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc78239",
   "metadata": {},
   "source": [
    "## 总的训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e9d16ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:06:58.039756Z",
     "start_time": "2023-12-18T03:06:58.022800Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed):\n",
    "    net = net.to(device)\n",
    "    \n",
    "    mae_epoch_list, rmse_epoch_list, re_epoch_list, r2_epoch_list = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(net, train_iter, loss, updater)\n",
    "        \n",
    "        # if (epoch + 1) % 100 == 0:\n",
    "        pre_list = predict(net, train_data, test_data, Rated_Capacity)\n",
    "        \n",
    "        test_y = test_data.copy()\n",
    "\n",
    "        mae, rmse, r2 = evaluation(test_data, pre_list)\n",
    "        re = relative_error(test_y, pre_list, threshold=Rated_Capacity * 0.7)\n",
    "\n",
    "        # if (len(re_epoch_list) == 0 or (r2_epoch_list[-1] < r2)):\n",
    "        print('seed: {}, 测试集: {}, epoch:{:<4d} , loss:{:<6.10f} , MAE:{:<6.4f} , RMSE:{:<6.4f} , RE:{:<6.4f} , R2:{:<6.4f}'.format(seed, Battery_list[i], epoch + 1, train_loss, mae, rmse, re, r2))\n",
    "        mae_epoch_list.append(mae)\n",
    "        rmse_epoch_list.append(rmse)\n",
    "        re_epoch_list.append(re)\n",
    "        r2_epoch_list.append(r2)\n",
    "\n",
    "\n",
    "        # matlab_make(pre_list, test_y)\n",
    "\n",
    "        # if (train_loss < 1e-3) and len(re_epoch_list) > 0 and 0.0 < re_epoch_list[-1] < 0.2 and (re_epoch_list[-1] < re):\n",
    "        #     break\n",
    "\n",
    "    return mae_epoch_list[-1], rmse_epoch_list[-1], re_epoch_list[-1], r2_epoch_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baa67d",
   "metadata": {},
   "source": [
    "## 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea03f569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:09:22.630085Z",
     "start_time": "2023-12-18T03:09:22.615102Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(net, train_data, test_data, Rated_Capacity):\n",
    "    # print()\n",
    "    net = net.eval()\n",
    "    \n",
    "    x = train_data.copy()\n",
    "    x = np.array(x)\n",
    "    x = torch.from_numpy(x).type(torch.float32).to(device)\n",
    "    x = torch.reshape(x, (1, -1)) # shape: (batch_size, input_size)\n",
    "    # print('x.shape', x.shape)\n",
    "    \n",
    "    pre_list = []\n",
    "    while len(pre_list) < len(test_data):\n",
    "        \n",
    "        # print(x)\n",
    "        out = net(x)\n",
    "        # print(out)\n",
    "        # print()\n",
    "        # print('out.shape', out.shape)\n",
    "        # print('x[:, 1:].shape', x[:, 1:].shape)\n",
    "        # print('out[:, -1:].shape', out[:, -1:].shape)\n",
    "        x = torch.cat([x[:, 1:], out[:, -1:]], dim=1)\n",
    "        \n",
    "        pred = out.reshape(-1)\n",
    "        \n",
    "        pred_next_point = pred.cpu().data.numpy()[-1]\n",
    "        \n",
    "        \n",
    "        pre_list.append(pred_next_point)\n",
    "        \n",
    "    # print(pre_list) \n",
    "    return pre_list\n",
    "        \n",
    "    \n",
    "# x = train_data.copy()\n",
    "# pred_list = predict(net, train_data, test_data, 2)\n",
    "# print((pred_list))\n",
    "# print((test_data))\n",
    "\n",
    "# print(len(pred_list))\n",
    "# print(len(test_data))\n",
    "# matlab_make(pred_list, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ab36f",
   "metadata": {},
   "source": [
    "## 开始训练 num_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726a6f1",
   "metadata": {},
   "source": [
    "### is_train=True 判断函数是(r2_epoch_list[-1] < r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a8388a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:45:13.462766Z",
     "start_time": "2023-12-18T03:12:23.652368Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************************************\n",
      "当前的 seed 为 2\n",
      "以电池 B0005 为测试数据的 数据集 开始训练\n",
      "seed: 2, 测试集: B0005, epoch:1    , loss:1.8629014492 , MAE:1.3993 , RMSE:1.4108 , RE:0.9908 , R2:-60.6113\n",
      "seed: 2, 测试集: B0005, epoch:2    , loss:1.9785821438 , MAE:1.3867 , RMSE:1.3982 , RE:0.9908 , R2:-59.5206\n",
      "seed: 2, 测试集: B0005, epoch:3    , loss:1.7256989479 , MAE:1.3740 , RMSE:1.3856 , RE:0.9908 , R2:-58.4329\n",
      "seed: 2, 测试集: B0005, epoch:4    , loss:1.3473974466 , MAE:1.3610 , RMSE:1.3727 , RE:0.9908 , R2:-57.3329\n",
      "seed: 2, 测试集: B0005, epoch:5    , loss:1.6778869629 , MAE:1.3475 , RMSE:1.3594 , RE:0.9908 , R2:-56.2028\n",
      "seed: 2, 测试集: B0005, epoch:6    , loss:1.9621496201 , MAE:1.3332 , RMSE:1.3452 , RE:0.9908 , R2:-55.0128\n",
      "seed: 2, 测试集: B0005, epoch:7    , loss:1.6787403822 , MAE:1.3177 , RMSE:1.3298 , RE:0.9908 , R2:-53.7395\n",
      "seed: 2, 测试集: B0005, epoch:8    , loss:1.7783172131 , MAE:1.3005 , RMSE:1.3128 , RE:0.9908 , R2:-52.3463\n",
      "seed: 2, 测试集: B0005, epoch:9    , loss:1.7636789083 , MAE:1.2813 , RMSE:1.2937 , RE:0.9908 , R2:-50.8092\n",
      "seed: 2, 测试集: B0005, epoch:10   , loss:1.2903361320 , MAE:1.2598 , RMSE:1.2724 , RE:0.9908 , R2:-49.1131\n",
      "seed: 2, 测试集: B0005, epoch:11   , loss:1.1471724510 , MAE:1.2356 , RMSE:1.2484 , RE:0.9908 , R2:-47.2425\n",
      "seed: 2, 测试集: B0005, epoch:12   , loss:0.9819235206 , MAE:1.2079 , RMSE:1.2209 , RE:0.9908 , R2:-45.1443\n",
      "seed: 2, 测试集: B0005, epoch:13   , loss:1.2837835550 , MAE:1.1753 , RMSE:1.1886 , RE:0.9908 , R2:-42.7358\n",
      "seed: 2, 测试集: B0005, epoch:14   , loss:1.1567528248 , MAE:1.1378 , RMSE:1.1515 , RE:0.9908 , R2:-40.0489\n",
      "seed: 2, 测试集: B0005, epoch:15   , loss:1.0302977562 , MAE:1.0951 , RMSE:1.1093 , RE:0.9908 , R2:-37.0922\n",
      "seed: 2, 测试集: B0005, epoch:16   , loss:0.5871534348 , MAE:1.0466 , RMSE:1.0614 , RE:0.9908 , R2:-33.8712\n",
      "seed: 2, 测试集: B0005, epoch:17   , loss:0.6862480044 , MAE:0.9906 , RMSE:1.0060 , RE:0.9908 , R2:-30.3306\n",
      "seed: 2, 测试集: B0005, epoch:18   , loss:0.5593940616 , MAE:0.9212 , RMSE:0.9377 , RE:0.9908 , R2:-26.2161\n",
      "seed: 2, 测试集: B0005, epoch:19   , loss:0.4523116350 , MAE:0.8420 , RMSE:0.8598 , RE:0.9908 , R2:-21.8867\n",
      "seed: 2, 测试集: B0005, epoch:20   , loss:0.2441415489 , MAE:0.7527 , RMSE:0.7725 , RE:0.9908 , R2:-17.4731\n",
      "seed: 2, 测试集: B0005, epoch:21   , loss:0.2710279822 , MAE:0.6552 , RMSE:0.6777 , RE:0.9908 , R2:-13.2181\n",
      "seed: 2, 测试集: B0005, epoch:22   , loss:0.1113203615 , MAE:0.5500 , RMSE:0.5765 , RE:0.9908 , R2:-9.2873\n",
      "seed: 2, 测试集: B0005, epoch:23   , loss:0.0927604511 , MAE:0.4424 , RMSE:0.4748 , RE:0.9908 , R2:-5.9778\n",
      "seed: 2, 测试集: B0005, epoch:24   , loss:0.0350023247 , MAE:0.3359 , RMSE:0.3775 , RE:0.9817 , R2:-3.4120\n",
      "seed: 2, 测试集: B0005, epoch:25   , loss:0.0412722901 , MAE:0.2405 , RMSE:0.2957 , RE:0.9541 , R2:-1.7058\n",
      "seed: 2, 测试集: B0005, epoch:26   , loss:0.0107144210 , MAE:0.1838 , RMSE:0.2334 , RE:0.8991 , R2:-0.6861\n",
      "seed: 2, 测试集: B0005, epoch:27   , loss:0.0069875610 , MAE:0.1618 , RMSE:0.1970 , RE:0.3945 , R2:-0.2008\n",
      "seed: 2, 测试集: B0005, epoch:28   , loss:0.0277313106 , MAE:0.1546 , RMSE:0.1804 , RE:0.3945 , R2:-0.0072\n",
      "seed: 2, 测试集: B0005, epoch:29   , loss:0.0015616160 , MAE:0.1534 , RMSE:0.1751 , RE:0.3945 , R2:0.0510\n",
      "seed: 2, 测试集: B0005, epoch:30   , loss:0.0034110781 , MAE:0.1541 , RMSE:0.1744 , RE:0.3945 , R2:0.0585\n",
      "seed: 2, 测试集: B0005, epoch:31   , loss:0.0242139660 , MAE:0.1549 , RMSE:0.1746 , RE:0.3945 , R2:0.0559\n",
      "seed: 2, 测试集: B0005, epoch:32   , loss:0.0029526360 , MAE:0.1555 , RMSE:0.1751 , RE:0.3945 , R2:0.0511\n",
      "seed: 2, 测试集: B0005, epoch:33   , loss:0.0022071057 , MAE:0.1552 , RMSE:0.1749 , RE:0.3945 , R2:0.0535\n",
      "seed: 2, 测试集: B0005, epoch:34   , loss:0.0278953742 , MAE:0.1552 , RMSE:0.1748 , RE:0.3945 , R2:0.0542\n",
      "seed: 2, 测试集: B0005, epoch:35   , loss:0.0147218937 , MAE:0.1556 , RMSE:0.1751 , RE:0.3945 , R2:0.0504\n",
      "seed: 2, 测试集: B0005, epoch:36   , loss:0.0039075301 , MAE:0.1557 , RMSE:0.1752 , RE:0.3945 , R2:0.0496\n",
      "seed: 2, 测试集: B0005, epoch:37   , loss:0.0099969227 , MAE:0.1553 , RMSE:0.1749 , RE:0.3945 , R2:0.0536\n",
      "seed: 2, 测试集: B0005, epoch:38   , loss:0.0043268055 , MAE:0.1553 , RMSE:0.1749 , RE:0.3945 , R2:0.0531\n",
      "seed: 2, 测试集: B0005, epoch:39   , loss:0.0162621662 , MAE:0.1556 , RMSE:0.1751 , RE:0.3945 , R2:0.0506\n",
      "seed: 2, 测试集: B0005, epoch:40   , loss:0.0063736914 , MAE:0.1555 , RMSE:0.1751 , RE:0.3945 , R2:0.0514\n",
      "seed: 2, 测试集: B0005, epoch:41   , loss:0.0045307265 , MAE:0.1555 , RMSE:0.1750 , RE:0.3945 , R2:0.0521\n",
      "seed: 2, 测试集: B0005, epoch:42   , loss:0.0042672385 , MAE:0.1552 , RMSE:0.1748 , RE:0.3945 , R2:0.0543\n",
      "seed: 2, 测试集: B0005, epoch:43   , loss:0.0174193308 , MAE:0.1547 , RMSE:0.1744 , RE:0.3945 , R2:0.0583\n",
      "seed: 2, 测试集: B0005, epoch:44   , loss:0.0235820059 , MAE:0.1543 , RMSE:0.1742 , RE:0.3945 , R2:0.0603\n",
      "seed: 2, 测试集: B0005, epoch:45   , loss:0.0037354245 , MAE:0.1555 , RMSE:0.1750 , RE:0.3945 , R2:0.0520\n",
      "seed: 2, 测试集: B0005, epoch:46   , loss:0.0054970449 , MAE:0.1555 , RMSE:0.1750 , RE:0.3945 , R2:0.0519\n",
      "seed: 2, 测试集: B0005, epoch:47   , loss:0.0175046269 , MAE:0.1551 , RMSE:0.1746 , RE:0.3945 , R2:0.0560\n",
      "seed: 2, 测试集: B0005, epoch:48   , loss:0.0041407687 , MAE:0.1550 , RMSE:0.1746 , RE:0.3945 , R2:0.0563\n",
      "seed: 2, 测试集: B0005, epoch:49   , loss:0.0056123529 , MAE:0.1547 , RMSE:0.1744 , RE:0.3945 , R2:0.0589\n",
      "seed: 2, 测试集: B0005, epoch:50   , loss:0.0019331560 , MAE:0.1553 , RMSE:0.1748 , RE:0.3945 , R2:0.0546\n",
      "seed: 2, 测试集: B0005, epoch:51   , loss:0.0048077209 , MAE:0.1551 , RMSE:0.1746 , RE:0.3945 , R2:0.0559\n",
      "seed: 2, 测试集: B0005, epoch:52   , loss:0.0063750232 , MAE:0.1547 , RMSE:0.1743 , RE:0.3945 , R2:0.0591\n",
      "seed: 2, 测试集: B0005, epoch:53   , loss:0.0004499247 , MAE:0.1545 , RMSE:0.1742 , RE:0.3945 , R2:0.0608\n",
      "seed: 2, 测试集: B0005, epoch:54   , loss:0.0077756206 , MAE:0.1544 , RMSE:0.1742 , RE:0.3945 , R2:0.0610\n",
      "seed: 2, 测试集: B0005, epoch:55   , loss:0.0065438431 , MAE:0.1547 , RMSE:0.1743 , RE:0.3945 , R2:0.0597\n",
      "seed: 2, 测试集: B0005, epoch:56   , loss:0.0148237860 , MAE:0.1544 , RMSE:0.1741 , RE:0.3945 , R2:0.0613\n",
      "seed: 2, 测试集: B0005, epoch:57   , loss:0.0033157298 , MAE:0.1543 , RMSE:0.1741 , RE:0.3945 , R2:0.0620\n",
      "seed: 2, 测试集: B0005, epoch:58   , loss:0.0020181499 , MAE:0.1546 , RMSE:0.1742 , RE:0.3945 , R2:0.0603\n",
      "seed: 2, 测试集: B0005, epoch:59   , loss:0.0082170414 , MAE:0.1545 , RMSE:0.1741 , RE:0.3945 , R2:0.0613\n",
      "seed: 2, 测试集: B0005, epoch:60   , loss:0.0076222075 , MAE:0.1549 , RMSE:0.1744 , RE:0.3945 , R2:0.0583\n",
      "seed: 2, 测试集: B0005, epoch:61   , loss:0.0052830996 , MAE:0.1547 , RMSE:0.1742 , RE:0.3945 , R2:0.0604\n",
      "seed: 2, 测试集: B0005, epoch:62   , loss:0.0085008908 , MAE:0.1541 , RMSE:0.1738 , RE:0.3945 , R2:0.0644\n",
      "seed: 2, 测试集: B0005, epoch:63   , loss:0.0130525278 , MAE:0.1540 , RMSE:0.1738 , RE:0.3945 , R2:0.0651\n",
      "seed: 2, 测试集: B0005, epoch:64   , loss:0.0044282023 , MAE:0.1536 , RMSE:0.1737 , RE:0.3945 , R2:0.0662\n",
      "seed: 2, 测试集: B0005, epoch:65   , loss:0.0096556256 , MAE:0.1542 , RMSE:0.1739 , RE:0.3945 , R2:0.0637\n",
      "seed: 2, 测试集: B0005, epoch:66   , loss:0.0111903753 , MAE:0.1545 , RMSE:0.1741 , RE:0.3945 , R2:0.0620\n",
      "seed: 2, 测试集: B0005, epoch:67   , loss:0.0161420759 , MAE:0.1548 , RMSE:0.1743 , RE:0.3945 , R2:0.0597\n",
      "seed: 2, 测试集: B0005, epoch:68   , loss:0.0191623829 , MAE:0.1548 , RMSE:0.1743 , RE:0.3945 , R2:0.0596\n",
      "seed: 2, 测试集: B0005, epoch:69   , loss:0.0042434903 , MAE:0.1560 , RMSE:0.1753 , RE:0.3945 , R2:0.0488\n",
      "seed: 2, 测试集: B0005, epoch:70   , loss:0.0061524273 , MAE:0.1551 , RMSE:0.1745 , RE:0.3945 , R2:0.0574\n",
      "seed: 2, 测试集: B0005, epoch:71   , loss:0.0070170267 , MAE:0.1545 , RMSE:0.1740 , RE:0.3945 , R2:0.0628\n",
      "seed: 2, 测试集: B0005, epoch:72   , loss:0.0145863229 , MAE:0.1545 , RMSE:0.1740 , RE:0.3945 , R2:0.0632\n",
      "seed: 2, 测试集: B0005, epoch:73   , loss:0.0062862555 , MAE:0.1549 , RMSE:0.1743 , RE:0.3945 , R2:0.0597\n",
      "seed: 2, 测试集: B0005, epoch:74   , loss:0.0051187482 , MAE:0.1544 , RMSE:0.1739 , RE:0.3945 , R2:0.0636\n",
      "seed: 2, 测试集: B0005, epoch:75   , loss:0.0123040322 , MAE:0.1538 , RMSE:0.1735 , RE:0.3945 , R2:0.0683\n",
      "seed: 2, 测试集: B0005, epoch:76   , loss:0.0096482076 , MAE:0.1541 , RMSE:0.1737 , RE:0.3945 , R2:0.0663\n",
      "seed: 2, 测试集: B0005, epoch:77   , loss:0.0054273689 , MAE:0.1538 , RMSE:0.1735 , RE:0.3945 , R2:0.0685\n",
      "seed: 2, 测试集: B0005, epoch:78   , loss:0.0083803348 , MAE:0.1545 , RMSE:0.1739 , RE:0.3945 , R2:0.0638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:79   , loss:0.0095697939 , MAE:0.1546 , RMSE:0.1740 , RE:0.3945 , R2:0.0627\n",
      "seed: 2, 测试集: B0005, epoch:80   , loss:0.0090239011 , MAE:0.1545 , RMSE:0.1739 , RE:0.3945 , R2:0.0640\n",
      "seed: 2, 测试集: B0005, epoch:81   , loss:0.0066703223 , MAE:0.1546 , RMSE:0.1740 , RE:0.3945 , R2:0.0627\n",
      "seed: 2, 测试集: B0005, epoch:82   , loss:0.0069185137 , MAE:0.1547 , RMSE:0.1741 , RE:0.3945 , R2:0.0622\n",
      "seed: 2, 测试集: B0005, epoch:83   , loss:0.0038287989 , MAE:0.1551 , RMSE:0.1744 , RE:0.3945 , R2:0.0581\n",
      "seed: 2, 测试集: B0005, epoch:84   , loss:0.0054307496 , MAE:0.1548 , RMSE:0.1741 , RE:0.3945 , R2:0.0613\n",
      "seed: 2, 测试集: B0005, epoch:85   , loss:0.0047617094 , MAE:0.1539 , RMSE:0.1734 , RE:0.3945 , R2:0.0691\n",
      "seed: 2, 测试集: B0005, epoch:86   , loss:0.0093401056 , MAE:0.1540 , RMSE:0.1735 , RE:0.3945 , R2:0.0686\n",
      "seed: 2, 测试集: B0005, epoch:87   , loss:0.0051540793 , MAE:0.1546 , RMSE:0.1739 , RE:0.3945 , R2:0.0634\n",
      "seed: 2, 测试集: B0005, epoch:88   , loss:0.0032599282 , MAE:0.1548 , RMSE:0.1741 , RE:0.3945 , R2:0.0612\n",
      "seed: 2, 测试集: B0005, epoch:89   , loss:0.0086047975 , MAE:0.1542 , RMSE:0.1736 , RE:0.3945 , R2:0.0675\n",
      "seed: 2, 测试集: B0005, epoch:90   , loss:0.0069420612 , MAE:0.1534 , RMSE:0.1730 , RE:0.3945 , R2:0.0731\n",
      "seed: 2, 测试集: B0005, epoch:91   , loss:0.0117723774 , MAE:0.1538 , RMSE:0.1733 , RE:0.3945 , R2:0.0708\n",
      "seed: 2, 测试集: B0005, epoch:92   , loss:0.0094726002 , MAE:0.1537 , RMSE:0.1732 , RE:0.3945 , R2:0.0713\n",
      "seed: 2, 测试集: B0005, epoch:93   , loss:0.0055894470 , MAE:0.1534 , RMSE:0.1730 , RE:0.3945 , R2:0.0736\n",
      "seed: 2, 测试集: B0005, epoch:94   , loss:0.0084552653 , MAE:0.1540 , RMSE:0.1734 , RE:0.3945 , R2:0.0697\n",
      "seed: 2, 测试集: B0005, epoch:95   , loss:0.0131836385 , MAE:0.1538 , RMSE:0.1732 , RE:0.3945 , R2:0.0712\n",
      "seed: 2, 测试集: B0005, epoch:96   , loss:0.0118094366 , MAE:0.1542 , RMSE:0.1735 , RE:0.3945 , R2:0.0679\n",
      "seed: 2, 测试集: B0005, epoch:97   , loss:0.0053857993 , MAE:0.1546 , RMSE:0.1739 , RE:0.3945 , R2:0.0641\n",
      "seed: 2, 测试集: B0005, epoch:98   , loss:0.0045952569 , MAE:0.1533 , RMSE:0.1728 , RE:0.3945 , R2:0.0756\n",
      "seed: 2, 测试集: B0005, epoch:99   , loss:0.0111290310 , MAE:0.1530 , RMSE:0.1726 , RE:0.3945 , R2:0.0774\n",
      "seed: 2, 测试集: B0005, epoch:100  , loss:0.0128342770 , MAE:0.1535 , RMSE:0.1729 , RE:0.3945 , R2:0.0748\n",
      "seed: 2, 测试集: B0005, epoch:101  , loss:0.0065457821 , MAE:0.1533 , RMSE:0.1727 , RE:0.3945 , R2:0.0762\n",
      "seed: 2, 测试集: B0005, epoch:102  , loss:0.0023712935 , MAE:0.1529 , RMSE:0.1725 , RE:0.3945 , R2:0.0788\n",
      "seed: 2, 测试集: B0005, epoch:103  , loss:0.0068347044 , MAE:0.1531 , RMSE:0.1726 , RE:0.3945 , R2:0.0782\n",
      "seed: 2, 测试集: B0005, epoch:104  , loss:0.0077465735 , MAE:0.1535 , RMSE:0.1728 , RE:0.3945 , R2:0.0756\n",
      "seed: 2, 测试集: B0005, epoch:105  , loss:0.0073525431 , MAE:0.1528 , RMSE:0.1723 , RE:0.3945 , R2:0.0805\n",
      "seed: 2, 测试集: B0005, epoch:106  , loss:0.0019258072 , MAE:0.1534 , RMSE:0.1727 , RE:0.3945 , R2:0.0763\n",
      "seed: 2, 测试集: B0005, epoch:107  , loss:0.0118367393 , MAE:0.1530 , RMSE:0.1724 , RE:0.3945 , R2:0.0794\n",
      "seed: 2, 测试集: B0005, epoch:108  , loss:0.0041028792 , MAE:0.1536 , RMSE:0.1728 , RE:0.3945 , R2:0.0751\n",
      "seed: 2, 测试集: B0005, epoch:109  , loss:0.0057335822 , MAE:0.1534 , RMSE:0.1726 , RE:0.3945 , R2:0.0774\n",
      "seed: 2, 测试集: B0005, epoch:110  , loss:0.0025447342 , MAE:0.1535 , RMSE:0.1728 , RE:0.3945 , R2:0.0760\n",
      "seed: 2, 测试集: B0005, epoch:111  , loss:0.0067101950 , MAE:0.1533 , RMSE:0.1725 , RE:0.3945 , R2:0.0785\n",
      "seed: 2, 测试集: B0005, epoch:112  , loss:0.0085313534 , MAE:0.1535 , RMSE:0.1727 , RE:0.3945 , R2:0.0768\n",
      "seed: 2, 测试集: B0005, epoch:113  , loss:0.0071805604 , MAE:0.1544 , RMSE:0.1735 , RE:0.3945 , R2:0.0682\n",
      "seed: 2, 测试集: B0005, epoch:114  , loss:0.0049559679 , MAE:0.1522 , RMSE:0.1716 , RE:0.3945 , R2:0.0880\n",
      "seed: 2, 测试集: B0005, epoch:115  , loss:0.0038698064 , MAE:0.1538 , RMSE:0.1729 , RE:0.3945 , R2:0.0741\n",
      "seed: 2, 测试集: B0005, epoch:116  , loss:0.0071318280 , MAE:0.1521 , RMSE:0.1714 , RE:0.3945 , R2:0.0904\n",
      "seed: 2, 测试集: B0005, epoch:117  , loss:0.0017240210 , MAE:0.1509 , RMSE:0.1711 , RE:0.3945 , R2:0.0935\n",
      "seed: 2, 测试集: B0005, epoch:118  , loss:0.0065761418 , MAE:0.1539 , RMSE:0.1730 , RE:0.3945 , R2:0.0739\n",
      "seed: 2, 测试集: B0005, epoch:119  , loss:0.0058049867 , MAE:0.1520 , RMSE:0.1712 , RE:0.3945 , R2:0.0928\n",
      "seed: 2, 测试集: B0005, epoch:120  , loss:0.0028851209 , MAE:0.1517 , RMSE:0.1709 , RE:0.3945 , R2:0.0960\n",
      "seed: 2, 测试集: B0005, epoch:121  , loss:0.0060073570 , MAE:0.1516 , RMSE:0.1708 , RE:0.3945 , R2:0.0968\n",
      "seed: 2, 测试集: B0005, epoch:122  , loss:0.0042387620 , MAE:0.1516 , RMSE:0.1707 , RE:0.3945 , R2:0.0981\n",
      "seed: 2, 测试集: B0005, epoch:123  , loss:0.0119276270 , MAE:0.1518 , RMSE:0.1708 , RE:0.3945 , R2:0.0969\n",
      "seed: 2, 测试集: B0005, epoch:124  , loss:0.0066624973 , MAE:0.1514 , RMSE:0.1705 , RE:0.3945 , R2:0.1002\n",
      "seed: 2, 测试集: B0005, epoch:125  , loss:0.0038545264 , MAE:0.1517 , RMSE:0.1707 , RE:0.3945 , R2:0.0980\n",
      "seed: 2, 测试集: B0005, epoch:126  , loss:0.0037634405 , MAE:0.1500 , RMSE:0.1698 , RE:0.3945 , R2:0.1079\n",
      "seed: 2, 测试集: B0005, epoch:127  , loss:0.0048879059 , MAE:0.1519 , RMSE:0.1708 , RE:0.3945 , R2:0.0971\n",
      "seed: 2, 测试集: B0005, epoch:128  , loss:0.0026617688 , MAE:0.1497 , RMSE:0.1695 , RE:0.3945 , R2:0.1112\n",
      "seed: 2, 测试集: B0005, epoch:129  , loss:0.0005573391 , MAE:0.1509 , RMSE:0.1699 , RE:0.3945 , R2:0.1066\n",
      "seed: 2, 测试集: B0005, epoch:130  , loss:0.0101456791 , MAE:0.1512 , RMSE:0.1701 , RE:0.3945 , R2:0.1045\n",
      "seed: 2, 测试集: B0005, epoch:131  , loss:0.0015130530 , MAE:0.1506 , RMSE:0.1695 , RE:0.3945 , R2:0.1104\n",
      "seed: 2, 测试集: B0005, epoch:132  , loss:0.0038618543 , MAE:0.1501 , RMSE:0.1691 , RE:0.3945 , R2:0.1149\n",
      "seed: 2, 测试集: B0005, epoch:133  , loss:0.0036546001 , MAE:0.1501 , RMSE:0.1690 , RE:0.3945 , R2:0.1162\n",
      "seed: 2, 测试集: B0005, epoch:134  , loss:0.0032394247 , MAE:0.1500 , RMSE:0.1689 , RE:0.3945 , R2:0.1172\n",
      "seed: 2, 测试集: B0005, epoch:135  , loss:0.0010072216 , MAE:0.1498 , RMSE:0.1686 , RE:0.3945 , R2:0.1196\n",
      "seed: 2, 测试集: B0005, epoch:136  , loss:0.0053394185 , MAE:0.1499 , RMSE:0.1686 , RE:0.3945 , R2:0.1197\n",
      "seed: 2, 测试集: B0005, epoch:137  , loss:0.0082011614 , MAE:0.1498 , RMSE:0.1685 , RE:0.3945 , R2:0.1210\n",
      "seed: 2, 测试集: B0005, epoch:138  , loss:0.0037742006 , MAE:0.1497 , RMSE:0.1684 , RE:0.3945 , R2:0.1221\n",
      "seed: 2, 测试集: B0005, epoch:139  , loss:0.0029646135 , MAE:0.1480 , RMSE:0.1676 , RE:0.3945 , R2:0.1306\n",
      "seed: 2, 测试集: B0005, epoch:140  , loss:0.0023297176 , MAE:0.1496 , RMSE:0.1682 , RE:0.3945 , R2:0.1240\n",
      "seed: 2, 测试集: B0005, epoch:141  , loss:0.0010736422 , MAE:0.1492 , RMSE:0.1678 , RE:0.3945 , R2:0.1284\n",
      "seed: 2, 测试集: B0005, epoch:142  , loss:0.0035773809 , MAE:0.1482 , RMSE:0.1671 , RE:0.3945 , R2:0.1357\n",
      "seed: 2, 测试集: B0005, epoch:143  , loss:0.0015039725 , MAE:0.1493 , RMSE:0.1678 , RE:0.3945 , R2:0.1281\n",
      "seed: 2, 测试集: B0005, epoch:144  , loss:0.0020514126 , MAE:0.1485 , RMSE:0.1671 , RE:0.3945 , R2:0.1361\n",
      "seed: 2, 测试集: B0005, epoch:145  , loss:0.0040146885 , MAE:0.1477 , RMSE:0.1665 , RE:0.3945 , R2:0.1420\n",
      "seed: 2, 测试集: B0005, epoch:146  , loss:0.0044267643 , MAE:0.1485 , RMSE:0.1670 , RE:0.3945 , R2:0.1364\n",
      "seed: 2, 测试集: B0005, epoch:147  , loss:0.0028166543 , MAE:0.1474 , RMSE:0.1661 , RE:0.3945 , R2:0.1459\n",
      "seed: 2, 测试集: B0005, epoch:148  , loss:0.0004660363 , MAE:0.1471 , RMSE:0.1658 , RE:0.3945 , R2:0.1490\n",
      "seed: 2, 测试集: B0005, epoch:149  , loss:0.0043134852 , MAE:0.1493 , RMSE:0.1678 , RE:0.3945 , R2:0.1289\n",
      "seed: 2, 测试集: B0005, epoch:150  , loss:0.0030836700 , MAE:0.1463 , RMSE:0.1652 , RE:0.3945 , R2:0.1547\n",
      "seed: 2, 测试集: B0005, epoch:151  , loss:0.0065980181 , MAE:0.1471 , RMSE:0.1655 , RE:0.3945 , R2:0.1522\n",
      "seed: 2, 测试集: B0005, epoch:152  , loss:0.0064427378 , MAE:0.1457 , RMSE:0.1648 , RE:0.3945 , R2:0.1594\n",
      "seed: 2, 测试集: B0005, epoch:153  , loss:0.0024337061 , MAE:0.1466 , RMSE:0.1650 , RE:0.3945 , R2:0.1577\n",
      "seed: 2, 测试集: B0005, epoch:154  , loss:0.0034985307 , MAE:0.1461 , RMSE:0.1645 , RE:0.3945 , R2:0.1624\n",
      "seed: 2, 测试集: B0005, epoch:155  , loss:0.0022756604 , MAE:0.1451 , RMSE:0.1640 , RE:0.3945 , R2:0.1678\n",
      "seed: 2, 测试集: B0005, epoch:156  , loss:0.0011336589 , MAE:0.1472 , RMSE:0.1654 , RE:0.3945 , R2:0.1531\n",
      "seed: 2, 测试集: B0005, epoch:157  , loss:0.0048521403 , MAE:0.1458 , RMSE:0.1640 , RE:0.3945 , R2:0.1677\n",
      "seed: 2, 测试集: B0005, epoch:158  , loss:0.0051512704 , MAE:0.1449 , RMSE:0.1633 , RE:0.3945 , R2:0.1749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:159  , loss:0.0006535046 , MAE:0.1451 , RMSE:0.1632 , RE:0.3945 , R2:0.1752\n",
      "seed: 2, 测试集: B0005, epoch:160  , loss:0.0035239821 , MAE:0.1445 , RMSE:0.1627 , RE:0.3945 , R2:0.1802\n",
      "seed: 2, 测试集: B0005, epoch:161  , loss:0.0021648502 , MAE:0.1444 , RMSE:0.1625 , RE:0.3945 , R2:0.1823\n",
      "seed: 2, 测试集: B0005, epoch:162  , loss:0.0038713771 , MAE:0.1435 , RMSE:0.1619 , RE:0.3945 , R2:0.1883\n",
      "seed: 2, 测试集: B0005, epoch:163  , loss:0.0023795320 , MAE:0.1440 , RMSE:0.1620 , RE:0.3945 , R2:0.1873\n",
      "seed: 2, 测试集: B0005, epoch:164  , loss:0.0010959913 , MAE:0.1426 , RMSE:0.1613 , RE:0.3945 , R2:0.1943\n",
      "seed: 2, 测试集: B0005, epoch:165  , loss:0.0008619931 , MAE:0.1443 , RMSE:0.1621 , RE:0.3945 , R2:0.1866\n",
      "seed: 2, 测试集: B0005, epoch:166  , loss:0.0006628426 , MAE:0.1424 , RMSE:0.1607 , RE:0.3945 , R2:0.2010\n",
      "seed: 2, 测试集: B0005, epoch:167  , loss:0.0016768090 , MAE:0.1418 , RMSE:0.1605 , RE:0.3945 , R2:0.2022\n",
      "seed: 2, 测试集: B0005, epoch:168  , loss:0.0008179107 , MAE:0.1438 , RMSE:0.1616 , RE:0.3945 , R2:0.1919\n",
      "seed: 2, 测试集: B0005, epoch:169  , loss:0.0004993576 , MAE:0.1417 , RMSE:0.1597 , RE:0.3945 , R2:0.2106\n",
      "seed: 2, 测试集: B0005, epoch:170  , loss:0.0015200572 , MAE:0.1413 , RMSE:0.1593 , RE:0.3945 , R2:0.2144\n",
      "seed: 2, 测试集: B0005, epoch:171  , loss:0.0009719962 , MAE:0.1422 , RMSE:0.1598 , RE:0.3945 , R2:0.2093\n",
      "seed: 2, 测试集: B0005, epoch:172  , loss:0.0007272543 , MAE:0.1403 , RMSE:0.1585 , RE:0.3945 , R2:0.2226\n",
      "seed: 2, 测试集: B0005, epoch:173  , loss:0.0035245838 , MAE:0.1401 , RMSE:0.1581 , RE:0.3945 , R2:0.2266\n",
      "seed: 2, 测试集: B0005, epoch:174  , loss:0.0012991135 , MAE:0.1405 , RMSE:0.1580 , RE:0.3945 , R2:0.2267\n",
      "seed: 2, 测试集: B0005, epoch:175  , loss:0.0016195457 , MAE:0.1397 , RMSE:0.1573 , RE:0.3945 , R2:0.2340\n",
      "seed: 2, 测试集: B0005, epoch:176  , loss:0.0012650847 , MAE:0.1389 , RMSE:0.1585 , RE:0.3945 , R2:0.2223\n",
      "seed: 2, 测试集: B0005, epoch:177  , loss:0.0002273987 , MAE:0.1434 , RMSE:0.1618 , RE:0.3945 , R2:0.1901\n",
      "seed: 2, 测试集: B0005, epoch:178  , loss:0.0033414846 , MAE:0.1390 , RMSE:0.1562 , RE:0.3945 , R2:0.2443\n",
      "seed: 2, 测试集: B0005, epoch:179  , loss:0.0004609913 , MAE:0.1376 , RMSE:0.1550 , RE:0.3945 , R2:0.2564\n",
      "seed: 2, 测试集: B0005, epoch:180  , loss:0.0012328696 , MAE:0.1376 , RMSE:0.1548 , RE:0.3945 , R2:0.2578\n",
      "seed: 2, 测试集: B0005, epoch:181  , loss:0.0002781210 , MAE:0.1374 , RMSE:0.1545 , RE:0.3945 , R2:0.2609\n",
      "seed: 2, 测试集: B0005, epoch:182  , loss:0.0004953749 , MAE:0.1360 , RMSE:0.1539 , RE:0.3945 , R2:0.2666\n",
      "seed: 2, 测试集: B0005, epoch:183  , loss:0.0001269630 , MAE:0.1367 , RMSE:0.1537 , RE:0.3945 , R2:0.2690\n",
      "seed: 2, 测试集: B0005, epoch:184  , loss:0.0007939345 , MAE:0.1372 , RMSE:0.1542 , RE:0.3945 , R2:0.2641\n",
      "seed: 2, 测试集: B0005, epoch:185  , loss:0.0005920768 , MAE:0.1346 , RMSE:0.1518 , RE:0.3945 , R2:0.2864\n",
      "seed: 2, 测试集: B0005, epoch:186  , loss:0.0005938151 , MAE:0.1352 , RMSE:0.1520 , RE:0.3945 , R2:0.2844\n",
      "seed: 2, 测试集: B0005, epoch:187  , loss:0.0006707679 , MAE:0.1337 , RMSE:0.1511 , RE:0.3945 , R2:0.2930\n",
      "seed: 2, 测试集: B0005, epoch:188  , loss:0.0013717785 , MAE:0.1338 , RMSE:0.1505 , RE:0.3945 , R2:0.2989\n",
      "seed: 2, 测试集: B0005, epoch:189  , loss:0.0003149347 , MAE:0.1340 , RMSE:0.1507 , RE:0.3945 , R2:0.2969\n",
      "seed: 2, 测试集: B0005, epoch:190  , loss:0.0005342304 , MAE:0.1346 , RMSE:0.1555 , RE:0.3945 , R2:0.2516\n",
      "seed: 2, 测试集: B0005, epoch:191  , loss:0.0018309038 , MAE:0.1320 , RMSE:0.1485 , RE:0.3945 , R2:0.3174\n",
      "seed: 2, 测试集: B0005, epoch:192  , loss:0.0007416278 , MAE:0.1378 , RMSE:0.1563 , RE:0.3945 , R2:0.2433\n",
      "seed: 2, 测试集: B0005, epoch:193  , loss:0.0061168866 , MAE:0.1307 , RMSE:0.1484 , RE:0.3945 , R2:0.3180\n",
      "seed: 2, 测试集: B0005, epoch:194  , loss:0.0003727450 , MAE:0.1299 , RMSE:0.1466 , RE:0.3945 , R2:0.3349\n",
      "seed: 2, 测试集: B0005, epoch:195  , loss:0.0007028844 , MAE:0.1323 , RMSE:0.1491 , RE:0.3945 , R2:0.3122\n",
      "seed: 2, 测试集: B0005, epoch:196  , loss:0.0004362059 , MAE:0.1290 , RMSE:0.1463 , RE:0.3945 , R2:0.3375\n",
      "seed: 2, 测试集: B0005, epoch:197  , loss:0.0009163289 , MAE:0.1301 , RMSE:0.1465 , RE:0.3945 , R2:0.3358\n",
      "seed: 2, 测试集: B0005, epoch:198  , loss:0.0007087947 , MAE:0.1280 , RMSE:0.1439 , RE:0.3945 , R2:0.3587\n",
      "seed: 2, 测试集: B0005, epoch:199  , loss:0.0013319402 , MAE:0.1355 , RMSE:0.1545 , RE:0.3945 , R2:0.2607\n",
      "seed: 2, 测试集: B0005, epoch:200  , loss:0.0006655378 , MAE:0.1298 , RMSE:0.1508 , RE:0.3945 , R2:0.2957\n",
      "以电池 B0006 为测试数据的 数据集 开始训练\n",
      "seed: 2, 测试集: B0006, epoch:1    , loss:1.6973125935 , MAE:1.3476 , RMSE:1.3655 , RE:0.9892 , R2:-37.2355\n",
      "seed: 2, 测试集: B0006, epoch:2    , loss:1.6699688435 , MAE:1.3350 , RMSE:1.3530 , RE:0.9892 , R2:-36.5404\n",
      "seed: 2, 测试集: B0006, epoch:3    , loss:2.0205042362 , MAE:1.3219 , RMSE:1.3401 , RE:0.9892 , R2:-35.8246\n",
      "seed: 2, 测试集: B0006, epoch:4    , loss:1.7668442726 , MAE:1.3080 , RMSE:1.3264 , RE:0.9892 , R2:-35.0763\n",
      "seed: 2, 测试集: B0006, epoch:5    , loss:2.1256706715 , MAE:1.2934 , RMSE:1.3119 , RE:0.9892 , R2:-34.2919\n",
      "seed: 2, 测试集: B0006, epoch:6    , loss:1.7050342560 , MAE:1.2776 , RMSE:1.2963 , RE:0.9892 , R2:-33.4587\n",
      "seed: 2, 测试集: B0006, epoch:7    , loss:2.0106148720 , MAE:1.2607 , RMSE:1.2795 , RE:0.9892 , R2:-32.5726\n",
      "seed: 2, 测试集: B0006, epoch:8    , loss:1.5241199732 , MAE:1.2421 , RMSE:1.2612 , RE:0.9892 , R2:-31.6180\n",
      "seed: 2, 测试集: B0006, epoch:9    , loss:1.3454841375 , MAE:1.2218 , RMSE:1.2412 , RE:0.9892 , R2:-30.5894\n",
      "seed: 2, 测试集: B0006, epoch:10   , loss:1.1017738581 , MAE:1.1992 , RMSE:1.2187 , RE:0.9892 , R2:-29.4579\n",
      "seed: 2, 测试集: B0006, epoch:11   , loss:1.1570529938 , MAE:1.1736 , RMSE:1.1935 , RE:0.9892 , R2:-28.2086\n",
      "seed: 2, 测试集: B0006, epoch:12   , loss:0.8826223612 , MAE:1.1446 , RMSE:1.1648 , RE:0.9892 , R2:-26.8231\n",
      "seed: 2, 测试集: B0006, epoch:13   , loss:0.9394459128 , MAE:1.1116 , RMSE:1.1322 , RE:0.9892 , R2:-25.2887\n",
      "seed: 2, 测试集: B0006, epoch:14   , loss:1.0831916332 , MAE:1.0739 , RMSE:1.0951 , RE:0.9892 , R2:-23.5914\n",
      "seed: 2, 测试集: B0006, epoch:15   , loss:0.8417282104 , MAE:1.0302 , RMSE:1.0520 , RE:0.9892 , R2:-21.6929\n",
      "seed: 2, 测试集: B0006, epoch:16   , loss:0.6808806658 , MAE:0.9794 , RMSE:1.0020 , RE:0.9892 , R2:-19.5869\n",
      "seed: 2, 测试集: B0006, epoch:17   , loss:0.3785420060 , MAE:0.9216 , RMSE:0.9452 , RE:0.9892 , R2:-17.3211\n",
      "seed: 2, 测试集: B0006, epoch:18   , loss:0.4636092782 , MAE:0.8509 , RMSE:0.8759 , RE:0.9892 , R2:-14.7329\n",
      "seed: 2, 测试集: B0006, epoch:19   , loss:0.3564904928 , MAE:0.7667 , RMSE:0.7939 , RE:0.9892 , R2:-11.9244\n",
      "seed: 2, 测试集: B0006, epoch:20   , loss:0.2452460676 , MAE:0.6689 , RMSE:0.6995 , RE:0.9892 , R2:-9.0334\n",
      "seed: 2, 测试集: B0006, epoch:21   , loss:0.1777576357 , MAE:0.5603 , RMSE:0.5959 , RE:0.9892 , R2:-6.2825\n",
      "seed: 2, 测试集: B0006, epoch:22   , loss:0.0878060907 , MAE:0.4440 , RMSE:0.4876 , RE:0.9785 , R2:-3.8763\n",
      "seed: 2, 测试集: B0006, epoch:23   , loss:0.0814652443 , MAE:0.3273 , RMSE:0.3839 , RE:0.9570 , R2:-2.0219\n",
      "seed: 2, 测试集: B0006, epoch:24   , loss:0.0106898900 , MAE:0.2252 , RMSE:0.2854 , RE:0.9140 , R2:-0.6698\n",
      "seed: 2, 测试集: B0006, epoch:25   , loss:0.0089796400 , MAE:0.1772 , RMSE:0.2238 , RE:0.7527 , R2:-0.0271\n",
      "seed: 2, 测试集: B0006, epoch:26   , loss:0.0015127014 , MAE:0.1702 , RMSE:0.2039 , RE:0.6344 , R2:0.1471\n",
      "seed: 2, 测试集: B0006, epoch:27   , loss:0.0018904514 , MAE:0.1783 , RMSE:0.2065 , RE:0.6344 , R2:0.1256\n",
      "seed: 2, 测试集: B0006, epoch:28   , loss:0.0049247434 , MAE:0.1854 , RMSE:0.2120 , RE:0.6344 , R2:0.0784\n",
      "seed: 2, 测试集: B0006, epoch:29   , loss:0.0019815378 , MAE:0.1889 , RMSE:0.2152 , RE:0.6344 , R2:0.0506\n",
      "seed: 2, 测试集: B0006, epoch:30   , loss:0.0071038613 , MAE:0.1904 , RMSE:0.2166 , RE:0.6344 , R2:0.0378\n",
      "seed: 2, 测试集: B0006, epoch:31   , loss:0.0042234603 , MAE:0.1911 , RMSE:0.2173 , RE:0.6344 , R2:0.0313\n",
      "seed: 2, 测试集: B0006, epoch:32   , loss:0.0046993061 , MAE:0.1908 , RMSE:0.2170 , RE:0.6344 , R2:0.0340\n",
      "seed: 2, 测试集: B0006, epoch:33   , loss:0.0036220665 , MAE:0.1901 , RMSE:0.2163 , RE:0.6344 , R2:0.0403\n",
      "seed: 2, 测试集: B0006, epoch:34   , loss:0.0050503071 , MAE:0.1889 , RMSE:0.2152 , RE:0.6344 , R2:0.0507\n",
      "seed: 2, 测试集: B0006, epoch:35   , loss:0.0037393027 , MAE:0.1895 , RMSE:0.2157 , RE:0.6344 , R2:0.0459\n",
      "seed: 2, 测试集: B0006, epoch:36   , loss:0.0051719439 , MAE:0.1909 , RMSE:0.2171 , RE:0.6344 , R2:0.0337\n",
      "seed: 2, 测试集: B0006, epoch:37   , loss:0.0040501850 , MAE:0.1925 , RMSE:0.2187 , RE:0.6344 , R2:0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0006, epoch:38   , loss:0.0047861193 , MAE:0.1902 , RMSE:0.2164 , RE:0.6344 , R2:0.0397\n",
      "seed: 2, 测试集: B0006, epoch:39   , loss:0.0064198612 , MAE:0.1892 , RMSE:0.2154 , RE:0.6344 , R2:0.0484\n",
      "seed: 2, 测试集: B0006, epoch:40   , loss:0.0065839523 , MAE:0.1901 , RMSE:0.2163 , RE:0.6344 , R2:0.0403\n",
      "seed: 2, 测试集: B0006, epoch:41   , loss:0.0060791317 , MAE:0.1914 , RMSE:0.2177 , RE:0.6344 , R2:0.0285\n",
      "seed: 2, 测试集: B0006, epoch:42   , loss:0.0051659653 , MAE:0.1919 , RMSE:0.2181 , RE:0.6344 , R2:0.0248\n",
      "seed: 2, 测试集: B0006, epoch:43   , loss:0.0050386256 , MAE:0.1897 , RMSE:0.2159 , RE:0.6344 , R2:0.0440\n",
      "seed: 2, 测试集: B0006, epoch:44   , loss:0.0021292744 , MAE:0.1900 , RMSE:0.2163 , RE:0.6344 , R2:0.0408\n",
      "seed: 2, 测试集: B0006, epoch:45   , loss:0.0064258147 , MAE:0.1910 , RMSE:0.2172 , RE:0.6344 , R2:0.0322\n",
      "seed: 2, 测试集: B0006, epoch:46   , loss:0.0044035469 , MAE:0.1923 , RMSE:0.2185 , RE:0.6344 , R2:0.0208\n",
      "seed: 2, 测试集: B0006, epoch:47   , loss:0.0033212502 , MAE:0.1927 , RMSE:0.2189 , RE:0.6344 , R2:0.0171\n",
      "seed: 2, 测试集: B0006, epoch:48   , loss:0.0045077084 , MAE:0.1909 , RMSE:0.2171 , RE:0.6344 , R2:0.0336\n",
      "seed: 2, 测试集: B0006, epoch:49   , loss:0.0043919343 , MAE:0.1897 , RMSE:0.2159 , RE:0.6344 , R2:0.0438\n",
      "seed: 2, 测试集: B0006, epoch:50   , loss:0.0018370250 , MAE:0.1899 , RMSE:0.2162 , RE:0.6344 , R2:0.0419\n",
      "seed: 2, 测试集: B0006, epoch:51   , loss:0.0046545309 , MAE:0.1892 , RMSE:0.2154 , RE:0.6344 , R2:0.0485\n",
      "seed: 2, 测试集: B0006, epoch:52   , loss:0.0024766922 , MAE:0.1883 , RMSE:0.2146 , RE:0.6344 , R2:0.0557\n",
      "seed: 2, 测试集: B0006, epoch:53   , loss:0.0037146208 , MAE:0.1887 , RMSE:0.2150 , RE:0.6344 , R2:0.0523\n",
      "seed: 2, 测试集: B0006, epoch:54   , loss:0.0098702908 , MAE:0.1889 , RMSE:0.2151 , RE:0.6344 , R2:0.0508\n",
      "seed: 2, 测试集: B0006, epoch:55   , loss:0.0048264507 , MAE:0.1901 , RMSE:0.2163 , RE:0.6344 , R2:0.0408\n",
      "seed: 2, 测试集: B0006, epoch:56   , loss:0.0073291697 , MAE:0.1907 , RMSE:0.2169 , RE:0.6344 , R2:0.0356\n",
      "seed: 2, 测试集: B0006, epoch:57   , loss:0.0062822602 , MAE:0.1907 , RMSE:0.2169 , RE:0.6344 , R2:0.0356\n",
      "seed: 2, 测试集: B0006, epoch:58   , loss:0.0033025111 , MAE:0.1917 , RMSE:0.2179 , RE:0.6344 , R2:0.0263\n",
      "seed: 2, 测试集: B0006, epoch:59   , loss:0.0091457423 , MAE:0.1910 , RMSE:0.2172 , RE:0.6344 , R2:0.0325\n",
      "seed: 2, 测试集: B0006, epoch:60   , loss:0.0029441125 , MAE:0.1915 , RMSE:0.2177 , RE:0.6344 , R2:0.0284\n",
      "seed: 2, 测试集: B0006, epoch:61   , loss:0.0084728040 , MAE:0.1908 , RMSE:0.2170 , RE:0.6344 , R2:0.0346\n",
      "seed: 2, 测试集: B0006, epoch:62   , loss:0.0078157373 , MAE:0.1903 , RMSE:0.2165 , RE:0.6344 , R2:0.0386\n",
      "seed: 2, 测试集: B0006, epoch:63   , loss:0.0054544695 , MAE:0.1891 , RMSE:0.2153 , RE:0.6344 , R2:0.0494\n",
      "seed: 2, 测试集: B0006, epoch:64   , loss:0.0046615382 , MAE:0.1888 , RMSE:0.2150 , RE:0.6344 , R2:0.0518\n",
      "seed: 2, 测试集: B0006, epoch:65   , loss:0.0014605654 , MAE:0.1898 , RMSE:0.2160 , RE:0.6344 , R2:0.0431\n",
      "seed: 2, 测试集: B0006, epoch:66   , loss:0.0065272916 , MAE:0.1896 , RMSE:0.2158 , RE:0.6344 , R2:0.0453\n",
      "seed: 2, 测试集: B0006, epoch:67   , loss:0.0056037530 , MAE:0.1887 , RMSE:0.2149 , RE:0.6344 , R2:0.0526\n",
      "seed: 2, 测试集: B0006, epoch:68   , loss:0.0063811820 , MAE:0.1875 , RMSE:0.2137 , RE:0.6344 , R2:0.0632\n",
      "seed: 2, 测试集: B0006, epoch:69   , loss:0.0056870673 , MAE:0.1898 , RMSE:0.2160 , RE:0.6344 , R2:0.0432\n",
      "seed: 2, 测试集: B0006, epoch:70   , loss:0.0044719800 , MAE:0.1883 , RMSE:0.2145 , RE:0.6344 , R2:0.0566\n",
      "seed: 2, 测试集: B0006, epoch:71   , loss:0.0014432480 , MAE:0.1887 , RMSE:0.2149 , RE:0.6344 , R2:0.0528\n",
      "seed: 2, 测试集: B0006, epoch:72   , loss:0.0048716390 , MAE:0.1906 , RMSE:0.2168 , RE:0.6344 , R2:0.0363\n",
      "seed: 2, 测试集: B0006, epoch:73   , loss:0.0072840555 , MAE:0.1910 , RMSE:0.2172 , RE:0.6344 , R2:0.0328\n",
      "seed: 2, 测试集: B0006, epoch:74   , loss:0.0048611183 , MAE:0.1891 , RMSE:0.2153 , RE:0.6344 , R2:0.0493\n",
      "seed: 2, 测试集: B0006, epoch:75   , loss:0.0063466514 , MAE:0.1882 , RMSE:0.2144 , RE:0.6344 , R2:0.0577\n",
      "seed: 2, 测试集: B0006, epoch:76   , loss:0.0017405755 , MAE:0.1862 , RMSE:0.2126 , RE:0.6344 , R2:0.0736\n",
      "seed: 2, 测试集: B0006, epoch:77   , loss:0.0008921410 , MAE:0.1876 , RMSE:0.2138 , RE:0.6344 , R2:0.0626\n",
      "seed: 2, 测试集: B0006, epoch:78   , loss:0.0055460101 , MAE:0.1894 , RMSE:0.2156 , RE:0.6344 , R2:0.0470\n",
      "seed: 2, 测试集: B0006, epoch:79   , loss:0.0096246181 , MAE:0.1881 , RMSE:0.2143 , RE:0.6344 , R2:0.0587\n",
      "seed: 2, 测试集: B0006, epoch:80   , loss:0.0046223905 , MAE:0.1919 , RMSE:0.2181 , RE:0.6344 , R2:0.0249\n",
      "seed: 2, 测试集: B0006, epoch:81   , loss:0.0050218794 , MAE:0.1921 , RMSE:0.2183 , RE:0.6344 , R2:0.0226\n",
      "seed: 2, 测试集: B0006, epoch:82   , loss:0.0038541169 , MAE:0.1882 , RMSE:0.2144 , RE:0.6344 , R2:0.0578\n",
      "seed: 2, 测试集: B0006, epoch:83   , loss:0.0029148001 , MAE:0.1916 , RMSE:0.2178 , RE:0.6344 , R2:0.0276\n",
      "seed: 2, 测试集: B0006, epoch:84   , loss:0.0023532580 , MAE:0.1872 , RMSE:0.2133 , RE:0.6344 , R2:0.0674\n",
      "seed: 2, 测试集: B0006, epoch:85   , loss:0.0038551060 , MAE:0.1868 , RMSE:0.2128 , RE:0.6344 , R2:0.0710\n",
      "seed: 2, 测试集: B0006, epoch:86   , loss:0.0018364212 , MAE:0.1893 , RMSE:0.2154 , RE:0.6344 , R2:0.0483\n",
      "seed: 2, 测试集: B0006, epoch:87   , loss:0.0043908502 , MAE:0.1899 , RMSE:0.2160 , RE:0.6344 , R2:0.0431\n",
      "seed: 2, 测试集: B0006, epoch:88   , loss:0.0016584694 , MAE:0.1861 , RMSE:0.2121 , RE:0.6344 , R2:0.0775\n",
      "seed: 2, 测试集: B0006, epoch:89   , loss:0.0120155783 , MAE:0.1860 , RMSE:0.2120 , RE:0.6344 , R2:0.0780\n",
      "seed: 2, 测试集: B0006, epoch:90   , loss:0.0046330853 , MAE:0.1962 , RMSE:0.2231 , RE:0.6344 , R2:-0.0204\n",
      "seed: 2, 测试集: B0006, epoch:91   , loss:0.0047854390 , MAE:0.1819 , RMSE:0.2080 , RE:0.6344 , R2:0.1125\n",
      "seed: 2, 测试集: B0006, epoch:92   , loss:0.0093110548 , MAE:0.1891 , RMSE:0.2153 , RE:0.6344 , R2:0.0497\n",
      "seed: 2, 测试集: B0006, epoch:93   , loss:0.0025001855 , MAE:0.1876 , RMSE:0.2137 , RE:0.6344 , R2:0.0637\n",
      "seed: 2, 测试集: B0006, epoch:94   , loss:0.0031827083 , MAE:0.1890 , RMSE:0.2151 , RE:0.6344 , R2:0.0511\n",
      "seed: 2, 测试集: B0006, epoch:95   , loss:0.0067326031 , MAE:0.1862 , RMSE:0.2122 , RE:0.6344 , R2:0.0767\n",
      "seed: 2, 测试集: B0006, epoch:96   , loss:0.0034153999 , MAE:0.1863 , RMSE:0.2123 , RE:0.6344 , R2:0.0756\n",
      "seed: 2, 测试集: B0006, epoch:97   , loss:0.0008558629 , MAE:0.1838 , RMSE:0.2098 , RE:0.6344 , R2:0.0975\n",
      "seed: 2, 测试集: B0006, epoch:98   , loss:0.0050380407 , MAE:0.1853 , RMSE:0.2113 , RE:0.6344 , R2:0.0847\n",
      "seed: 2, 测试集: B0006, epoch:99   , loss:0.0045663016 , MAE:0.1814 , RMSE:0.2074 , RE:0.6344 , R2:0.1182\n",
      "seed: 2, 测试集: B0006, epoch:100  , loss:0.0021463311 , MAE:0.1842 , RMSE:0.2101 , RE:0.6344 , R2:0.0950\n",
      "seed: 2, 测试集: B0006, epoch:101  , loss:0.0050209807 , MAE:0.1818 , RMSE:0.2077 , RE:0.6344 , R2:0.1155\n",
      "seed: 2, 测试集: B0006, epoch:102  , loss:0.0024785865 , MAE:0.1846 , RMSE:0.2106 , RE:0.6344 , R2:0.0907\n",
      "seed: 2, 测试集: B0006, epoch:103  , loss:0.0054086852 , MAE:0.1829 , RMSE:0.2088 , RE:0.6344 , R2:0.1064\n",
      "seed: 2, 测试集: B0006, epoch:104  , loss:0.0025690622 , MAE:0.1856 , RMSE:0.2116 , RE:0.6344 , R2:0.0817\n",
      "seed: 2, 测试集: B0006, epoch:105  , loss:0.0021854930 , MAE:0.1823 , RMSE:0.2082 , RE:0.6344 , R2:0.1109\n",
      "seed: 2, 测试集: B0006, epoch:106  , loss:0.0028353073 , MAE:0.1810 , RMSE:0.2068 , RE:0.6344 , R2:0.1226\n",
      "seed: 2, 测试集: B0006, epoch:107  , loss:0.0045152917 , MAE:0.1828 , RMSE:0.2088 , RE:0.6344 , R2:0.1062\n",
      "seed: 2, 测试集: B0006, epoch:108  , loss:0.0038440151 , MAE:0.1799 , RMSE:0.2058 , RE:0.6344 , R2:0.1318\n",
      "seed: 2, 测试集: B0006, epoch:109  , loss:0.0033340042 , MAE:0.1796 , RMSE:0.2054 , RE:0.6344 , R2:0.1347\n",
      "seed: 2, 测试集: B0006, epoch:110  , loss:0.0042293635 , MAE:0.1866 , RMSE:0.2131 , RE:0.6344 , R2:0.0687\n",
      "seed: 2, 测试集: B0006, epoch:111  , loss:0.0019264894 , MAE:0.1793 , RMSE:0.2051 , RE:0.6344 , R2:0.1370\n",
      "seed: 2, 测试集: B0006, epoch:112  , loss:0.0013262228 , MAE:0.1809 , RMSE:0.2068 , RE:0.6344 , R2:0.1229\n",
      "seed: 2, 测试集: B0006, epoch:113  , loss:0.0051633255 , MAE:0.1767 , RMSE:0.2025 , RE:0.6344 , R2:0.1589\n",
      "seed: 2, 测试集: B0006, epoch:114  , loss:0.0019893206 , MAE:0.1767 , RMSE:0.2025 , RE:0.6344 , R2:0.1590\n",
      "seed: 2, 测试集: B0006, epoch:115  , loss:0.0007165130 , MAE:0.1759 , RMSE:0.2017 , RE:0.6344 , R2:0.1658\n",
      "seed: 2, 测试集: B0006, epoch:116  , loss:0.0022266896 , MAE:0.1789 , RMSE:0.2048 , RE:0.6344 , R2:0.1399\n",
      "seed: 2, 测试集: B0006, epoch:117  , loss:0.0052340543 , MAE:0.1777 , RMSE:0.2036 , RE:0.6344 , R2:0.1501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0006, epoch:118  , loss:0.0008519098 , MAE:0.1791 , RMSE:0.2051 , RE:0.6344 , R2:0.1373\n",
      "seed: 2, 测试集: B0006, epoch:119  , loss:0.0034241290 , MAE:0.1772 , RMSE:0.2032 , RE:0.6344 , R2:0.1536\n",
      "seed: 2, 测试集: B0006, epoch:120  , loss:0.0020508119 , MAE:0.1754 , RMSE:0.2012 , RE:0.6344 , R2:0.1699\n",
      "seed: 2, 测试集: B0006, epoch:121  , loss:0.0017795360 , MAE:0.1758 , RMSE:0.2017 , RE:0.6344 , R2:0.1657\n",
      "seed: 2, 测试集: B0006, epoch:122  , loss:0.0033637723 , MAE:0.1754 , RMSE:0.2013 , RE:0.6344 , R2:0.1689\n",
      "seed: 2, 测试集: B0006, epoch:123  , loss:0.0013792523 , MAE:0.1805 , RMSE:0.2071 , RE:0.6344 , R2:0.1208\n",
      "seed: 2, 测试集: B0006, epoch:124  , loss:0.0015403880 , MAE:0.1723 , RMSE:0.1980 , RE:0.6344 , R2:0.1960\n",
      "seed: 2, 测试集: B0006, epoch:125  , loss:0.0023327540 , MAE:0.1702 , RMSE:0.1958 , RE:0.6344 , R2:0.2136\n",
      "seed: 2, 测试集: B0006, epoch:126  , loss:0.0029042920 , MAE:0.1736 , RMSE:0.1996 , RE:0.6344 , R2:0.1834\n",
      "seed: 2, 测试集: B0006, epoch:127  , loss:0.0010246158 , MAE:0.1731 , RMSE:0.1990 , RE:0.6344 , R2:0.1877\n",
      "seed: 2, 测试集: B0006, epoch:128  , loss:0.0029220057 , MAE:0.1700 , RMSE:0.1957 , RE:0.6344 , R2:0.2146\n",
      "seed: 2, 测试集: B0006, epoch:129  , loss:0.0040398245 , MAE:0.1731 , RMSE:0.1991 , RE:0.6344 , R2:0.1868\n",
      "seed: 2, 测试集: B0006, epoch:130  , loss:0.0012823381 , MAE:0.1685 , RMSE:0.1942 , RE:0.6344 , R2:0.2270\n",
      "seed: 2, 测试集: B0006, epoch:131  , loss:0.0005443438 , MAE:0.1680 , RMSE:0.1937 , RE:0.6344 , R2:0.2304\n",
      "seed: 2, 测试集: B0006, epoch:132  , loss:0.0022249068 , MAE:0.1681 , RMSE:0.1938 , RE:0.6344 , R2:0.2299\n",
      "seed: 2, 测试集: B0006, epoch:133  , loss:0.0019225100 , MAE:0.1672 , RMSE:0.1929 , RE:0.6344 , R2:0.2368\n",
      "seed: 2, 测试集: B0006, epoch:134  , loss:0.0030937975 , MAE:0.1695 , RMSE:0.1955 , RE:0.6344 , R2:0.2159\n",
      "seed: 2, 测试集: B0006, epoch:135  , loss:0.0004854559 , MAE:0.1673 , RMSE:0.1932 , RE:0.6344 , R2:0.2347\n",
      "seed: 2, 测试集: B0006, epoch:136  , loss:0.0022508944 , MAE:0.1685 , RMSE:0.1946 , RE:0.6344 , R2:0.2237\n",
      "seed: 2, 测试集: B0006, epoch:137  , loss:0.0012058646 , MAE:0.1637 , RMSE:0.1893 , RE:0.6344 , R2:0.2652\n",
      "seed: 2, 测试集: B0006, epoch:138  , loss:0.0009911901 , MAE:0.1657 , RMSE:0.1915 , RE:0.6344 , R2:0.2477\n",
      "seed: 2, 测试集: B0006, epoch:139  , loss:0.0030807329 , MAE:0.1658 , RMSE:0.1918 , RE:0.6344 , R2:0.2454\n",
      "seed: 2, 测试集: B0006, epoch:140  , loss:0.0007012467 , MAE:0.1651 , RMSE:0.1911 , RE:0.6344 , R2:0.2508\n",
      "seed: 2, 测试集: B0006, epoch:141  , loss:0.0003267855 , MAE:0.1653 , RMSE:0.1914 , RE:0.6344 , R2:0.2486\n",
      "seed: 2, 测试集: B0006, epoch:142  , loss:0.0015976250 , MAE:0.1632 , RMSE:0.1891 , RE:0.6344 , R2:0.2667\n",
      "seed: 2, 测试集: B0006, epoch:143  , loss:0.0004669998 , MAE:0.1561 , RMSE:0.1814 , RE:0.6344 , R2:0.3249\n",
      "seed: 2, 测试集: B0006, epoch:144  , loss:0.0004768876 , MAE:0.1667 , RMSE:0.1935 , RE:0.6344 , R2:0.2322\n",
      "seed: 2, 测试集: B0006, epoch:145  , loss:0.0006536248 , MAE:0.1608 , RMSE:0.1867 , RE:0.6344 , R2:0.2854\n",
      "seed: 2, 测试集: B0006, epoch:146  , loss:0.0009732323 , MAE:0.1604 , RMSE:0.1864 , RE:0.6344 , R2:0.2873\n",
      "seed: 2, 测试集: B0006, epoch:147  , loss:0.0015082904 , MAE:0.1539 , RMSE:0.1793 , RE:0.6344 , R2:0.3410\n",
      "seed: 2, 测试集: B0006, epoch:148  , loss:0.0003741525 , MAE:0.1605 , RMSE:0.1868 , RE:0.6344 , R2:0.2848\n",
      "seed: 2, 测试集: B0006, epoch:149  , loss:0.0016300179 , MAE:0.1573 , RMSE:0.1832 , RE:0.6344 , R2:0.3116\n",
      "seed: 2, 测试集: B0006, epoch:150  , loss:0.0011091885 , MAE:0.1564 , RMSE:0.1822 , RE:0.6344 , R2:0.3191\n",
      "seed: 2, 测试集: B0006, epoch:151  , loss:0.0005642832 , MAE:0.1515 , RMSE:0.1770 , RE:0.6344 , R2:0.3578\n",
      "seed: 2, 测试集: B0006, epoch:152  , loss:0.0007364388 , MAE:0.1593 , RMSE:0.1860 , RE:0.6344 , R2:0.2903\n",
      "seed: 2, 测试集: B0006, epoch:153  , loss:0.0024250061 , MAE:0.1518 , RMSE:0.1774 , RE:0.6344 , R2:0.3543\n",
      "seed: 2, 测试集: B0006, epoch:154  , loss:0.0004410903 , MAE:0.1497 , RMSE:0.1752 , RE:0.6344 , R2:0.3707\n",
      "seed: 2, 测试集: B0006, epoch:155  , loss:0.0009176633 , MAE:0.1542 , RMSE:0.1804 , RE:0.6344 , R2:0.3323\n",
      "seed: 2, 测试集: B0006, epoch:156  , loss:0.0005860271 , MAE:0.1497 , RMSE:0.1753 , RE:0.6344 , R2:0.3696\n",
      "seed: 2, 测试集: B0006, epoch:157  , loss:0.0007110895 , MAE:0.1533 , RMSE:0.1796 , RE:0.6344 , R2:0.3383\n",
      "seed: 2, 测试集: B0006, epoch:158  , loss:0.0004518100 , MAE:0.1414 , RMSE:0.1662 , RE:0.6344 , R2:0.4333\n",
      "seed: 2, 测试集: B0006, epoch:159  , loss:0.0009749788 , MAE:0.1639 , RMSE:0.1929 , RE:0.6344 , R2:0.2366\n",
      "seed: 2, 测试集: B0006, epoch:160  , loss:0.0003749744 , MAE:0.1395 , RMSE:0.1643 , RE:0.6344 , R2:0.4466\n",
      "seed: 2, 测试集: B0006, epoch:161  , loss:0.0002841249 , MAE:0.1537 , RMSE:0.1809 , RE:0.6344 , R2:0.3290\n",
      "seed: 2, 测试集: B0006, epoch:162  , loss:0.0002053896 , MAE:0.1364 , RMSE:0.1609 , RE:0.6344 , R2:0.4689\n",
      "seed: 2, 测试集: B0006, epoch:163  , loss:0.0013361799 , MAE:0.1485 , RMSE:0.1749 , RE:0.6344 , R2:0.3729\n",
      "seed: 2, 测试集: B0006, epoch:164  , loss:0.0004329011 , MAE:0.1318 , RMSE:0.1559 , RE:0.6344 , R2:0.5018\n",
      "seed: 2, 测试集: B0006, epoch:165  , loss:0.0007488861 , MAE:0.1487 , RMSE:0.1755 , RE:0.6344 , R2:0.3683\n",
      "seed: 2, 测试集: B0006, epoch:166  , loss:0.0008328260 , MAE:0.1397 , RMSE:0.1652 , RE:0.6344 , R2:0.4406\n",
      "seed: 2, 测试集: B0006, epoch:167  , loss:0.0001072276 , MAE:0.1520 , RMSE:0.1800 , RE:0.6344 , R2:0.3356\n",
      "seed: 2, 测试集: B0006, epoch:168  , loss:0.0003043864 , MAE:0.1315 , RMSE:0.1559 , RE:0.6344 , R2:0.5015\n",
      "seed: 2, 测试集: B0006, epoch:169  , loss:0.0001811252 , MAE:0.1512 , RMSE:0.1794 , RE:0.6344 , R2:0.3402\n",
      "seed: 2, 测试集: B0006, epoch:170  , loss:0.0009316939 , MAE:0.1328 , RMSE:0.1576 , RE:0.6344 , R2:0.4905\n",
      "seed: 2, 测试集: B0006, epoch:171  , loss:0.0001009019 , MAE:0.1391 , RMSE:0.1650 , RE:0.6344 , R2:0.4417\n",
      "seed: 2, 测试集: B0006, epoch:172  , loss:0.0003907268 , MAE:0.1350 , RMSE:0.1604 , RE:0.6344 , R2:0.4726\n",
      "seed: 2, 测试集: B0006, epoch:173  , loss:0.0004399990 , MAE:0.1338 , RMSE:0.1591 , RE:0.6344 , R2:0.4812\n",
      "seed: 2, 测试集: B0006, epoch:174  , loss:0.0004132666 , MAE:0.1295 , RMSE:0.1542 , RE:0.6344 , R2:0.5125\n",
      "seed: 2, 测试集: B0006, epoch:175  , loss:0.0004949026 , MAE:0.1515 , RMSE:0.1807 , RE:0.6344 , R2:0.3303\n",
      "seed: 2, 测试集: B0006, epoch:176  , loss:0.0003096904 , MAE:0.1165 , RMSE:0.1395 , RE:0.6344 , R2:0.6011\n",
      "seed: 2, 测试集: B0006, epoch:177  , loss:0.0004092718 , MAE:0.1506 , RMSE:0.1799 , RE:0.6344 , R2:0.3360\n",
      "seed: 2, 测试集: B0006, epoch:178  , loss:0.0016175909 , MAE:0.1267 , RMSE:0.1514 , RE:0.6344 , R2:0.5300\n",
      "seed: 2, 测试集: B0006, epoch:179  , loss:0.0003901792 , MAE:0.1146 , RMSE:0.1376 , RE:0.6344 , R2:0.6118\n",
      "seed: 2, 测试集: B0006, epoch:180  , loss:0.0004764126 , MAE:0.1507 , RMSE:0.1804 , RE:0.6344 , R2:0.3324\n",
      "seed: 2, 测试集: B0006, epoch:181  , loss:0.0003316198 , MAE:0.1132 , RMSE:0.1362 , RE:0.6344 , R2:0.6197\n",
      "seed: 2, 测试集: B0006, epoch:182  , loss:0.0005325818 , MAE:0.1396 , RMSE:0.1673 , RE:0.6344 , R2:0.4262\n",
      "seed: 2, 测试集: B0006, epoch:183  , loss:0.0014597470 , MAE:0.1159 , RMSE:0.1393 , RE:0.6344 , R2:0.6022\n",
      "seed: 2, 测试集: B0006, epoch:184  , loss:0.0004664230 , MAE:0.1148 , RMSE:0.1381 , RE:0.6344 , R2:0.6092\n",
      "seed: 2, 测试集: B0006, epoch:185  , loss:0.0003838362 , MAE:0.1364 , RMSE:0.1637 , RE:0.6344 , R2:0.4506\n",
      "seed: 2, 测试集: B0006, epoch:186  , loss:0.0004585984 , MAE:0.1036 , RMSE:0.1256 , RE:0.6344 , R2:0.6766\n",
      "seed: 2, 测试集: B0006, epoch:187  , loss:0.0003153692 , MAE:0.1379 , RMSE:0.1654 , RE:0.6344 , R2:0.4388\n",
      "seed: 2, 测试集: B0006, epoch:188  , loss:0.0001977201 , MAE:0.1280 , RMSE:0.1537 , RE:0.6344 , R2:0.5158\n",
      "seed: 2, 测试集: B0006, epoch:189  , loss:0.0002651109 , MAE:0.1075 , RMSE:0.1298 , RE:0.6344 , R2:0.6543\n",
      "seed: 2, 测试集: B0006, epoch:190  , loss:0.0003929607 , MAE:0.1301 , RMSE:0.1564 , RE:0.6344 , R2:0.4986\n",
      "seed: 2, 测试集: B0006, epoch:191  , loss:0.0003256465 , MAE:0.1108 , RMSE:0.1336 , RE:0.6344 , R2:0.6338\n",
      "seed: 2, 测试集: B0006, epoch:192  , loss:0.0001889503 , MAE:0.1071 , RMSE:0.1294 , RE:0.6344 , R2:0.6564\n",
      "seed: 2, 测试集: B0006, epoch:193  , loss:0.0004399978 , MAE:0.1170 , RMSE:0.1408 , RE:0.6344 , R2:0.5934\n",
      "seed: 2, 测试集: B0006, epoch:194  , loss:0.0004189286 , MAE:0.1325 , RMSE:0.1592 , RE:0.6344 , R2:0.4806\n",
      "seed: 2, 测试集: B0006, epoch:195  , loss:0.0012713519 , MAE:0.1152 , RMSE:0.1387 , RE:0.6344 , R2:0.6055\n",
      "seed: 2, 测试集: B0006, epoch:196  , loss:0.0001435085 , MAE:0.0878 , RMSE:0.1081 , RE:0.3656 , R2:0.7606\n",
      "seed: 2, 测试集: B0006, epoch:197  , loss:0.0023244096 , MAE:0.1431 , RMSE:0.1722 , RE:0.6344 , R2:0.3920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0006, epoch:198  , loss:0.0004312881 , MAE:0.0888 , RMSE:0.1092 , RE:0.6344 , R2:0.7554\n",
      "seed: 2, 测试集: B0006, epoch:199  , loss:0.0000296160 , MAE:0.1217 , RMSE:0.1461 , RE:0.6344 , R2:0.5625\n",
      "seed: 2, 测试集: B0006, epoch:200  , loss:0.0000703014 , MAE:0.1018 , RMSE:0.1230 , RE:0.6344 , R2:0.6900\n",
      "以电池 B0007 为测试数据的 数据集 开始训练\n",
      "seed: 2, 测试集: B0007, epoch:1    , loss:2.8886189461 , MAE:1.8311 , RMSE:1.8372 , RE:0.9934 , R2:-149.6960\n",
      "seed: 2, 测试集: B0007, epoch:2    , loss:2.8537638187 , MAE:1.8227 , RMSE:1.8288 , RE:0.9934 , R2:-148.3222\n",
      "seed: 2, 测试集: B0007, epoch:3    , loss:2.4662842751 , MAE:1.8135 , RMSE:1.8196 , RE:0.9934 , R2:-146.8341\n",
      "seed: 2, 测试集: B0007, epoch:4    , loss:3.0973885059 , MAE:1.8036 , RMSE:1.8097 , RE:0.9934 , R2:-145.2334\n",
      "seed: 2, 测试集: B0007, epoch:5    , loss:2.2855286598 , MAE:1.7931 , RMSE:1.7992 , RE:0.9934 , R2:-143.5367\n",
      "seed: 2, 测试集: B0007, epoch:6    , loss:2.3010914326 , MAE:1.7820 , RMSE:1.7882 , RE:0.9934 , R2:-141.7689\n",
      "seed: 2, 测试集: B0007, epoch:7    , loss:2.7075705528 , MAE:1.7703 , RMSE:1.7765 , RE:0.9934 , R2:-139.9132\n",
      "seed: 2, 测试集: B0007, epoch:8    , loss:2.3124890327 , MAE:1.7575 , RMSE:1.7637 , RE:0.9934 , R2:-137.8907\n",
      "seed: 2, 测试集: B0007, epoch:9    , loss:2.3793120384 , MAE:1.7432 , RMSE:1.7494 , RE:0.9934 , R2:-135.6412\n",
      "seed: 2, 测试集: B0007, epoch:10   , loss:2.2828154564 , MAE:1.7270 , RMSE:1.7333 , RE:0.9934 , R2:-133.1353\n",
      "seed: 2, 测试集: B0007, epoch:11   , loss:2.3641982079 , MAE:1.7091 , RMSE:1.7154 , RE:0.9934 , R2:-130.3799\n",
      "seed: 2, 测试集: B0007, epoch:12   , loss:2.0244245529 , MAE:1.6888 , RMSE:1.6951 , RE:0.9934 , R2:-127.2878\n",
      "seed: 2, 测试集: B0007, epoch:13   , loss:1.8586258888 , MAE:1.6647 , RMSE:1.6710 , RE:0.9934 , R2:-123.6643\n",
      "seed: 2, 测试集: B0007, epoch:14   , loss:1.6899755001 , MAE:1.6364 , RMSE:1.6427 , RE:0.9934 , R2:-119.4837\n",
      "seed: 2, 测试集: B0007, epoch:15   , loss:1.4390480518 , MAE:1.6029 , RMSE:1.6093 , RE:0.9934 , R2:-114.6411\n",
      "seed: 2, 测试集: B0007, epoch:16   , loss:1.2322410345 , MAE:1.5623 , RMSE:1.5689 , RE:0.9934 , R2:-108.9024\n",
      "seed: 2, 测试集: B0007, epoch:17   , loss:1.2410334349 , MAE:1.5158 , RMSE:1.5226 , RE:0.9934 , R2:-102.5057\n",
      "seed: 2, 测试集: B0007, epoch:18   , loss:0.7490180731 , MAE:1.4618 , RMSE:1.4689 , RE:0.9934 , R2:-95.3385\n",
      "seed: 2, 测试集: B0007, epoch:19   , loss:0.6846250892 , MAE:1.3994 , RMSE:1.4069 , RE:0.9934 , R2:-87.3803\n",
      "seed: 2, 测试集: B0007, epoch:20   , loss:0.4715668559 , MAE:1.3278 , RMSE:1.3360 , RE:0.9934 , R2:-78.6893\n",
      "seed: 2, 测试集: B0007, epoch:21   , loss:0.4128715396 , MAE:1.2427 , RMSE:1.2517 , RE:0.9934 , R2:-68.9493\n",
      "seed: 2, 测试集: B0007, epoch:22   , loss:0.1997530460 , MAE:1.1324 , RMSE:1.1424 , RE:0.9934 , R2:-57.2716\n",
      "seed: 2, 测试集: B0007, epoch:23   , loss:0.0772858411 , MAE:0.9934 , RMSE:1.0042 , RE:0.9803 , R2:-44.0240\n",
      "seed: 2, 测试集: B0007, epoch:24   , loss:0.0446621440 , MAE:0.8068 , RMSE:0.8183 , RE:0.9671 , R2:-28.9008\n",
      "seed: 2, 测试集: B0007, epoch:25   , loss:0.0158085674 , MAE:0.5930 , RMSE:0.6045 , RE:0.9408 , R2:-15.3130\n",
      "seed: 2, 测试集: B0007, epoch:26   , loss:0.0031678660 , MAE:0.3889 , RMSE:0.4016 , RE:0.8816 , R2:-6.2015\n",
      "seed: 2, 测试集: B0007, epoch:27   , loss:0.0045274007 , MAE:0.2408 , RMSE:0.2570 , RE:0.7566 , R2:-1.9480\n",
      "seed: 2, 测试集: B0007, epoch:28   , loss:0.0003789566 , MAE:0.1462 , RMSE:0.1707 , RE:0.0000 , R2:-0.3016\n",
      "seed: 2, 测试集: B0007, epoch:29   , loss:0.0020278245 , MAE:0.1180 , RMSE:0.1423 , RE:0.0000 , R2:0.0959\n",
      "seed: 2, 测试集: B0007, epoch:30   , loss:0.0003904897 , MAE:0.1133 , RMSE:0.1367 , RE:0.0000 , R2:0.1652\n",
      "seed: 2, 测试集: B0007, epoch:31   , loss:0.0003208708 , MAE:0.1156 , RMSE:0.1394 , RE:0.0000 , R2:0.1318\n",
      "seed: 2, 测试集: B0007, epoch:32   , loss:0.0004331082 , MAE:0.1188 , RMSE:0.1432 , RE:0.0000 , R2:0.0843\n",
      "seed: 2, 测试集: B0007, epoch:33   , loss:0.0009435014 , MAE:0.1167 , RMSE:0.1405 , RE:0.0000 , R2:0.1187\n",
      "seed: 2, 测试集: B0007, epoch:34   , loss:0.0003252253 , MAE:0.1127 , RMSE:0.1358 , RE:0.0000 , R2:0.1767\n",
      "seed: 2, 测试集: B0007, epoch:35   , loss:0.0003946112 , MAE:0.1142 , RMSE:0.1375 , RE:0.0000 , R2:0.1562\n",
      "seed: 2, 测试集: B0007, epoch:36   , loss:0.0008158184 , MAE:0.1180 , RMSE:0.1418 , RE:0.0000 , R2:0.1017\n",
      "seed: 2, 测试集: B0007, epoch:37   , loss:0.0031740968 , MAE:0.1229 , RMSE:0.1469 , RE:0.0000 , R2:0.0365\n",
      "seed: 2, 测试集: B0007, epoch:38   , loss:0.0014257343 , MAE:0.1178 , RMSE:0.1415 , RE:0.0000 , R2:0.1066\n",
      "seed: 2, 测试集: B0007, epoch:39   , loss:0.0002348515 , MAE:0.1144 , RMSE:0.1376 , RE:0.0000 , R2:0.1546\n",
      "seed: 2, 测试集: B0007, epoch:40   , loss:0.0001580266 , MAE:0.1155 , RMSE:0.1387 , RE:0.0000 , R2:0.1410\n",
      "seed: 2, 测试集: B0007, epoch:41   , loss:0.0006325553 , MAE:0.1148 , RMSE:0.1379 , RE:0.0000 , R2:0.1515\n",
      "seed: 2, 测试集: B0007, epoch:42   , loss:0.0001095467 , MAE:0.1194 , RMSE:0.1428 , RE:0.0000 , R2:0.0898\n",
      "seed: 2, 测试集: B0007, epoch:43   , loss:0.0004291138 , MAE:0.1200 , RMSE:0.1433 , RE:0.0000 , R2:0.0826\n",
      "seed: 2, 测试集: B0007, epoch:44   , loss:0.0016019564 , MAE:0.1214 , RMSE:0.1447 , RE:0.0000 , R2:0.0646\n",
      "seed: 2, 测试集: B0007, epoch:45   , loss:0.0002984259 , MAE:0.1155 , RMSE:0.1384 , RE:0.0000 , R2:0.1446\n",
      "seed: 2, 测试集: B0007, epoch:46   , loss:0.0008989103 , MAE:0.1161 , RMSE:0.1390 , RE:0.0000 , R2:0.1379\n",
      "seed: 2, 测试集: B0007, epoch:47   , loss:0.0001169365 , MAE:0.1202 , RMSE:0.1432 , RE:0.0000 , R2:0.0846\n",
      "seed: 2, 测试集: B0007, epoch:48   , loss:0.0011500575 , MAE:0.1201 , RMSE:0.1430 , RE:0.0000 , R2:0.0874\n",
      "seed: 2, 测试集: B0007, epoch:49   , loss:0.0007030845 , MAE:0.1130 , RMSE:0.1354 , RE:0.0000 , R2:0.1814\n",
      "seed: 2, 测试集: B0007, epoch:50   , loss:0.0006469510 , MAE:0.1138 , RMSE:0.1361 , RE:0.0000 , R2:0.1724\n",
      "seed: 2, 测试集: B0007, epoch:51   , loss:0.0004884045 , MAE:0.1204 , RMSE:0.1429 , RE:0.0000 , R2:0.0889\n",
      "seed: 2, 测试集: B0007, epoch:52   , loss:0.0002978674 , MAE:0.1246 , RMSE:0.1467 , RE:0.0000 , R2:0.0388\n",
      "seed: 2, 测试集: B0007, epoch:53   , loss:0.0035113525 , MAE:0.1199 , RMSE:0.1422 , RE:0.0000 , R2:0.0973\n",
      "seed: 2, 测试集: B0007, epoch:54   , loss:0.0002935114 , MAE:0.1057 , RMSE:0.1267 , RE:0.0000 , R2:0.2832\n",
      "seed: 2, 测试集: B0007, epoch:55   , loss:0.0011773148 , MAE:0.1115 , RMSE:0.1333 , RE:0.0000 , R2:0.2069\n",
      "seed: 2, 测试集: B0007, epoch:56   , loss:0.0003103398 , MAE:0.1148 , RMSE:0.1367 , RE:0.0000 , R2:0.1660\n",
      "seed: 2, 测试集: B0007, epoch:57   , loss:0.0000409230 , MAE:0.1187 , RMSE:0.1404 , RE:0.0000 , R2:0.1196\n",
      "seed: 2, 测试集: B0007, epoch:58   , loss:0.0005110894 , MAE:0.1169 , RMSE:0.1386 , RE:0.0000 , R2:0.1423\n",
      "seed: 2, 测试集: B0007, epoch:59   , loss:0.0004961150 , MAE:0.1174 , RMSE:0.1389 , RE:0.0000 , R2:0.1386\n",
      "seed: 2, 测试集: B0007, epoch:60   , loss:0.0044618906 , MAE:0.1182 , RMSE:0.1395 , RE:0.0000 , R2:0.1312\n",
      "seed: 2, 测试集: B0007, epoch:61   , loss:0.0019556510 , MAE:0.1066 , RMSE:0.1275 , RE:0.0000 , R2:0.2747\n",
      "seed: 2, 测试集: B0007, epoch:62   , loss:0.0004737334 , MAE:0.1080 , RMSE:0.1289 , RE:0.0000 , R2:0.2582\n",
      "seed: 2, 测试集: B0007, epoch:63   , loss:0.0004473694 , MAE:0.1149 , RMSE:0.1359 , RE:0.0000 , R2:0.1755\n",
      "seed: 2, 测试集: B0007, epoch:64   , loss:0.0014739899 , MAE:0.1221 , RMSE:0.1425 , RE:0.0000 , R2:0.0937\n",
      "seed: 2, 测试集: B0007, epoch:65   , loss:0.0000899164 , MAE:0.1130 , RMSE:0.1338 , RE:0.0000 , R2:0.2010\n",
      "seed: 2, 测试集: B0007, epoch:66   , loss:0.0003572454 , MAE:0.1176 , RMSE:0.1380 , RE:0.0000 , R2:0.1494\n",
      "seed: 2, 测试集: B0007, epoch:67   , loss:0.0007046411 , MAE:0.1122 , RMSE:0.1327 , RE:0.0000 , R2:0.2132\n",
      "seed: 2, 测试集: B0007, epoch:68   , loss:0.0006880867 , MAE:0.1233 , RMSE:0.1429 , RE:0.0000 , R2:0.0883\n",
      "seed: 2, 测试集: B0007, epoch:69   , loss:0.0009436816 , MAE:0.1234 , RMSE:0.1428 , RE:0.0000 , R2:0.0895\n",
      "seed: 2, 测试集: B0007, epoch:70   , loss:0.0002262612 , MAE:0.1090 , RMSE:0.1292 , RE:0.0000 , R2:0.2548\n",
      "seed: 2, 测试集: B0007, epoch:71   , loss:0.0003818205 , MAE:0.1099 , RMSE:0.1299 , RE:0.0000 , R2:0.2460\n",
      "seed: 2, 测试集: B0007, epoch:72   , loss:0.0000386871 , MAE:0.1242 , RMSE:0.1429 , RE:0.0000 , R2:0.0880\n",
      "seed: 2, 测试集: B0007, epoch:73   , loss:0.0004194417 , MAE:0.1216 , RMSE:0.1404 , RE:0.0000 , R2:0.1196\n",
      "seed: 2, 测试集: B0007, epoch:74   , loss:0.0003513296 , MAE:0.1171 , RMSE:0.1362 , RE:0.0000 , R2:0.1720\n",
      "seed: 2, 测试集: B0007, epoch:75   , loss:0.0001258017 , MAE:0.1175 , RMSE:0.1364 , RE:0.0000 , R2:0.1699\n",
      "seed: 2, 测试集: B0007, epoch:76   , loss:0.0003245047 , MAE:0.1156 , RMSE:0.1344 , RE:0.0000 , R2:0.1931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0007, epoch:77   , loss:0.0002306029 , MAE:0.1281 , RMSE:0.1453 , RE:0.0000 , R2:0.0570\n",
      "seed: 2, 测试集: B0007, epoch:78   , loss:0.0015389491 , MAE:0.1176 , RMSE:0.1359 , RE:0.0000 , R2:0.1753\n",
      "seed: 2, 测试集: B0007, epoch:79   , loss:0.0004910097 , MAE:0.1112 , RMSE:0.1299 , RE:0.0000 , R2:0.2471\n",
      "seed: 2, 测试集: B0007, epoch:80   , loss:0.0014926055 , MAE:0.1193 , RMSE:0.1370 , RE:0.0000 , R2:0.1623\n",
      "seed: 2, 测试集: B0007, epoch:81   , loss:0.0003222115 , MAE:0.1085 , RMSE:0.1270 , RE:0.0000 , R2:0.2793\n",
      "seed: 2, 测试集: B0007, epoch:82   , loss:0.0010247353 , MAE:0.1275 , RMSE:0.1436 , RE:0.0132 , R2:0.0789\n",
      "seed: 2, 测试集: B0007, epoch:83   , loss:0.0049250741 , MAE:0.1176 , RMSE:0.1349 , RE:0.0000 , R2:0.1877\n",
      "seed: 2, 测试集: B0007, epoch:84   , loss:0.0004199821 , MAE:0.1080 , RMSE:0.1260 , RE:0.0000 , R2:0.2912\n",
      "seed: 2, 测试集: B0007, epoch:85   , loss:0.0009750552 , MAE:0.1193 , RMSE:0.1359 , RE:0.0000 , R2:0.1749\n",
      "seed: 2, 测试集: B0007, epoch:86   , loss:0.0000874624 , MAE:0.1294 , RMSE:0.1443 , RE:0.1579 , R2:0.0700\n",
      "seed: 2, 测试集: B0007, epoch:87   , loss:0.0015569369 , MAE:0.1167 , RMSE:0.1332 , RE:0.0000 , R2:0.2079\n",
      "seed: 2, 测试集: B0007, epoch:88   , loss:0.0003499079 , MAE:0.1145 , RMSE:0.1311 , RE:0.0000 , R2:0.2330\n",
      "seed: 2, 测试集: B0007, epoch:89   , loss:0.0009371589 , MAE:0.1155 , RMSE:0.1317 , RE:0.0000 , R2:0.2259\n",
      "seed: 2, 测试集: B0007, epoch:90   , loss:0.0000533700 , MAE:0.1371 , RMSE:0.1502 , RE:0.3026 , R2:-0.0070\n",
      "seed: 2, 测试集: B0007, epoch:91   , loss:0.0039151162 , MAE:0.1176 , RMSE:0.1330 , RE:0.0000 , R2:0.2100\n",
      "seed: 2, 测试集: B0007, epoch:92   , loss:0.0001767187 , MAE:0.0931 , RMSE:0.1103 , RE:0.0000 , R2:0.4566\n",
      "seed: 2, 测试集: B0007, epoch:93   , loss:0.0007799735 , MAE:0.1118 , RMSE:0.1276 , RE:0.0000 , R2:0.2731\n",
      "seed: 2, 测试集: B0007, epoch:94   , loss:0.0017879782 , MAE:0.1140 , RMSE:0.1293 , RE:0.0000 , R2:0.2533\n",
      "seed: 2, 测试集: B0007, epoch:95   , loss:0.0041775908 , MAE:0.1129 , RMSE:0.1282 , RE:0.0000 , R2:0.2667\n",
      "seed: 2, 测试集: B0007, epoch:96   , loss:0.0001758234 , MAE:0.1050 , RMSE:0.1210 , RE:0.0000 , R2:0.3465\n",
      "seed: 2, 测试集: B0007, epoch:97   , loss:0.0002296196 , MAE:0.1265 , RMSE:0.1393 , RE:0.2105 , R2:0.1334\n",
      "seed: 2, 测试集: B0007, epoch:98   , loss:0.0060708430 , MAE:0.1257 , RMSE:0.1385 , RE:0.2105 , R2:0.1438\n",
      "seed: 2, 测试集: B0007, epoch:99   , loss:0.0002773299 , MAE:0.1011 , RMSE:0.1169 , RE:0.0000 , R2:0.3895\n",
      "seed: 2, 测试集: B0007, epoch:100  , loss:0.0006158554 , MAE:0.1277 , RMSE:0.1398 , RE:0.2434 , R2:0.1273\n",
      "seed: 2, 测试集: B0007, epoch:101  , loss:0.0003202667 , MAE:0.1325 , RMSE:0.1439 , RE:0.2961 , R2:0.0754\n",
      "seed: 2, 测试集: B0007, epoch:102  , loss:0.0004021134 , MAE:0.1162 , RMSE:0.1294 , RE:0.0855 , R2:0.2518\n",
      "seed: 2, 测试集: B0007, epoch:103  , loss:0.0008129915 , MAE:0.1131 , RMSE:0.1266 , RE:0.0329 , R2:0.2845\n",
      "seed: 2, 测试集: B0007, epoch:104  , loss:0.0000333991 , MAE:0.1203 , RMSE:0.1326 , RE:0.1776 , R2:0.2155\n",
      "seed: 2, 测试集: B0007, epoch:105  , loss:0.0001920220 , MAE:0.1250 , RMSE:0.1364 , RE:0.2434 , R2:0.1693\n",
      "seed: 2, 测试集: B0007, epoch:106  , loss:0.0001192163 , MAE:0.1260 , RMSE:0.1372 , RE:0.2566 , R2:0.1601\n",
      "seed: 2, 测试集: B0007, epoch:107  , loss:0.0003198263 , MAE:0.1237 , RMSE:0.1349 , RE:0.2368 , R2:0.1869\n",
      "seed: 2, 测试集: B0007, epoch:108  , loss:0.0001099591 , MAE:0.1162 , RMSE:0.1282 , RE:0.1513 , R2:0.2664\n",
      "seed: 2, 测试集: B0007, epoch:109  , loss:0.0002672675 , MAE:0.1245 , RMSE:0.1353 , RE:0.2500 , R2:0.1826\n",
      "seed: 2, 测试集: B0007, epoch:110  , loss:0.0004447871 , MAE:0.1201 , RMSE:0.1312 , RE:0.2105 , R2:0.2317\n",
      "seed: 2, 测试集: B0007, epoch:111  , loss:0.0001693533 , MAE:0.1358 , RMSE:0.1451 , RE:0.3487 , R2:0.0602\n",
      "seed: 2, 测试集: B0007, epoch:112  , loss:0.0010411203 , MAE:0.1178 , RMSE:0.1288 , RE:0.1974 , R2:0.2591\n",
      "seed: 2, 测试集: B0007, epoch:113  , loss:0.0003954839 , MAE:0.1144 , RMSE:0.1257 , RE:0.1645 , R2:0.2946\n",
      "seed: 2, 测试集: B0007, epoch:114  , loss:0.0004046386 , MAE:0.1338 , RMSE:0.1428 , RE:0.3421 , R2:0.0901\n",
      "seed: 2, 测试集: B0007, epoch:115  , loss:0.0011257828 , MAE:0.1208 , RMSE:0.1309 , RE:0.2434 , R2:0.2346\n",
      "seed: 2, 测试集: B0007, epoch:116  , loss:0.0003459529 , MAE:0.1068 , RMSE:0.1185 , RE:0.0724 , R2:0.3726\n",
      "seed: 2, 测试集: B0007, epoch:117  , loss:0.0002523088 , MAE:0.1281 , RMSE:0.1371 , RE:0.3092 , R2:0.1606\n",
      "seed: 2, 测试集: B0007, epoch:118  , loss:0.0000782775 , MAE:0.1201 , RMSE:0.1298 , RE:0.2434 , R2:0.2476\n",
      "seed: 2, 测试集: B0007, epoch:119  , loss:0.0000672302 , MAE:0.1294 , RMSE:0.1380 , RE:0.3158 , R2:0.1497\n",
      "seed: 2, 测试集: B0007, epoch:120  , loss:0.0016444126 , MAE:0.1222 , RMSE:0.1314 , RE:0.2697 , R2:0.2294\n",
      "seed: 2, 测试集: B0007, epoch:121  , loss:0.0019889162 , MAE:0.0947 , RMSE:0.1074 , RE:0.0000 , R2:0.4851\n",
      "seed: 2, 测试集: B0007, epoch:122  , loss:0.0002702035 , MAE:0.1071 , RMSE:0.1176 , RE:0.1316 , R2:0.3821\n",
      "seed: 2, 测试集: B0007, epoch:123  , loss:0.0035262306 , MAE:0.1282 , RMSE:0.1363 , RE:0.3224 , R2:0.1704\n",
      "seed: 2, 测试集: B0007, epoch:124  , loss:0.0059812819 , MAE:0.0945 , RMSE:0.1066 , RE:0.0000 , R2:0.4925\n",
      "seed: 2, 测试集: B0007, epoch:125  , loss:0.0001666118 , MAE:0.0832 , RMSE:0.0966 , RE:0.0000 , R2:0.5831\n",
      "seed: 2, 测试集: B0007, epoch:126  , loss:0.0011437101 , MAE:0.1332 , RMSE:0.1405 , RE:0.3553 , R2:0.1182\n",
      "seed: 2, 测试集: B0007, epoch:127  , loss:0.0001295982 , MAE:0.1246 , RMSE:0.1325 , RE:0.3026 , R2:0.2166\n",
      "seed: 2, 测试集: B0007, epoch:128  , loss:0.0011435433 , MAE:0.1225 , RMSE:0.1304 , RE:0.2895 , R2:0.2411\n",
      "seed: 2, 测试集: B0007, epoch:129  , loss:0.0019634096 , MAE:0.0904 , RMSE:0.1022 , RE:0.0000 , R2:0.5334\n",
      "seed: 2, 测试集: B0007, epoch:130  , loss:0.0002009806 , MAE:0.1223 , RMSE:0.1299 , RE:0.2961 , R2:0.2471\n",
      "seed: 2, 测试集: B0007, epoch:131  , loss:0.0000480557 , MAE:0.1509 , RMSE:0.1567 , RE:0.4342 , R2:-0.0957\n",
      "seed: 2, 测试集: B0007, epoch:132  , loss:0.0001697553 , MAE:0.1201 , RMSE:0.1276 , RE:0.2829 , R2:0.2733\n",
      "seed: 2, 测试集: B0007, epoch:133  , loss:0.0003985200 , MAE:0.1199 , RMSE:0.1272 , RE:0.2829 , R2:0.2774\n",
      "seed: 2, 测试集: B0007, epoch:134  , loss:0.0004899282 , MAE:0.1311 , RMSE:0.1375 , RE:0.3487 , R2:0.1560\n",
      "seed: 2, 测试集: B0007, epoch:135  , loss:0.0003509625 , MAE:0.1240 , RMSE:0.1308 , RE:0.3158 , R2:0.2361\n",
      "seed: 2, 测试集: B0007, epoch:136  , loss:0.0058095134 , MAE:0.1144 , RMSE:0.1218 , RE:0.2566 , R2:0.3374\n",
      "seed: 2, 测试集: B0007, epoch:137  , loss:0.0001736115 , MAE:0.1116 , RMSE:0.1192 , RE:0.2368 , R2:0.3653\n",
      "seed: 2, 测试集: B0007, epoch:138  , loss:0.0001605143 , MAE:0.1253 , RMSE:0.1316 , RE:0.3224 , R2:0.2266\n",
      "seed: 2, 测试集: B0007, epoch:139  , loss:0.0059823394 , MAE:0.1322 , RMSE:0.1380 , RE:0.3618 , R2:0.1503\n",
      "seed: 2, 测试集: B0007, epoch:140  , loss:0.0003290300 , MAE:0.0873 , RMSE:0.0977 , RE:0.0066 , R2:0.5737\n",
      "seed: 2, 测试集: B0007, epoch:141  , loss:0.0040809428 , MAE:0.1306 , RMSE:0.1363 , RE:0.3553 , R2:0.1702\n",
      "seed: 2, 测试集: B0007, epoch:142  , loss:0.0000628743 , MAE:0.1048 , RMSE:0.1124 , RE:0.1974 , R2:0.4357\n",
      "seed: 2, 测试集: B0007, epoch:143  , loss:0.0000854024 , MAE:0.1260 , RMSE:0.1317 , RE:0.3355 , R2:0.2252\n",
      "seed: 2, 测试集: B0007, epoch:144  , loss:0.0002749946 , MAE:0.1317 , RMSE:0.1370 , RE:0.3618 , R2:0.1619\n",
      "seed: 2, 测试集: B0007, epoch:145  , loss:0.0002359663 , MAE:0.1395 , RMSE:0.1444 , RE:0.3947 , R2:0.0686\n",
      "seed: 2, 测试集: B0007, epoch:146  , loss:0.0001752665 , MAE:0.1141 , RMSE:0.1204 , RE:0.2697 , R2:0.3529\n",
      "seed: 2, 测试集: B0007, epoch:147  , loss:0.0000412021 , MAE:0.1160 , RMSE:0.1220 , RE:0.2829 , R2:0.3355\n",
      "seed: 2, 测试集: B0007, epoch:148  , loss:0.0054088021 , MAE:0.1157 , RMSE:0.1216 , RE:0.2829 , R2:0.3394\n",
      "seed: 2, 测试集: B0007, epoch:149  , loss:0.0004310540 , MAE:0.0675 , RMSE:0.0796 , RE:0.0000 , R2:0.7173\n",
      "seed: 2, 测试集: B0007, epoch:150  , loss:0.0000410223 , MAE:0.1559 , RMSE:0.1600 , RE:0.4539 , R2:-0.1432\n",
      "seed: 2, 测试集: B0007, epoch:151  , loss:0.0001613804 , MAE:0.1173 , RMSE:0.1227 , RE:0.2961 , R2:0.3273\n",
      "seed: 2, 测试集: B0007, epoch:152  , loss:0.0003231362 , MAE:0.1173 , RMSE:0.1226 , RE:0.2961 , R2:0.3285\n",
      "seed: 2, 测试集: B0007, epoch:153  , loss:0.0006213113 , MAE:0.1328 , RMSE:0.1373 , RE:0.3684 , R2:0.1586\n",
      "seed: 2, 测试集: B0007, epoch:154  , loss:0.0001230861 , MAE:0.1065 , RMSE:0.1125 , RE:0.2368 , R2:0.4352\n",
      "seed: 2, 测试集: B0007, epoch:155  , loss:0.0021940176 , MAE:0.1299 , RMSE:0.1343 , RE:0.3618 , R2:0.1943\n",
      "seed: 2, 测试集: B0007, epoch:156  , loss:0.0002078503 , MAE:0.1006 , RMSE:0.1069 , RE:0.2039 , R2:0.4897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0007, epoch:157  , loss:0.0005897949 , MAE:0.1468 , RMSE:0.1507 , RE:0.4211 , R2:-0.0137\n",
      "seed: 2, 测试集: B0007, epoch:158  , loss:0.0034667233 , MAE:0.1131 , RMSE:0.1181 , RE:0.2829 , R2:0.3773\n",
      "seed: 2, 测试集: B0007, epoch:159  , loss:0.0001789146 , MAE:0.1114 , RMSE:0.1164 , RE:0.2763 , R2:0.3949\n",
      "seed: 2, 测试集: B0007, epoch:160  , loss:0.0001173135 , MAE:0.1300 , RMSE:0.1341 , RE:0.3618 , R2:0.1977\n",
      "seed: 2, 测试集: B0007, epoch:161  , loss:0.0000999081 , MAE:0.1362 , RMSE:0.1400 , RE:0.3882 , R2:0.1243\n",
      "seed: 2, 测试集: B0007, epoch:162  , loss:0.0002470574 , MAE:0.1258 , RMSE:0.1299 , RE:0.3487 , R2:0.2466\n",
      "seed: 2, 测试集: B0007, epoch:163  , loss:0.0000894404 , MAE:0.1262 , RMSE:0.1302 , RE:0.3487 , R2:0.2433\n",
      "seed: 2, 测试集: B0007, epoch:164  , loss:0.0002082249 , MAE:0.1312 , RMSE:0.1350 , RE:0.3684 , R2:0.1859\n",
      "seed: 2, 测试集: B0007, epoch:165  , loss:0.0004050136 , MAE:0.1136 , RMSE:0.1180 , RE:0.2961 , R2:0.3786\n",
      "seed: 2, 测试集: B0007, epoch:166  , loss:0.0005265257 , MAE:0.1241 , RMSE:0.1280 , RE:0.3421 , R2:0.2688\n",
      "seed: 2, 测试集: B0007, epoch:167  , loss:0.0008284816 , MAE:0.1009 , RMSE:0.1059 , RE:0.2303 , R2:0.4996\n",
      "seed: 2, 测试集: B0007, epoch:168  , loss:0.0011370985 , MAE:0.0971 , RMSE:0.1023 , RE:0.2105 , R2:0.5325\n",
      "seed: 2, 测试集: B0007, epoch:169  , loss:0.0002523787 , MAE:0.1273 , RMSE:0.1309 , RE:0.3553 , R2:0.2351\n",
      "seed: 2, 测试集: B0007, epoch:170  , loss:0.0018494648 , MAE:0.1333 , RMSE:0.1367 , RE:0.3750 , R2:0.1660\n",
      "seed: 2, 测试集: B0007, epoch:171  , loss:0.0003371026 , MAE:0.0982 , RMSE:0.1030 , RE:0.2237 , R2:0.5261\n",
      "seed: 2, 测试集: B0007, epoch:172  , loss:0.0004269861 , MAE:0.1257 , RMSE:0.1291 , RE:0.3487 , R2:0.2562\n",
      "seed: 2, 测试集: B0007, epoch:173  , loss:0.0013754189 , MAE:0.1153 , RMSE:0.1189 , RE:0.3092 , R2:0.3686\n",
      "seed: 2, 测试集: B0007, epoch:174  , loss:0.0001382695 , MAE:0.1228 , RMSE:0.1262 , RE:0.3421 , R2:0.2892\n",
      "seed: 2, 测试集: B0007, epoch:175  , loss:0.0000864522 , MAE:0.1386 , RMSE:0.1417 , RE:0.3947 , R2:0.1038\n",
      "seed: 2, 测试集: B0007, epoch:176  , loss:0.0015048165 , MAE:0.1012 , RMSE:0.1054 , RE:0.2434 , R2:0.5042\n",
      "seed: 2, 测试集: B0007, epoch:177  , loss:0.0002144003 , MAE:0.1139 , RMSE:0.1174 , RE:0.3092 , R2:0.3848\n",
      "seed: 2, 测试集: B0007, epoch:178  , loss:0.0011965077 , MAE:0.1212 , RMSE:0.1244 , RE:0.3355 , R2:0.3089\n",
      "seed: 2, 测试集: B0007, epoch:179  , loss:0.0002162942 , MAE:0.1003 , RMSE:0.1043 , RE:0.2434 , R2:0.5147\n",
      "seed: 2, 测试集: B0007, epoch:180  , loss:0.0002443880 , MAE:0.1382 , RMSE:0.1411 , RE:0.3947 , R2:0.1107\n",
      "seed: 2, 测试集: B0007, epoch:181  , loss:0.0001058393 , MAE:0.1408 , RMSE:0.1437 , RE:0.4013 , R2:0.0780\n",
      "seed: 2, 测试集: B0007, epoch:182  , loss:0.0000303286 , MAE:0.1250 , RMSE:0.1279 , RE:0.3553 , R2:0.2692\n",
      "seed: 2, 测试集: B0007, epoch:183  , loss:0.0000942460 , MAE:0.1135 , RMSE:0.1166 , RE:0.3092 , R2:0.3930\n",
      "seed: 2, 测试集: B0007, epoch:184  , loss:0.0002193360 , MAE:0.1302 , RMSE:0.1330 , RE:0.3684 , R2:0.2099\n",
      "seed: 2, 测试集: B0007, epoch:185  , loss:0.0001250895 , MAE:0.1289 , RMSE:0.1317 , RE:0.3684 , R2:0.2253\n",
      "seed: 2, 测试集: B0007, epoch:186  , loss:0.0001156986 , MAE:0.1299 , RMSE:0.1327 , RE:0.3684 , R2:0.2140\n",
      "seed: 2, 测试集: B0007, epoch:187  , loss:0.0006165844 , MAE:0.1330 , RMSE:0.1358 , RE:0.3816 , R2:0.1771\n",
      "seed: 2, 测试集: B0007, epoch:188  , loss:0.0011241008 , MAE:0.0920 , RMSE:0.0958 , RE:0.2171 , R2:0.5901\n",
      "seed: 2, 测试集: B0007, epoch:189  , loss:0.0001895530 , MAE:0.1166 , RMSE:0.1194 , RE:0.3224 , R2:0.3636\n",
      "seed: 2, 测试集: B0007, epoch:190  , loss:0.0000158977 , MAE:0.1380 , RMSE:0.1407 , RE:0.3947 , R2:0.1158\n",
      "seed: 2, 测试集: B0007, epoch:191  , loss:0.0003030925 , MAE:0.1095 , RMSE:0.1123 , RE:0.2961 , R2:0.4366\n",
      "seed: 2, 测试集: B0007, epoch:192  , loss:0.0002480725 , MAE:0.1167 , RMSE:0.1194 , RE:0.3224 , R2:0.3640\n",
      "seed: 2, 测试集: B0007, epoch:193  , loss:0.0012287768 , MAE:0.1049 , RMSE:0.1078 , RE:0.2829 , R2:0.4808\n",
      "seed: 2, 测试集: B0007, epoch:194  , loss:0.0001972200 , MAE:0.1007 , RMSE:0.1037 , RE:0.2632 , R2:0.5198\n",
      "seed: 2, 测试集: B0007, epoch:195  , loss:0.0002921663 , MAE:0.1416 , RMSE:0.1443 , RE:0.4079 , R2:0.0703\n",
      "seed: 2, 测试集: B0007, epoch:196  , loss:0.0003870891 , MAE:0.0956 , RMSE:0.0987 , RE:0.2434 , R2:0.5651\n",
      "seed: 2, 测试集: B0007, epoch:197  , loss:0.0013102627 , MAE:0.1183 , RMSE:0.1208 , RE:0.3355 , R2:0.3483\n",
      "seed: 2, 测试集: B0007, epoch:198  , loss:0.0005251240 , MAE:0.1205 , RMSE:0.1230 , RE:0.3421 , R2:0.3244\n",
      "seed: 2, 测试集: B0007, epoch:199  , loss:0.0004753379 , MAE:0.1353 , RMSE:0.1379 , RE:0.3882 , R2:0.1509\n",
      "seed: 2, 测试集: B0007, epoch:200  , loss:0.0001488107 , MAE:0.1055 , RMSE:0.1081 , RE:0.2895 , R2:0.4784\n",
      "以电池 B0018 为测试数据的 数据集 开始训练\n",
      "seed: 2, 测试集: B0018, epoch:1    , loss:3.2591571808 , MAE:1.6835 , RMSE:1.6884 , RE:0.9877 , R2:-170.2963\n",
      "seed: 2, 测试集: B0018, epoch:2    , loss:2.6765637398 , MAE:1.6736 , RMSE:1.6785 , RE:0.9877 , R2:-168.2984\n",
      "seed: 2, 测试集: B0018, epoch:3    , loss:2.9398050308 , MAE:1.6636 , RMSE:1.6686 , RE:0.9877 , R2:-166.3035\n",
      "seed: 2, 测试集: B0018, epoch:4    , loss:2.3894050121 , MAE:1.6536 , RMSE:1.6586 , RE:0.9877 , R2:-164.3008\n",
      "seed: 2, 测试集: B0018, epoch:5    , loss:2.7350740433 , MAE:1.6429 , RMSE:1.6479 , RE:0.9877 , R2:-162.1802\n",
      "seed: 2, 测试集: B0018, epoch:6    , loss:3.0168321133 , MAE:1.6317 , RMSE:1.6367 , RE:0.9877 , R2:-159.9777\n",
      "seed: 2, 测试集: B0018, epoch:7    , loss:2.7223844528 , MAE:1.6196 , RMSE:1.6246 , RE:0.9877 , R2:-157.6063\n",
      "seed: 2, 测试集: B0018, epoch:8    , loss:3.0402326584 , MAE:1.6062 , RMSE:1.6112 , RE:0.9877 , R2:-154.9920\n",
      "seed: 2, 测试集: B0018, epoch:9    , loss:2.4956369400 , MAE:1.5914 , RMSE:1.5964 , RE:0.9877 , R2:-152.1426\n",
      "seed: 2, 测试集: B0018, epoch:10   , loss:2.8043630123 , MAE:1.5748 , RMSE:1.5798 , RE:0.9877 , R2:-148.9743\n",
      "seed: 2, 测试集: B0018, epoch:11   , loss:2.4911975861 , MAE:1.5557 , RMSE:1.5608 , RE:0.9877 , R2:-145.3868\n",
      "seed: 2, 测试集: B0018, epoch:12   , loss:1.9903600216 , MAE:1.5338 , RMSE:1.5388 , RE:0.9877 , R2:-141.2939\n",
      "seed: 2, 测试集: B0018, epoch:13   , loss:2.1643714905 , MAE:1.5073 , RMSE:1.5123 , RE:0.9877 , R2:-136.4362\n",
      "seed: 2, 测试集: B0018, epoch:14   , loss:1.7065029144 , MAE:1.4740 , RMSE:1.4791 , RE:0.9877 , R2:-130.4567\n",
      "seed: 2, 测试集: B0018, epoch:15   , loss:1.6564719677 , MAE:1.4337 , RMSE:1.4389 , RE:0.9877 , R2:-123.4158\n",
      "seed: 2, 测试集: B0018, epoch:16   , loss:1.7203521729 , MAE:1.3836 , RMSE:1.3889 , RE:0.9877 , R2:-114.9128\n",
      "seed: 2, 测试集: B0018, epoch:17   , loss:1.2394387722 , MAE:1.3214 , RMSE:1.3268 , RE:0.9877 , R2:-104.7873\n",
      "seed: 2, 测试集: B0018, epoch:18   , loss:0.9437912107 , MAE:1.2449 , RMSE:1.2505 , RE:0.9877 , R2:-92.9661\n",
      "seed: 2, 测试集: B0018, epoch:19   , loss:0.6239513159 , MAE:1.1506 , RMSE:1.1566 , RE:0.9877 , R2:-79.3857\n",
      "seed: 2, 测试集: B0018, epoch:20   , loss:0.4835338593 , MAE:1.0323 , RMSE:1.0388 , RE:0.9877 , R2:-63.8411\n",
      "seed: 2, 测试集: B0018, epoch:21   , loss:0.2976002991 , MAE:0.8850 , RMSE:0.8924 , RE:0.9877 , R2:-46.8524\n",
      "seed: 2, 测试集: B0018, epoch:22   , loss:0.1794008017 , MAE:0.7136 , RMSE:0.7223 , RE:0.9877 , R2:-30.3512\n",
      "seed: 2, 测试集: B0018, epoch:23   , loss:0.0757120624 , MAE:0.5181 , RMSE:0.5294 , RE:0.9877 , R2:-15.8420\n",
      "seed: 2, 测试集: B0018, epoch:24   , loss:0.0362825096 , MAE:0.3244 , RMSE:0.3416 , RE:0.9383 , R2:-6.0112\n",
      "seed: 2, 测试集: B0018, epoch:25   , loss:0.0128900837 , MAE:0.1601 , RMSE:0.1930 , RE:0.8395 , R2:-1.2387\n",
      "seed: 2, 测试集: B0018, epoch:26   , loss:0.0094127348 , MAE:0.1009 , RMSE:0.1215 , RE:0.4321 , R2:0.1124\n",
      "seed: 2, 测试集: B0018, epoch:27   , loss:0.0032142019 , MAE:0.1036 , RMSE:0.1132 , RE:0.4321 , R2:0.2295\n",
      "seed: 2, 测试集: B0018, epoch:28   , loss:0.0047657890 , MAE:0.1081 , RMSE:0.1189 , RE:0.4321 , R2:0.1511\n",
      "seed: 2, 测试集: B0018, epoch:29   , loss:0.0052341586 , MAE:0.1092 , RMSE:0.1204 , RE:0.4321 , R2:0.1284\n",
      "seed: 2, 测试集: B0018, epoch:30   , loss:0.0098258387 , MAE:0.1088 , RMSE:0.1199 , RE:0.4321 , R2:0.1358\n",
      "seed: 2, 测试集: B0018, epoch:31   , loss:0.0024992307 , MAE:0.1088 , RMSE:0.1200 , RE:0.4321 , R2:0.1350\n",
      "seed: 2, 测试集: B0018, epoch:32   , loss:0.0087127229 , MAE:0.1093 , RMSE:0.1207 , RE:0.4321 , R2:0.1247\n",
      "seed: 2, 测试集: B0018, epoch:33   , loss:0.0046250387 , MAE:0.1084 , RMSE:0.1194 , RE:0.4321 , R2:0.1434\n",
      "seed: 2, 测试集: B0018, epoch:34   , loss:0.0119967218 , MAE:0.1082 , RMSE:0.1191 , RE:0.4321 , R2:0.1475\n",
      "seed: 2, 测试集: B0018, epoch:35   , loss:0.0052584084 , MAE:0.1084 , RMSE:0.1195 , RE:0.4321 , R2:0.1425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0018, epoch:36   , loss:0.0053540999 , MAE:0.1079 , RMSE:0.1187 , RE:0.4321 , R2:0.1530\n",
      "seed: 2, 测试集: B0018, epoch:37   , loss:0.0071912850 , MAE:0.1086 , RMSE:0.1198 , RE:0.4321 , R2:0.1369\n",
      "seed: 2, 测试集: B0018, epoch:38   , loss:0.0144607443 , MAE:0.1077 , RMSE:0.1186 , RE:0.4321 , R2:0.1551\n",
      "seed: 2, 测试集: B0018, epoch:39   , loss:0.0019999049 , MAE:0.1085 , RMSE:0.1197 , RE:0.4321 , R2:0.1391\n",
      "seed: 2, 测试集: B0018, epoch:40   , loss:0.0032069702 , MAE:0.1079 , RMSE:0.1188 , RE:0.4321 , R2:0.1515\n",
      "seed: 2, 测试集: B0018, epoch:41   , loss:0.0029848237 , MAE:0.1074 , RMSE:0.1183 , RE:0.4321 , R2:0.1597\n",
      "seed: 2, 测试集: B0018, epoch:42   , loss:0.0031421199 , MAE:0.1070 , RMSE:0.1177 , RE:0.4321 , R2:0.1681\n",
      "seed: 2, 测试集: B0018, epoch:43   , loss:0.0068141543 , MAE:0.1081 , RMSE:0.1193 , RE:0.4321 , R2:0.1447\n",
      "seed: 2, 测试集: B0018, epoch:44   , loss:0.0070732441 , MAE:0.1068 , RMSE:0.1174 , RE:0.4321 , R2:0.1711\n",
      "seed: 2, 测试集: B0018, epoch:45   , loss:0.0041188160 , MAE:0.1080 , RMSE:0.1192 , RE:0.4321 , R2:0.1466\n",
      "seed: 2, 测试集: B0018, epoch:46   , loss:0.0031607826 , MAE:0.1083 , RMSE:0.1197 , RE:0.4321 , R2:0.1394\n",
      "seed: 2, 测试集: B0018, epoch:47   , loss:0.0052940976 , MAE:0.1071 , RMSE:0.1180 , RE:0.4321 , R2:0.1633\n",
      "seed: 2, 测试集: B0018, epoch:48   , loss:0.0038885460 , MAE:0.1067 , RMSE:0.1174 , RE:0.4321 , R2:0.1720\n",
      "seed: 2, 测试集: B0018, epoch:49   , loss:0.0062808725 , MAE:0.1075 , RMSE:0.1186 , RE:0.4321 , R2:0.1544\n",
      "seed: 2, 测试集: B0018, epoch:50   , loss:0.0074660694 , MAE:0.1070 , RMSE:0.1179 , RE:0.4321 , R2:0.1649\n",
      "seed: 2, 测试集: B0018, epoch:51   , loss:0.0065172771 , MAE:0.1068 , RMSE:0.1177 , RE:0.4321 , R2:0.1672\n",
      "seed: 2, 测试集: B0018, epoch:52   , loss:0.0040346961 , MAE:0.1081 , RMSE:0.1197 , RE:0.4321 , R2:0.1390\n",
      "seed: 2, 测试集: B0018, epoch:53   , loss:0.0023948047 , MAE:0.1069 , RMSE:0.1179 , RE:0.4321 , R2:0.1645\n",
      "seed: 2, 测试集: B0018, epoch:54   , loss:0.0048307944 , MAE:0.1069 , RMSE:0.1179 , RE:0.4321 , R2:0.1650\n",
      "seed: 2, 测试集: B0018, epoch:55   , loss:0.0047828592 , MAE:0.1058 , RMSE:0.1165 , RE:0.4321 , R2:0.1850\n",
      "seed: 2, 测试集: B0018, epoch:56   , loss:0.0013150250 , MAE:0.1073 , RMSE:0.1186 , RE:0.4321 , R2:0.1552\n",
      "seed: 2, 测试集: B0018, epoch:57   , loss:0.0097700004 , MAE:0.1067 , RMSE:0.1177 , RE:0.4321 , R2:0.1678\n",
      "seed: 2, 测试集: B0018, epoch:58   , loss:0.0058971005 , MAE:0.1057 , RMSE:0.1164 , RE:0.4321 , R2:0.1858\n",
      "seed: 2, 测试集: B0018, epoch:59   , loss:0.0067661311 , MAE:0.1055 , RMSE:0.1161 , RE:0.4321 , R2:0.1894\n",
      "seed: 2, 测试集: B0018, epoch:60   , loss:0.0025143700 , MAE:0.1069 , RMSE:0.1182 , RE:0.4321 , R2:0.1602\n",
      "seed: 2, 测试集: B0018, epoch:61   , loss:0.0060759848 , MAE:0.1066 , RMSE:0.1178 , RE:0.4321 , R2:0.1665\n",
      "seed: 2, 测试集: B0018, epoch:62   , loss:0.0031922357 , MAE:0.1077 , RMSE:0.1196 , RE:0.4321 , R2:0.1406\n",
      "seed: 2, 测试集: B0018, epoch:63   , loss:0.0070215301 , MAE:0.1067 , RMSE:0.1180 , RE:0.4321 , R2:0.1634\n",
      "seed: 2, 测试集: B0018, epoch:64   , loss:0.0051632766 , MAE:0.1057 , RMSE:0.1166 , RE:0.4321 , R2:0.1830\n",
      "seed: 2, 测试集: B0018, epoch:65   , loss:0.0028354910 , MAE:0.1064 , RMSE:0.1176 , RE:0.4321 , R2:0.1690\n",
      "seed: 2, 测试集: B0018, epoch:66   , loss:0.0033664578 , MAE:0.1068 , RMSE:0.1184 , RE:0.4321 , R2:0.1580\n",
      "seed: 2, 测试集: B0018, epoch:67   , loss:0.0027727846 , MAE:0.1075 , RMSE:0.1195 , RE:0.4321 , R2:0.1425\n",
      "seed: 2, 测试集: B0018, epoch:68   , loss:0.0024667238 , MAE:0.1058 , RMSE:0.1168 , RE:0.4321 , R2:0.1795\n",
      "seed: 2, 测试集: B0018, epoch:69   , loss:0.0034890426 , MAE:0.1061 , RMSE:0.1174 , RE:0.4321 , R2:0.1723\n",
      "seed: 2, 测试集: B0018, epoch:70   , loss:0.0038440609 , MAE:0.1063 , RMSE:0.1177 , RE:0.4321 , R2:0.1678\n",
      "seed: 2, 测试集: B0018, epoch:71   , loss:0.0052161575 , MAE:0.1062 , RMSE:0.1177 , RE:0.4321 , R2:0.1676\n",
      "seed: 2, 测试集: B0018, epoch:72   , loss:0.0049470114 , MAE:0.1070 , RMSE:0.1190 , RE:0.4321 , R2:0.1491\n",
      "seed: 2, 测试集: B0018, epoch:73   , loss:0.0066956468 , MAE:0.1065 , RMSE:0.1181 , RE:0.4321 , R2:0.1613\n",
      "seed: 2, 测试集: B0018, epoch:74   , loss:0.0030768155 , MAE:0.1065 , RMSE:0.1182 , RE:0.4321 , R2:0.1601\n",
      "seed: 2, 测试集: B0018, epoch:75   , loss:0.0028533384 , MAE:0.1053 , RMSE:0.1167 , RE:0.4321 , R2:0.1815\n",
      "seed: 2, 测试集: B0018, epoch:76   , loss:0.0036870681 , MAE:0.1051 , RMSE:0.1167 , RE:0.4321 , R2:0.1815\n",
      "seed: 2, 测试集: B0018, epoch:77   , loss:0.0053654900 , MAE:0.1035 , RMSE:0.1146 , RE:0.4321 , R2:0.2111\n",
      "seed: 2, 测试集: B0018, epoch:78   , loss:0.0036723551 , MAE:0.1045 , RMSE:0.1162 , RE:0.4321 , R2:0.1889\n",
      "seed: 2, 测试集: B0018, epoch:79   , loss:0.0023770411 , MAE:0.1045 , RMSE:0.1165 , RE:0.4321 , R2:0.1843\n",
      "seed: 2, 测试集: B0018, epoch:80   , loss:0.0017634865 , MAE:0.1037 , RMSE:0.1155 , RE:0.4321 , R2:0.1983\n",
      "seed: 2, 测试集: B0018, epoch:81   , loss:0.0036041802 , MAE:0.1025 , RMSE:0.1139 , RE:0.4321 , R2:0.2208\n",
      "seed: 2, 测试集: B0018, epoch:82   , loss:0.0034422367 , MAE:0.1009 , RMSE:0.1119 , RE:0.4321 , R2:0.2481\n",
      "seed: 2, 测试集: B0018, epoch:83   , loss:0.0031571875 , MAE:0.1023 , RMSE:0.1141 , RE:0.4321 , R2:0.2182\n",
      "seed: 2, 测试集: B0018, epoch:84   , loss:0.0013057129 , MAE:0.1019 , RMSE:0.1137 , RE:0.4321 , R2:0.2233\n",
      "seed: 2, 测试集: B0018, epoch:85   , loss:0.0018007522 , MAE:0.0996 , RMSE:0.1106 , RE:0.4321 , R2:0.2647\n",
      "seed: 2, 测试集: B0018, epoch:86   , loss:0.0007266380 , MAE:0.0998 , RMSE:0.1110 , RE:0.4321 , R2:0.2597\n",
      "seed: 2, 测试集: B0018, epoch:87   , loss:0.0038380916 , MAE:0.0994 , RMSE:0.1107 , RE:0.4321 , R2:0.2640\n",
      "seed: 2, 测试集: B0018, epoch:88   , loss:0.0060736490 , MAE:0.0988 , RMSE:0.1100 , RE:0.4321 , R2:0.2727\n",
      "seed: 2, 测试集: B0018, epoch:89   , loss:0.0022346457 , MAE:0.0997 , RMSE:0.1114 , RE:0.4321 , R2:0.2537\n",
      "seed: 2, 测试集: B0018, epoch:90   , loss:0.0026683451 , MAE:0.0969 , RMSE:0.1077 , RE:0.4321 , R2:0.3036\n",
      "seed: 2, 测试集: B0018, epoch:91   , loss:0.0023628646 , MAE:0.0976 , RMSE:0.1088 , RE:0.4321 , R2:0.2891\n",
      "seed: 2, 测试集: B0018, epoch:92   , loss:0.0032843878 , MAE:0.0978 , RMSE:0.1092 , RE:0.4321 , R2:0.2836\n",
      "seed: 2, 测试集: B0018, epoch:93   , loss:0.0031267004 , MAE:0.0974 , RMSE:0.1088 , RE:0.4321 , R2:0.2887\n",
      "seed: 2, 测试集: B0018, epoch:94   , loss:0.0022901008 , MAE:0.0957 , RMSE:0.1066 , RE:0.4321 , R2:0.3170\n",
      "seed: 2, 测试集: B0018, epoch:95   , loss:0.0058756606 , MAE:0.0958 , RMSE:0.1068 , RE:0.4321 , R2:0.3142\n",
      "seed: 2, 测试集: B0018, epoch:96   , loss:0.0030967700 , MAE:0.0977 , RMSE:0.1098 , RE:0.4321 , R2:0.2758\n",
      "seed: 2, 测试集: B0018, epoch:97   , loss:0.0036282891 , MAE:0.0950 , RMSE:0.1061 , RE:0.4321 , R2:0.3239\n",
      "seed: 2, 测试集: B0018, epoch:98   , loss:0.0031733899 , MAE:0.0951 , RMSE:0.1063 , RE:0.4321 , R2:0.3206\n",
      "seed: 2, 测试集: B0018, epoch:99   , loss:0.0016565510 , MAE:0.0938 , RMSE:0.1046 , RE:0.4321 , R2:0.3425\n",
      "seed: 2, 测试集: B0018, epoch:100  , loss:0.0021728436 , MAE:0.0951 , RMSE:0.1067 , RE:0.4321 , R2:0.3162\n",
      "seed: 2, 测试集: B0018, epoch:101  , loss:0.0034678595 , MAE:0.0930 , RMSE:0.1038 , RE:0.4321 , R2:0.3526\n",
      "seed: 2, 测试集: B0018, epoch:102  , loss:0.0028929454 , MAE:0.0942 , RMSE:0.1058 , RE:0.4321 , R2:0.3277\n",
      "seed: 2, 测试集: B0018, epoch:103  , loss:0.0023524966 , MAE:0.0934 , RMSE:0.1049 , RE:0.4321 , R2:0.3390\n",
      "seed: 2, 测试集: B0018, epoch:104  , loss:0.0039142231 , MAE:0.0922 , RMSE:0.1031 , RE:0.4321 , R2:0.3608\n",
      "seed: 2, 测试集: B0018, epoch:105  , loss:0.0016915051 , MAE:0.0925 , RMSE:0.1038 , RE:0.4321 , R2:0.3520\n",
      "seed: 2, 测试集: B0018, epoch:106  , loss:0.0017942598 , MAE:0.0905 , RMSE:0.1010 , RE:0.4321 , R2:0.3873\n",
      "seed: 2, 测试集: B0018, epoch:107  , loss:0.0023792246 , MAE:0.0912 , RMSE:0.1022 , RE:0.4321 , R2:0.3721\n",
      "seed: 2, 测试集: B0018, epoch:108  , loss:0.0013724135 , MAE:0.0908 , RMSE:0.1019 , RE:0.4321 , R2:0.3756\n",
      "seed: 2, 测试集: B0018, epoch:109  , loss:0.0037301420 , MAE:0.0908 , RMSE:0.1022 , RE:0.4321 , R2:0.3730\n",
      "seed: 2, 测试集: B0018, epoch:110  , loss:0.0016651975 , MAE:0.0929 , RMSE:0.1055 , RE:0.4321 , R2:0.3312\n",
      "seed: 2, 测试集: B0018, epoch:111  , loss:0.0047514495 , MAE:0.0899 , RMSE:0.1012 , RE:0.4321 , R2:0.3852\n",
      "seed: 2, 测试集: B0018, epoch:112  , loss:0.0011033994 , MAE:0.0918 , RMSE:0.1043 , RE:0.4321 , R2:0.3465\n",
      "seed: 2, 测试集: B0018, epoch:113  , loss:0.0018884155 , MAE:0.0890 , RMSE:0.1002 , RE:0.4321 , R2:0.3966\n",
      "seed: 2, 测试集: B0018, epoch:114  , loss:0.0017665222 , MAE:0.0894 , RMSE:0.1011 , RE:0.4321 , R2:0.3862\n",
      "seed: 2, 测试集: B0018, epoch:115  , loss:0.0018575322 , MAE:0.0891 , RMSE:0.1008 , RE:0.4321 , R2:0.3890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0018, epoch:116  , loss:0.0014983460 , MAE:0.0876 , RMSE:0.0987 , RE:0.4321 , R2:0.4145\n",
      "seed: 2, 测试集: B0018, epoch:117  , loss:0.0010373275 , MAE:0.0890 , RMSE:0.1012 , RE:0.4321 , R2:0.3851\n",
      "seed: 2, 测试集: B0018, epoch:118  , loss:0.0024535796 , MAE:0.0869 , RMSE:0.0981 , RE:0.4321 , R2:0.4220\n",
      "seed: 2, 测试集: B0018, epoch:119  , loss:0.0011169792 , MAE:0.0875 , RMSE:0.0993 , RE:0.4321 , R2:0.4076\n",
      "seed: 2, 测试集: B0018, epoch:120  , loss:0.0019271534 , MAE:0.0843 , RMSE:0.0947 , RE:0.4321 , R2:0.4615\n",
      "seed: 2, 测试集: B0018, epoch:121  , loss:0.0043927324 , MAE:0.0866 , RMSE:0.0984 , RE:0.4321 , R2:0.4186\n",
      "seed: 2, 测试集: B0018, epoch:122  , loss:0.0007221347 , MAE:0.0866 , RMSE:0.0987 , RE:0.4321 , R2:0.4147\n",
      "seed: 2, 测试集: B0018, epoch:123  , loss:0.0014982952 , MAE:0.0844 , RMSE:0.0954 , RE:0.4321 , R2:0.4526\n",
      "seed: 2, 测试集: B0018, epoch:124  , loss:0.0020316415 , MAE:0.0856 , RMSE:0.0976 , RE:0.4321 , R2:0.4274\n",
      "seed: 2, 测试集: B0018, epoch:125  , loss:0.0032936919 , MAE:0.0850 , RMSE:0.0970 , RE:0.4321 , R2:0.4344\n",
      "seed: 2, 测试集: B0018, epoch:126  , loss:0.0009082148 , MAE:0.0863 , RMSE:0.0991 , RE:0.4321 , R2:0.4094\n",
      "seed: 2, 测试集: B0018, epoch:127  , loss:0.0032613010 , MAE:0.0812 , RMSE:0.0916 , RE:0.4321 , R2:0.4957\n",
      "seed: 2, 测试集: B0018, epoch:128  , loss:0.0007399220 , MAE:0.0838 , RMSE:0.0959 , RE:0.4321 , R2:0.4469\n",
      "seed: 2, 测试集: B0018, epoch:129  , loss:0.0019985533 , MAE:0.0838 , RMSE:0.0961 , RE:0.4321 , R2:0.4453\n",
      "seed: 2, 测试集: B0018, epoch:130  , loss:0.0011390981 , MAE:0.0809 , RMSE:0.0918 , RE:0.4321 , R2:0.4940\n",
      "seed: 2, 测试集: B0018, epoch:131  , loss:0.0015137459 , MAE:0.0820 , RMSE:0.0939 , RE:0.4321 , R2:0.4702\n",
      "seed: 2, 测试集: B0018, epoch:132  , loss:0.0019769967 , MAE:0.0810 , RMSE:0.0925 , RE:0.4321 , R2:0.4857\n",
      "seed: 2, 测试集: B0018, epoch:133  , loss:0.0019602119 , MAE:0.0794 , RMSE:0.0902 , RE:0.4321 , R2:0.5106\n",
      "seed: 2, 测试集: B0018, epoch:134  , loss:0.0017517479 , MAE:0.0789 , RMSE:0.0898 , RE:0.4321 , R2:0.5156\n",
      "seed: 2, 测试集: B0018, epoch:135  , loss:0.0009019134 , MAE:0.0790 , RMSE:0.0903 , RE:0.4321 , R2:0.5105\n",
      "seed: 2, 测试集: B0018, epoch:136  , loss:0.0014583690 , MAE:0.0813 , RMSE:0.0941 , RE:0.4321 , R2:0.4673\n",
      "seed: 2, 测试集: B0018, epoch:137  , loss:0.0024904832 , MAE:0.0769 , RMSE:0.0876 , RE:0.4321 , R2:0.5388\n",
      "seed: 2, 测试集: B0018, epoch:138  , loss:0.0008148445 , MAE:0.0778 , RMSE:0.0893 , RE:0.4321 , R2:0.5213\n",
      "seed: 2, 测试集: B0018, epoch:139  , loss:0.0020094798 , MAE:0.0774 , RMSE:0.0888 , RE:0.4321 , R2:0.5257\n",
      "seed: 2, 测试集: B0018, epoch:140  , loss:0.0008404215 , MAE:0.0771 , RMSE:0.0886 , RE:0.4321 , R2:0.5279\n",
      "seed: 2, 测试集: B0018, epoch:141  , loss:0.0008218600 , MAE:0.0732 , RMSE:0.0836 , RE:0.4321 , R2:0.5799\n",
      "seed: 2, 测试集: B0018, epoch:142  , loss:0.0023964380 , MAE:0.0764 , RMSE:0.0881 , RE:0.4321 , R2:0.5339\n",
      "seed: 2, 测试集: B0018, epoch:143  , loss:0.0016753349 , MAE:0.0772 , RMSE:0.0898 , RE:0.4321 , R2:0.5156\n",
      "seed: 2, 测试集: B0018, epoch:144  , loss:0.0004385317 , MAE:0.0756 , RMSE:0.0875 , RE:0.4321 , R2:0.5404\n",
      "seed: 2, 测试集: B0018, epoch:145  , loss:0.0008158324 , MAE:0.0750 , RMSE:0.0868 , RE:0.4321 , R2:0.5476\n",
      "seed: 2, 测试集: B0018, epoch:146  , loss:0.0011596906 , MAE:0.0723 , RMSE:0.0831 , RE:0.4321 , R2:0.5846\n",
      "seed: 2, 测试集: B0018, epoch:147  , loss:0.0010544329 , MAE:0.0706 , RMSE:0.0811 , RE:0.4321 , R2:0.6043\n",
      "seed: 2, 测试集: B0018, epoch:148  , loss:0.0005398809 , MAE:0.0735 , RMSE:0.0854 , RE:0.4321 , R2:0.5617\n",
      "seed: 2, 测试集: B0018, epoch:149  , loss:0.0006179156 , MAE:0.0705 , RMSE:0.0813 , RE:0.4321 , R2:0.6032\n",
      "seed: 2, 测试集: B0018, epoch:150  , loss:0.0020623752 , MAE:0.0701 , RMSE:0.0809 , RE:0.4321 , R2:0.6070\n",
      "seed: 2, 测试集: B0018, epoch:151  , loss:0.0009358187 , MAE:0.0739 , RMSE:0.0869 , RE:0.4321 , R2:0.5467\n",
      "seed: 2, 测试集: B0018, epoch:152  , loss:0.0011482440 , MAE:0.0714 , RMSE:0.0833 , RE:0.4321 , R2:0.5831\n",
      "seed: 2, 测试集: B0018, epoch:153  , loss:0.0010276263 , MAE:0.0683 , RMSE:0.0791 , RE:0.4321 , R2:0.6241\n",
      "seed: 2, 测试集: B0018, epoch:154  , loss:0.0015234724 , MAE:0.0711 , RMSE:0.0835 , RE:0.4321 , R2:0.5808\n",
      "seed: 2, 测试集: B0018, epoch:155  , loss:0.0006232085 , MAE:0.0680 , RMSE:0.0791 , RE:0.4321 , R2:0.6238\n",
      "seed: 2, 测试集: B0018, epoch:156  , loss:0.0005668793 , MAE:0.0680 , RMSE:0.0793 , RE:0.4321 , R2:0.6222\n",
      "seed: 2, 测试集: B0018, epoch:157  , loss:0.0002756779 , MAE:0.0674 , RMSE:0.0788 , RE:0.4321 , R2:0.6268\n",
      "seed: 2, 测试集: B0018, epoch:158  , loss:0.0007771021 , MAE:0.0648 , RMSE:0.0755 , RE:0.4321 , R2:0.6573\n",
      "seed: 2, 测试集: B0018, epoch:159  , loss:0.0011132546 , MAE:0.0695 , RMSE:0.0825 , RE:0.4321 , R2:0.5907\n",
      "seed: 2, 测试集: B0018, epoch:160  , loss:0.0005550515 , MAE:0.0627 , RMSE:0.0733 , RE:0.4321 , R2:0.6769\n",
      "seed: 2, 测试集: B0018, epoch:161  , loss:0.0010061680 , MAE:0.0669 , RMSE:0.0791 , RE:0.4321 , R2:0.6236\n",
      "seed: 2, 测试集: B0018, epoch:162  , loss:0.0012299464 , MAE:0.0664 , RMSE:0.0787 , RE:0.4321 , R2:0.6279\n",
      "seed: 2, 测试集: B0018, epoch:163  , loss:0.0002208063 , MAE:0.0622 , RMSE:0.0730 , RE:0.4321 , R2:0.6800\n",
      "seed: 2, 测试集: B0018, epoch:164  , loss:0.0003928713 , MAE:0.0643 , RMSE:0.0760 , RE:0.4321 , R2:0.6527\n",
      "seed: 2, 测试集: B0018, epoch:165  , loss:0.0044702757 , MAE:0.0654 , RMSE:0.0781 , RE:0.4321 , R2:0.6339\n",
      "seed: 2, 测试集: B0018, epoch:166  , loss:0.0005804364 , MAE:0.0634 , RMSE:0.0752 , RE:0.4321 , R2:0.6598\n",
      "seed: 2, 测试集: B0018, epoch:167  , loss:0.0007068529 , MAE:0.0629 , RMSE:0.0748 , RE:0.4321 , R2:0.6638\n",
      "seed: 2, 测试集: B0018, epoch:168  , loss:0.0007186124 , MAE:0.0613 , RMSE:0.0728 , RE:0.4321 , R2:0.6819\n",
      "seed: 2, 测试集: B0018, epoch:169  , loss:0.0006093664 , MAE:0.0584 , RMSE:0.0693 , RE:0.4321 , R2:0.7118\n",
      "seed: 2, 测试集: B0018, epoch:170  , loss:0.0005376620 , MAE:0.0602 , RMSE:0.0716 , RE:0.4321 , R2:0.6917\n",
      "seed: 2, 测试集: B0018, epoch:171  , loss:0.0006192403 , MAE:0.0596 , RMSE:0.0710 , RE:0.4321 , R2:0.6968\n",
      "seed: 2, 测试集: B0018, epoch:172  , loss:0.0001955903 , MAE:0.0599 , RMSE:0.0717 , RE:0.4321 , R2:0.6907\n",
      "seed: 2, 测试集: B0018, epoch:173  , loss:0.0009346858 , MAE:0.0557 , RMSE:0.0665 , RE:0.4321 , R2:0.7343\n",
      "seed: 2, 测试集: B0018, epoch:174  , loss:0.0005457730 , MAE:0.0591 , RMSE:0.0710 , RE:0.4321 , R2:0.6971\n",
      "seed: 2, 测试集: B0018, epoch:175  , loss:0.0012054275 , MAE:0.0537 , RMSE:0.0645 , RE:0.4321 , R2:0.7497\n",
      "seed: 2, 测试集: B0018, epoch:176  , loss:0.0004879371 , MAE:0.0593 , RMSE:0.0718 , RE:0.4321 , R2:0.6904\n",
      "seed: 2, 测试集: B0018, epoch:177  , loss:0.0012032884 , MAE:0.0532 , RMSE:0.0640 , RE:0.4321 , R2:0.7540\n",
      "seed: 2, 测试集: B0018, epoch:178  , loss:0.0007615393 , MAE:0.0590 , RMSE:0.0717 , RE:0.4321 , R2:0.6911\n",
      "seed: 2, 测试集: B0018, epoch:179  , loss:0.0001614597 , MAE:0.0555 , RMSE:0.0671 , RE:0.4321 , R2:0.7297\n",
      "seed: 2, 测试集: B0018, epoch:180  , loss:0.0003018488 , MAE:0.0506 , RMSE:0.0615 , RE:0.4321 , R2:0.7728\n",
      "seed: 2, 测试集: B0018, epoch:181  , loss:0.0006450283 , MAE:0.0529 , RMSE:0.0640 , RE:0.4321 , R2:0.7537\n",
      "seed: 2, 测试集: B0018, epoch:182  , loss:0.0000744311 , MAE:0.0544 , RMSE:0.0661 , RE:0.4321 , R2:0.7373\n",
      "seed: 2, 测试集: B0018, epoch:183  , loss:0.0000854313 , MAE:0.0539 , RMSE:0.0657 , RE:0.4321 , R2:0.7407\n",
      "seed: 2, 测试集: B0018, epoch:184  , loss:0.0010554309 , MAE:0.0489 , RMSE:0.0597 , RE:0.4321 , R2:0.7856\n",
      "seed: 2, 测试集: B0018, epoch:185  , loss:0.0002783316 , MAE:0.0518 , RMSE:0.0631 , RE:0.4321 , R2:0.7604\n",
      "seed: 2, 测试集: B0018, epoch:186  , loss:0.0002774486 , MAE:0.0539 , RMSE:0.0658 , RE:0.4321 , R2:0.7399\n",
      "seed: 2, 测试集: B0018, epoch:187  , loss:0.0012785983 , MAE:0.0440 , RMSE:0.0554 , RE:0.4321 , R2:0.8157\n",
      "seed: 2, 测试集: B0018, epoch:188  , loss:0.0006416803 , MAE:0.0558 , RMSE:0.0680 , RE:0.4321 , R2:0.7219\n",
      "seed: 2, 测试集: B0018, epoch:189  , loss:0.0006014704 , MAE:0.0504 , RMSE:0.0618 , RE:0.4321 , R2:0.7708\n",
      "seed: 2, 测试集: B0018, epoch:190  , loss:0.0002282111 , MAE:0.0480 , RMSE:0.0591 , RE:0.4321 , R2:0.7902\n",
      "seed: 2, 测试集: B0018, epoch:191  , loss:0.0003719696 , MAE:0.0459 , RMSE:0.0568 , RE:0.4321 , R2:0.8062\n",
      "seed: 2, 测试集: B0018, epoch:192  , loss:0.0002909728 , MAE:0.0512 , RMSE:0.0626 , RE:0.4321 , R2:0.7642\n",
      "seed: 2, 测试集: B0018, epoch:193  , loss:0.0016766870 , MAE:0.0432 , RMSE:0.0541 , RE:0.4321 , R2:0.8244\n",
      "seed: 2, 测试集: B0018, epoch:194  , loss:0.0004109666 , MAE:0.0464 , RMSE:0.0573 , RE:0.4321 , R2:0.8024\n",
      "seed: 2, 测试集: B0018, epoch:195  , loss:0.0005490832 , MAE:0.0497 , RMSE:0.0609 , RE:0.4321 , R2:0.7774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0018, epoch:196  , loss:0.0005946470 , MAE:0.0469 , RMSE:0.0577 , RE:0.4321 , R2:0.7998\n",
      "seed: 2, 测试集: B0018, epoch:197  , loss:0.0002348425 , MAE:0.0457 , RMSE:0.0564 , RE:0.4321 , R2:0.8088\n",
      "seed: 2, 测试集: B0018, epoch:198  , loss:0.0004313664 , MAE:0.0419 , RMSE:0.0525 , RE:0.4321 , R2:0.8345\n",
      "seed: 2, 测试集: B0018, epoch:199  , loss:0.0003645910 , MAE:0.0448 , RMSE:0.0553 , RE:0.4321 , R2:0.8161\n",
      "seed: 2, 测试集: B0018, epoch:200  , loss:0.0002820756 , MAE:0.0462 , RMSE:0.0567 , RE:0.4321 , R2:0.8068\n",
      "---------------------------------\n",
      "re_s [0.3944954128440367, 0.6344086021505376, 0.2894736842105263, 0.43209876543209874]\n",
      "---------------------------------\n",
      "re mean: 0.4376191161592998\n",
      "mae mean: 0.0958182363276179\n",
      "rmse mean: 0.1096454685482345\n",
      "r2 mean: 0.5677152491995431\n",
      "---------------------------------\n",
      "*******************************************************************************************************************\n",
      "当前的 seed 为 3\n",
      "以电池 B0005 为测试数据的 数据集 开始训练\n",
      "seed: 3, 测试集: B0005, epoch:1    , loss:2.1129655838 , MAE:1.5052 , RMSE:1.5158 , RE:0.9908 , R2:-70.1293\n",
      "seed: 3, 测试集: B0005, epoch:2    , loss:2.4649057388 , MAE:1.4927 , RMSE:1.5035 , RE:0.9908 , R2:-68.9734\n",
      "seed: 3, 测试集: B0005, epoch:3    , loss:1.8901683092 , MAE:1.4802 , RMSE:1.4910 , RE:0.9908 , R2:-67.8146\n",
      "seed: 3, 测试集: B0005, epoch:4    , loss:2.0909869671 , MAE:1.4674 , RMSE:1.4783 , RE:0.9908 , R2:-66.6471\n",
      "seed: 3, 测试集: B0005, epoch:5    , loss:2.4960711002 , MAE:1.4542 , RMSE:1.4652 , RE:0.9908 , R2:-65.4549\n",
      "seed: 3, 测试集: B0005, epoch:6    , loss:2.0829811096 , MAE:1.4405 , RMSE:1.4515 , RE:0.9908 , R2:-64.2190\n",
      "seed: 3, 测试集: B0005, epoch:7    , loss:2.0873427391 , MAE:1.4262 , RMSE:1.4373 , RE:0.9908 , R2:-62.9497\n",
      "seed: 3, 测试集: B0005, epoch:8    , loss:1.4909965992 , MAE:1.4112 , RMSE:1.4224 , RE:0.9908 , R2:-61.6278\n",
      "seed: 3, 测试集: B0005, epoch:9    , loss:1.4983183146 , MAE:1.3955 , RMSE:1.4068 , RE:0.9908 , R2:-60.2608\n",
      "seed: 3, 测试集: B0005, epoch:10   , loss:1.4775207043 , MAE:1.3786 , RMSE:1.3899 , RE:0.9908 , R2:-58.8014\n",
      "seed: 3, 测试集: B0005, epoch:11   , loss:1.4942643642 , MAE:1.3603 , RMSE:1.3717 , RE:0.9908 , R2:-57.2457\n",
      "seed: 3, 测试集: B0005, epoch:12   , loss:1.3610653877 , MAE:1.3403 , RMSE:1.3519 , RE:0.9908 , R2:-55.5721\n",
      "seed: 3, 测试集: B0005, epoch:13   , loss:1.8757141829 , MAE:1.3187 , RMSE:1.3304 , RE:0.9908 , R2:-53.7866\n",
      "seed: 3, 测试集: B0005, epoch:14   , loss:0.9795304537 , MAE:1.2948 , RMSE:1.3066 , RE:0.9908 , R2:-51.8470\n",
      "seed: 3, 测试集: B0005, epoch:15   , loss:1.2718124390 , MAE:1.2690 , RMSE:1.2810 , RE:0.9908 , R2:-49.7942\n",
      "seed: 3, 测试集: B0005, epoch:16   , loss:1.0674195290 , MAE:1.2403 , RMSE:1.2524 , RE:0.9908 , R2:-47.5554\n",
      "seed: 3, 测试集: B0005, epoch:17   , loss:1.1088000536 , MAE:1.2084 , RMSE:1.2207 , RE:0.9908 , R2:-45.1266\n",
      "seed: 3, 测试集: B0005, epoch:18   , loss:0.7672653198 , MAE:1.1719 , RMSE:1.1845 , RE:0.9908 , R2:-42.4324\n",
      "seed: 3, 测试集: B0005, epoch:19   , loss:0.7687270641 , MAE:1.1311 , RMSE:1.1440 , RE:0.9908 , R2:-39.5104\n",
      "seed: 3, 测试集: B0005, epoch:20   , loss:0.7110866904 , MAE:1.0832 , RMSE:1.0965 , RE:0.9908 , R2:-36.2189\n",
      "seed: 3, 测试集: B0005, epoch:21   , loss:0.5784966350 , MAE:1.0293 , RMSE:1.0431 , RE:0.9908 , R2:-32.6811\n",
      "seed: 3, 测试集: B0005, epoch:22   , loss:0.3182457685 , MAE:0.9578 , RMSE:0.9723 , RE:0.9908 , R2:-28.2654\n",
      "seed: 3, 测试集: B0005, epoch:23   , loss:0.2785135806 , MAE:0.8715 , RMSE:0.8871 , RE:0.9908 , R2:-23.3630\n",
      "seed: 3, 测试集: B0005, epoch:24   , loss:0.0971915424 , MAE:0.7726 , RMSE:0.7899 , RE:0.9908 , R2:-18.3142\n",
      "seed: 3, 测试集: B0005, epoch:25   , loss:0.0950990096 , MAE:0.6658 , RMSE:0.6853 , RE:0.9817 , R2:-13.5371\n",
      "seed: 3, 测试集: B0005, epoch:26   , loss:0.0357946679 , MAE:0.5517 , RMSE:0.5741 , RE:0.9725 , R2:-9.2024\n",
      "seed: 3, 测试集: B0005, epoch:27   , loss:0.0315699652 , MAE:0.4353 , RMSE:0.4618 , RE:0.9450 , R2:-5.6028\n",
      "seed: 3, 测试集: B0005, epoch:28   , loss:0.0051011206 , MAE:0.3123 , RMSE:0.3477 , RE:0.9174 , R2:-2.7431\n",
      "seed: 3, 测试集: B0005, epoch:29   , loss:0.0149919391 , MAE:0.2114 , RMSE:0.2597 , RE:0.8624 , R2:-1.0884\n",
      "seed: 3, 测试集: B0005, epoch:30   , loss:0.0034207751 , MAE:0.1623 , RMSE:0.2012 , RE:0.6055 , R2:-0.2530\n",
      "seed: 3, 测试集: B0005, epoch:31   , loss:0.0033722790 , MAE:0.1456 , RMSE:0.1718 , RE:0.3945 , R2:0.0859\n",
      "seed: 3, 测试集: B0005, epoch:32   , loss:0.0015198828 , MAE:0.1414 , RMSE:0.1618 , RE:0.3945 , R2:0.1892\n",
      "seed: 3, 测试集: B0005, epoch:33   , loss:0.0035333196 , MAE:0.1407 , RMSE:0.1592 , RE:0.3945 , R2:0.2154\n",
      "seed: 3, 测试集: B0005, epoch:34   , loss:0.0003792357 , MAE:0.1408 , RMSE:0.1589 , RE:0.3945 , R2:0.2187\n",
      "seed: 3, 测试集: B0005, epoch:35   , loss:0.0004451877 , MAE:0.1410 , RMSE:0.1589 , RE:0.3945 , R2:0.2186\n",
      "seed: 3, 测试集: B0005, epoch:36   , loss:0.0010699468 , MAE:0.1412 , RMSE:0.1590 , RE:0.3945 , R2:0.2178\n",
      "seed: 3, 测试集: B0005, epoch:37   , loss:0.0002499588 , MAE:0.1411 , RMSE:0.1589 , RE:0.3945 , R2:0.2181\n",
      "seed: 3, 测试集: B0005, epoch:38   , loss:0.0077630719 , MAE:0.1411 , RMSE:0.1589 , RE:0.3945 , R2:0.2183\n",
      "seed: 3, 测试集: B0005, epoch:39   , loss:0.0009662879 , MAE:0.1414 , RMSE:0.1590 , RE:0.3945 , R2:0.2169\n",
      "seed: 3, 测试集: B0005, epoch:40   , loss:0.0055175349 , MAE:0.1414 , RMSE:0.1590 , RE:0.3945 , R2:0.2170\n",
      "seed: 3, 测试集: B0005, epoch:41   , loss:0.0024181472 , MAE:0.1415 , RMSE:0.1591 , RE:0.3945 , R2:0.2161\n",
      "seed: 3, 测试集: B0005, epoch:42   , loss:0.0032345562 , MAE:0.1417 , RMSE:0.1592 , RE:0.3945 , R2:0.2151\n",
      "seed: 3, 测试集: B0005, epoch:43   , loss:0.0005610001 , MAE:0.1413 , RMSE:0.1590 , RE:0.3945 , R2:0.2177\n",
      "seed: 3, 测试集: B0005, epoch:44   , loss:0.0016634623 , MAE:0.1410 , RMSE:0.1588 , RE:0.3945 , R2:0.2192\n",
      "seed: 3, 测试集: B0005, epoch:45   , loss:0.0013893171 , MAE:0.1411 , RMSE:0.1589 , RE:0.3945 , R2:0.2189\n",
      "seed: 3, 测试集: B0005, epoch:46   , loss:0.0017179514 , MAE:0.1414 , RMSE:0.1590 , RE:0.3945 , R2:0.2171\n",
      "seed: 3, 测试集: B0005, epoch:47   , loss:0.0032999893 , MAE:0.1412 , RMSE:0.1589 , RE:0.3945 , R2:0.2188\n",
      "seed: 3, 测试集: B0005, epoch:48   , loss:0.0016774635 , MAE:0.1413 , RMSE:0.1589 , RE:0.3945 , R2:0.2181\n",
      "seed: 3, 测试集: B0005, epoch:49   , loss:0.0018493505 , MAE:0.1417 , RMSE:0.1592 , RE:0.3945 , R2:0.2151\n",
      "seed: 3, 测试集: B0005, epoch:50   , loss:0.0068444321 , MAE:0.1414 , RMSE:0.1590 , RE:0.3945 , R2:0.2175\n",
      "seed: 3, 测试集: B0005, epoch:51   , loss:0.0036465041 , MAE:0.1415 , RMSE:0.1591 , RE:0.3945 , R2:0.2166\n",
      "seed: 3, 测试集: B0005, epoch:52   , loss:0.0040633962 , MAE:0.1415 , RMSE:0.1589 , RE:0.3945 , R2:0.2179\n",
      "seed: 3, 测试集: B0005, epoch:53   , loss:0.0009467598 , MAE:0.1420 , RMSE:0.1594 , RE:0.3945 , R2:0.2131\n",
      "seed: 3, 测试集: B0005, epoch:54   , loss:0.0023849686 , MAE:0.1409 , RMSE:0.1585 , RE:0.3945 , R2:0.2223\n",
      "seed: 3, 测试集: B0005, epoch:55   , loss:0.0005792914 , MAE:0.1412 , RMSE:0.1587 , RE:0.3945 , R2:0.2205\n",
      "seed: 3, 测试集: B0005, epoch:56   , loss:0.0008156964 , MAE:0.1409 , RMSE:0.1584 , RE:0.3945 , R2:0.2231\n",
      "seed: 3, 测试集: B0005, epoch:57   , loss:0.0019048654 , MAE:0.1410 , RMSE:0.1585 , RE:0.3945 , R2:0.2225\n",
      "seed: 3, 测试集: B0005, epoch:58   , loss:0.0007162463 , MAE:0.1411 , RMSE:0.1586 , RE:0.3945 , R2:0.2212\n",
      "seed: 3, 测试集: B0005, epoch:59   , loss:0.0022080627 , MAE:0.1411 , RMSE:0.1586 , RE:0.3945 , R2:0.2214\n",
      "seed: 3, 测试集: B0005, epoch:60   , loss:0.0096193934 , MAE:0.1416 , RMSE:0.1590 , RE:0.3945 , R2:0.2173\n",
      "seed: 3, 测试集: B0005, epoch:61   , loss:0.0002137020 , MAE:0.1408 , RMSE:0.1583 , RE:0.3945 , R2:0.2243\n",
      "seed: 3, 测试集: B0005, epoch:62   , loss:0.0012357594 , MAE:0.1410 , RMSE:0.1585 , RE:0.3945 , R2:0.2224\n",
      "seed: 3, 测试集: B0005, epoch:63   , loss:0.0011128073 , MAE:0.1407 , RMSE:0.1582 , RE:0.3945 , R2:0.2252\n",
      "seed: 3, 测试集: B0005, epoch:64   , loss:0.0017196607 , MAE:0.1404 , RMSE:0.1580 , RE:0.3945 , R2:0.2271\n",
      "seed: 3, 测试集: B0005, epoch:65   , loss:0.0008766500 , MAE:0.1403 , RMSE:0.1579 , RE:0.3945 , R2:0.2283\n",
      "seed: 3, 测试集: B0005, epoch:66   , loss:0.0021034600 , MAE:0.1402 , RMSE:0.1578 , RE:0.3945 , R2:0.2288\n",
      "seed: 3, 测试集: B0005, epoch:67   , loss:0.0019038103 , MAE:0.1401 , RMSE:0.1578 , RE:0.3945 , R2:0.2293\n",
      "seed: 3, 测试集: B0005, epoch:68   , loss:0.0034006133 , MAE:0.1406 , RMSE:0.1581 , RE:0.3945 , R2:0.2267\n",
      "seed: 3, 测试集: B0005, epoch:69   , loss:0.0035079159 , MAE:0.1404 , RMSE:0.1579 , RE:0.3945 , R2:0.2278\n",
      "seed: 3, 测试集: B0005, epoch:70   , loss:0.0008769732 , MAE:0.1410 , RMSE:0.1584 , RE:0.3945 , R2:0.2237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0005, epoch:71   , loss:0.0026485089 , MAE:0.1403 , RMSE:0.1578 , RE:0.3945 , R2:0.2293\n",
      "seed: 3, 测试集: B0005, epoch:72   , loss:0.0042037247 , MAE:0.1398 , RMSE:0.1575 , RE:0.3945 , R2:0.2322\n",
      "seed: 3, 测试集: B0005, epoch:73   , loss:0.0010682258 , MAE:0.1407 , RMSE:0.1581 , RE:0.3945 , R2:0.2261\n",
      "seed: 3, 测试集: B0005, epoch:74   , loss:0.0030525376 , MAE:0.1409 , RMSE:0.1583 , RE:0.3945 , R2:0.2247\n",
      "seed: 3, 测试集: B0005, epoch:75   , loss:0.0022234176 , MAE:0.1405 , RMSE:0.1579 , RE:0.3945 , R2:0.2278\n",
      "seed: 3, 测试集: B0005, epoch:76   , loss:0.0014145597 , MAE:0.1409 , RMSE:0.1582 , RE:0.3945 , R2:0.2250\n",
      "seed: 3, 测试集: B0005, epoch:77   , loss:0.0017627771 , MAE:0.1410 , RMSE:0.1583 , RE:0.3945 , R2:0.2239\n",
      "seed: 3, 测试集: B0005, epoch:78   , loss:0.0015704804 , MAE:0.1400 , RMSE:0.1575 , RE:0.3945 , R2:0.2323\n",
      "seed: 3, 测试集: B0005, epoch:79   , loss:0.0030581048 , MAE:0.1400 , RMSE:0.1575 , RE:0.3945 , R2:0.2324\n",
      "seed: 3, 测试集: B0005, epoch:80   , loss:0.0014712048 , MAE:0.1407 , RMSE:0.1581 , RE:0.3945 , R2:0.2263\n",
      "seed: 3, 测试集: B0005, epoch:81   , loss:0.0009477409 , MAE:0.1403 , RMSE:0.1577 , RE:0.3945 , R2:0.2302\n",
      "seed: 3, 测试集: B0005, epoch:82   , loss:0.0015595051 , MAE:0.1404 , RMSE:0.1578 , RE:0.3945 , R2:0.2295\n",
      "seed: 3, 测试集: B0005, epoch:83   , loss:0.0001809775 , MAE:0.1397 , RMSE:0.1572 , RE:0.3945 , R2:0.2350\n",
      "seed: 3, 测试集: B0005, epoch:84   , loss:0.0011972501 , MAE:0.1395 , RMSE:0.1570 , RE:0.3945 , R2:0.2365\n",
      "seed: 3, 测试集: B0005, epoch:85   , loss:0.0003865940 , MAE:0.1402 , RMSE:0.1575 , RE:0.3945 , R2:0.2316\n",
      "seed: 3, 测试集: B0005, epoch:86   , loss:0.0011376723 , MAE:0.1402 , RMSE:0.1576 , RE:0.3945 , R2:0.2312\n",
      "seed: 3, 测试集: B0005, epoch:87   , loss:0.0012919694 , MAE:0.1401 , RMSE:0.1575 , RE:0.3945 , R2:0.2322\n",
      "seed: 3, 测试集: B0005, epoch:88   , loss:0.0043556578 , MAE:0.1398 , RMSE:0.1572 , RE:0.3945 , R2:0.2347\n",
      "seed: 3, 测试集: B0005, epoch:89   , loss:0.0016617889 , MAE:0.1400 , RMSE:0.1573 , RE:0.3945 , R2:0.2336\n",
      "seed: 3, 测试集: B0005, epoch:90   , loss:0.0001215432 , MAE:0.1396 , RMSE:0.1570 , RE:0.3945 , R2:0.2367\n",
      "seed: 3, 测试集: B0005, epoch:91   , loss:0.0007751532 , MAE:0.1396 , RMSE:0.1570 , RE:0.3945 , R2:0.2367\n",
      "seed: 3, 测试集: B0005, epoch:92   , loss:0.0017902412 , MAE:0.1397 , RMSE:0.1571 , RE:0.3945 , R2:0.2362\n",
      "seed: 3, 测试集: B0005, epoch:93   , loss:0.0050850702 , MAE:0.1401 , RMSE:0.1574 , RE:0.3945 , R2:0.2328\n",
      "seed: 3, 测试集: B0005, epoch:94   , loss:0.0034927970 , MAE:0.1408 , RMSE:0.1581 , RE:0.3945 , R2:0.2258\n",
      "seed: 3, 测试集: B0005, epoch:95   , loss:0.0008823979 , MAE:0.1402 , RMSE:0.1575 , RE:0.3945 , R2:0.2320\n",
      "seed: 3, 测试集: B0005, epoch:96   , loss:0.0015280352 , MAE:0.1396 , RMSE:0.1570 , RE:0.3945 , R2:0.2373\n",
      "seed: 3, 测试集: B0005, epoch:97   , loss:0.0024148151 , MAE:0.1394 , RMSE:0.1568 , RE:0.3945 , R2:0.2394\n",
      "seed: 3, 测试集: B0005, epoch:98   , loss:0.0023381300 , MAE:0.1391 , RMSE:0.1566 , RE:0.3945 , R2:0.2413\n",
      "seed: 3, 测试集: B0005, epoch:99   , loss:0.0020546534 , MAE:0.1394 , RMSE:0.1567 , RE:0.3945 , R2:0.2395\n",
      "seed: 3, 测试集: B0005, epoch:100  , loss:0.0005769925 , MAE:0.1388 , RMSE:0.1563 , RE:0.3945 , R2:0.2438\n",
      "seed: 3, 测试集: B0005, epoch:101  , loss:0.0011042194 , MAE:0.1387 , RMSE:0.1562 , RE:0.3945 , R2:0.2450\n",
      "seed: 3, 测试集: B0005, epoch:102  , loss:0.0055926167 , MAE:0.1400 , RMSE:0.1573 , RE:0.3945 , R2:0.2345\n",
      "seed: 3, 测试集: B0005, epoch:103  , loss:0.0008769251 , MAE:0.1393 , RMSE:0.1566 , RE:0.3945 , R2:0.2409\n",
      "seed: 3, 测试集: B0005, epoch:104  , loss:0.0022790483 , MAE:0.1391 , RMSE:0.1564 , RE:0.3945 , R2:0.2430\n",
      "seed: 3, 测试集: B0005, epoch:105  , loss:0.0019471158 , MAE:0.1384 , RMSE:0.1558 , RE:0.3945 , R2:0.2486\n",
      "seed: 3, 测试集: B0005, epoch:106  , loss:0.0017447870 , MAE:0.1390 , RMSE:0.1562 , RE:0.3945 , R2:0.2446\n",
      "seed: 3, 测试集: B0005, epoch:107  , loss:0.0010394200 , MAE:0.1390 , RMSE:0.1563 , RE:0.3945 , R2:0.2442\n",
      "seed: 3, 测试集: B0005, epoch:108  , loss:0.0021042570 , MAE:0.1380 , RMSE:0.1555 , RE:0.3945 , R2:0.2520\n",
      "seed: 3, 测试集: B0005, epoch:109  , loss:0.0008382630 , MAE:0.1380 , RMSE:0.1554 , RE:0.3945 , R2:0.2526\n",
      "seed: 3, 测试集: B0005, epoch:110  , loss:0.0011437854 , MAE:0.1382 , RMSE:0.1555 , RE:0.3945 , R2:0.2517\n",
      "seed: 3, 测试集: B0005, epoch:111  , loss:0.0029821391 , MAE:0.1386 , RMSE:0.1558 , RE:0.3945 , R2:0.2489\n",
      "seed: 3, 测试集: B0005, epoch:112  , loss:0.0024267833 , MAE:0.1386 , RMSE:0.1558 , RE:0.3945 , R2:0.2490\n",
      "seed: 3, 测试集: B0005, epoch:113  , loss:0.0012636406 , MAE:0.1377 , RMSE:0.1550 , RE:0.3945 , R2:0.2560\n",
      "seed: 3, 测试集: B0005, epoch:114  , loss:0.0016002810 , MAE:0.1378 , RMSE:0.1550 , RE:0.3945 , R2:0.2560\n",
      "seed: 3, 测试集: B0005, epoch:115  , loss:0.0010762902 , MAE:0.1385 , RMSE:0.1557 , RE:0.3945 , R2:0.2498\n",
      "seed: 3, 测试集: B0005, epoch:116  , loss:0.0022656876 , MAE:0.1377 , RMSE:0.1550 , RE:0.3945 , R2:0.2565\n",
      "seed: 3, 测试集: B0005, epoch:117  , loss:0.0043400852 , MAE:0.1376 , RMSE:0.1548 , RE:0.3945 , R2:0.2584\n",
      "seed: 3, 测试集: B0005, epoch:118  , loss:0.0017057698 , MAE:0.1376 , RMSE:0.1548 , RE:0.3945 , R2:0.2587\n",
      "seed: 3, 测试集: B0005, epoch:119  , loss:0.0009830302 , MAE:0.1375 , RMSE:0.1547 , RE:0.3945 , R2:0.2591\n",
      "seed: 3, 测试集: B0005, epoch:120  , loss:0.0027566857 , MAE:0.1376 , RMSE:0.1547 , RE:0.3945 , R2:0.2587\n",
      "seed: 3, 测试集: B0005, epoch:121  , loss:0.0028566159 , MAE:0.1377 , RMSE:0.1548 , RE:0.3945 , R2:0.2584\n",
      "seed: 3, 测试集: B0005, epoch:122  , loss:0.0017244520 , MAE:0.1369 , RMSE:0.1542 , RE:0.3945 , R2:0.2644\n",
      "seed: 3, 测试集: B0005, epoch:123  , loss:0.0032082752 , MAE:0.1385 , RMSE:0.1556 , RE:0.3945 , R2:0.2509\n",
      "seed: 3, 测试集: B0005, epoch:124  , loss:0.0013374332 , MAE:0.1378 , RMSE:0.1549 , RE:0.3945 , R2:0.2575\n",
      "seed: 3, 测试集: B0005, epoch:125  , loss:0.0023175308 , MAE:0.1373 , RMSE:0.1544 , RE:0.3945 , R2:0.2623\n",
      "seed: 3, 测试集: B0005, epoch:126  , loss:0.0009246522 , MAE:0.1367 , RMSE:0.1538 , RE:0.3945 , R2:0.2675\n",
      "seed: 3, 测试集: B0005, epoch:127  , loss:0.0009623503 , MAE:0.1365 , RMSE:0.1537 , RE:0.3945 , R2:0.2688\n",
      "seed: 3, 测试集: B0005, epoch:128  , loss:0.0007235448 , MAE:0.1372 , RMSE:0.1542 , RE:0.3945 , R2:0.2637\n",
      "seed: 3, 测试集: B0005, epoch:129  , loss:0.0018429719 , MAE:0.1362 , RMSE:0.1535 , RE:0.3945 , R2:0.2707\n",
      "seed: 3, 测试集: B0005, epoch:130  , loss:0.0017030023 , MAE:0.1362 , RMSE:0.1534 , RE:0.3945 , R2:0.2717\n",
      "seed: 3, 测试集: B0005, epoch:131  , loss:0.0019128458 , MAE:0.1370 , RMSE:0.1540 , RE:0.3945 , R2:0.2660\n",
      "seed: 3, 测试集: B0005, epoch:132  , loss:0.0022881487 , MAE:0.1364 , RMSE:0.1534 , RE:0.3945 , R2:0.2714\n",
      "seed: 3, 测试集: B0005, epoch:133  , loss:0.0003287279 , MAE:0.1361 , RMSE:0.1531 , RE:0.3945 , R2:0.2740\n",
      "seed: 3, 测试集: B0005, epoch:134  , loss:0.0016477903 , MAE:0.1359 , RMSE:0.1530 , RE:0.3945 , R2:0.2753\n",
      "seed: 3, 测试集: B0005, epoch:135  , loss:0.0009068086 , MAE:0.1358 , RMSE:0.1529 , RE:0.3945 , R2:0.2762\n",
      "seed: 3, 测试集: B0005, epoch:136  , loss:0.0039365808 , MAE:0.1359 , RMSE:0.1529 , RE:0.3945 , R2:0.2758\n",
      "seed: 3, 测试集: B0005, epoch:137  , loss:0.0008614896 , MAE:0.1362 , RMSE:0.1532 , RE:0.3945 , R2:0.2739\n",
      "seed: 3, 测试集: B0005, epoch:138  , loss:0.0019733307 , MAE:0.1355 , RMSE:0.1526 , RE:0.3945 , R2:0.2792\n",
      "seed: 3, 测试集: B0005, epoch:139  , loss:0.0008883408 , MAE:0.1355 , RMSE:0.1525 , RE:0.3945 , R2:0.2800\n",
      "seed: 3, 测试集: B0005, epoch:140  , loss:0.0034354595 , MAE:0.1353 , RMSE:0.1524 , RE:0.3945 , R2:0.2807\n",
      "seed: 3, 测试集: B0005, epoch:141  , loss:0.0018497356 , MAE:0.1357 , RMSE:0.1526 , RE:0.3945 , R2:0.2792\n",
      "seed: 3, 测试集: B0005, epoch:142  , loss:0.0046167397 , MAE:0.1353 , RMSE:0.1523 , RE:0.3945 , R2:0.2824\n",
      "seed: 3, 测试集: B0005, epoch:143  , loss:0.0031543684 , MAE:0.1355 , RMSE:0.1524 , RE:0.3945 , R2:0.2813\n",
      "seed: 3, 测试集: B0005, epoch:144  , loss:0.0022792784 , MAE:0.1354 , RMSE:0.1522 , RE:0.3945 , R2:0.2825\n",
      "seed: 3, 测试集: B0005, epoch:145  , loss:0.0014765974 , MAE:0.1355 , RMSE:0.1524 , RE:0.3945 , R2:0.2811\n",
      "seed: 3, 测试集: B0005, epoch:146  , loss:0.0008557786 , MAE:0.1347 , RMSE:0.1518 , RE:0.3945 , R2:0.2865\n",
      "seed: 3, 测试集: B0005, epoch:147  , loss:0.0010585057 , MAE:0.1356 , RMSE:0.1525 , RE:0.3945 , R2:0.2805\n",
      "seed: 3, 测试集: B0005, epoch:148  , loss:0.0035199472 , MAE:0.1355 , RMSE:0.1523 , RE:0.3945 , R2:0.2818\n",
      "seed: 3, 测试集: B0005, epoch:149  , loss:0.0005596750 , MAE:0.1349 , RMSE:0.1517 , RE:0.3945 , R2:0.2872\n",
      "seed: 3, 测试集: B0005, epoch:150  , loss:0.0017405059 , MAE:0.1349 , RMSE:0.1517 , RE:0.3945 , R2:0.2879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0005, epoch:151  , loss:0.0020356567 , MAE:0.1351 , RMSE:0.1519 , RE:0.3945 , R2:0.2856\n",
      "seed: 3, 测试集: B0005, epoch:152  , loss:0.0023278110 , MAE:0.1342 , RMSE:0.1511 , RE:0.3945 , R2:0.2933\n",
      "seed: 3, 测试集: B0005, epoch:153  , loss:0.0007778503 , MAE:0.1341 , RMSE:0.1510 , RE:0.3945 , R2:0.2943\n",
      "seed: 3, 测试集: B0005, epoch:154  , loss:0.0023326091 , MAE:0.1350 , RMSE:0.1517 , RE:0.3945 , R2:0.2875\n",
      "seed: 3, 测试集: B0005, epoch:155  , loss:0.0027671196 , MAE:0.1346 , RMSE:0.1514 , RE:0.3945 , R2:0.2905\n",
      "seed: 3, 测试集: B0005, epoch:156  , loss:0.0010888455 , MAE:0.1350 , RMSE:0.1517 , RE:0.3945 , R2:0.2873\n",
      "seed: 3, 测试集: B0005, epoch:157  , loss:0.0016794219 , MAE:0.1336 , RMSE:0.1507 , RE:0.3945 , R2:0.2974\n",
      "seed: 3, 测试集: B0005, epoch:158  , loss:0.0028336167 , MAE:0.1336 , RMSE:0.1504 , RE:0.3945 , R2:0.2996\n",
      "seed: 3, 测试集: B0005, epoch:159  , loss:0.0046757804 , MAE:0.1336 , RMSE:0.1503 , RE:0.3945 , R2:0.3004\n",
      "seed: 3, 测试集: B0005, epoch:160  , loss:0.0005653686 , MAE:0.1343 , RMSE:0.1510 , RE:0.3945 , R2:0.2938\n",
      "seed: 3, 测试集: B0005, epoch:161  , loss:0.0007897007 , MAE:0.1333 , RMSE:0.1501 , RE:0.3945 , R2:0.3027\n",
      "seed: 3, 测试集: B0005, epoch:162  , loss:0.0024559351 , MAE:0.1333 , RMSE:0.1500 , RE:0.3945 , R2:0.3037\n",
      "seed: 3, 测试集: B0005, epoch:163  , loss:0.0003099597 , MAE:0.1332 , RMSE:0.1499 , RE:0.3945 , R2:0.3049\n",
      "seed: 3, 测试集: B0005, epoch:164  , loss:0.0001655860 , MAE:0.1338 , RMSE:0.1505 , RE:0.3945 , R2:0.2991\n",
      "seed: 3, 测试集: B0005, epoch:165  , loss:0.0010203375 , MAE:0.1336 , RMSE:0.1503 , RE:0.3945 , R2:0.3011\n",
      "seed: 3, 测试集: B0005, epoch:166  , loss:0.0006360658 , MAE:0.1328 , RMSE:0.1496 , RE:0.3945 , R2:0.3073\n",
      "seed: 3, 测试集: B0005, epoch:167  , loss:0.0015029456 , MAE:0.1329 , RMSE:0.1495 , RE:0.3945 , R2:0.3084\n",
      "seed: 3, 测试集: B0005, epoch:168  , loss:0.0012698647 , MAE:0.1331 , RMSE:0.1497 , RE:0.3945 , R2:0.3063\n",
      "seed: 3, 测试集: B0005, epoch:169  , loss:0.0007692266 , MAE:0.1326 , RMSE:0.1492 , RE:0.3945 , R2:0.3113\n",
      "seed: 3, 测试集: B0005, epoch:170  , loss:0.0015680258 , MAE:0.1326 , RMSE:0.1491 , RE:0.3945 , R2:0.3117\n",
      "seed: 3, 测试集: B0005, epoch:171  , loss:0.0017580988 , MAE:0.1327 , RMSE:0.1493 , RE:0.3945 , R2:0.3104\n",
      "seed: 3, 测试集: B0005, epoch:172  , loss:0.0008223332 , MAE:0.1321 , RMSE:0.1488 , RE:0.3945 , R2:0.3142\n",
      "seed: 3, 测试集: B0005, epoch:173  , loss:0.0010834252 , MAE:0.1325 , RMSE:0.1490 , RE:0.3945 , R2:0.3125\n",
      "seed: 3, 测试集: B0005, epoch:174  , loss:0.0004576237 , MAE:0.1321 , RMSE:0.1486 , RE:0.3945 , R2:0.3165\n",
      "seed: 3, 测试集: B0005, epoch:175  , loss:0.0002658113 , MAE:0.1320 , RMSE:0.1484 , RE:0.3945 , R2:0.3179\n",
      "seed: 3, 测试集: B0005, epoch:176  , loss:0.0014365306 , MAE:0.1320 , RMSE:0.1484 , RE:0.3945 , R2:0.3182\n",
      "seed: 3, 测试集: B0005, epoch:177  , loss:0.0004334630 , MAE:0.1322 , RMSE:0.1486 , RE:0.3945 , R2:0.3162\n",
      "seed: 3, 测试集: B0005, epoch:178  , loss:0.0007279251 , MAE:0.1315 , RMSE:0.1480 , RE:0.3945 , R2:0.3223\n",
      "seed: 3, 测试集: B0005, epoch:179  , loss:0.0022130429 , MAE:0.1316 , RMSE:0.1480 , RE:0.3945 , R2:0.3219\n",
      "seed: 3, 测试集: B0005, epoch:180  , loss:0.0018632002 , MAE:0.1312 , RMSE:0.1477 , RE:0.3945 , R2:0.3251\n",
      "seed: 3, 测试集: B0005, epoch:181  , loss:0.0013159253 , MAE:0.1313 , RMSE:0.1476 , RE:0.3945 , R2:0.3256\n",
      "seed: 3, 测试集: B0005, epoch:182  , loss:0.0010912747 , MAE:0.1310 , RMSE:0.1474 , RE:0.3945 , R2:0.3276\n",
      "seed: 3, 测试集: B0005, epoch:183  , loss:0.0019305600 , MAE:0.1311 , RMSE:0.1474 , RE:0.3945 , R2:0.3275\n",
      "seed: 3, 测试集: B0005, epoch:184  , loss:0.0033086494 , MAE:0.1307 , RMSE:0.1471 , RE:0.3945 , R2:0.3303\n",
      "seed: 3, 测试集: B0005, epoch:185  , loss:0.0021005818 , MAE:0.1307 , RMSE:0.1470 , RE:0.3945 , R2:0.3315\n",
      "seed: 3, 测试集: B0005, epoch:186  , loss:0.0019511440 , MAE:0.1307 , RMSE:0.1470 , RE:0.3945 , R2:0.3311\n",
      "seed: 3, 测试集: B0005, epoch:187  , loss:0.0010465175 , MAE:0.1316 , RMSE:0.1480 , RE:0.3945 , R2:0.3223\n",
      "seed: 3, 测试集: B0005, epoch:188  , loss:0.0017143791 , MAE:0.1304 , RMSE:0.1466 , RE:0.3945 , R2:0.3350\n",
      "seed: 3, 测试集: B0005, epoch:189  , loss:0.0017919682 , MAE:0.1302 , RMSE:0.1464 , RE:0.3945 , R2:0.3367\n",
      "seed: 3, 测试集: B0005, epoch:190  , loss:0.0012534282 , MAE:0.1300 , RMSE:0.1462 , RE:0.3945 , R2:0.3386\n",
      "seed: 3, 测试集: B0005, epoch:191  , loss:0.0003135405 , MAE:0.1299 , RMSE:0.1460 , RE:0.3945 , R2:0.3399\n",
      "seed: 3, 测试集: B0005, epoch:192  , loss:0.0037882000 , MAE:0.1298 , RMSE:0.1459 , RE:0.3945 , R2:0.3410\n",
      "seed: 3, 测试集: B0005, epoch:193  , loss:0.0028464636 , MAE:0.1302 , RMSE:0.1464 , RE:0.3945 , R2:0.3361\n",
      "seed: 3, 测试集: B0005, epoch:194  , loss:0.0010478479 , MAE:0.1294 , RMSE:0.1462 , RE:0.3945 , R2:0.3382\n",
      "seed: 3, 测试集: B0005, epoch:195  , loss:0.0006312597 , MAE:0.1295 , RMSE:0.1457 , RE:0.3945 , R2:0.3432\n",
      "seed: 3, 测试集: B0005, epoch:196  , loss:0.0003519038 , MAE:0.1292 , RMSE:0.1453 , RE:0.3945 , R2:0.3464\n",
      "seed: 3, 测试集: B0005, epoch:197  , loss:0.0009926475 , MAE:0.1290 , RMSE:0.1457 , RE:0.3945 , R2:0.3430\n",
      "seed: 3, 测试集: B0005, epoch:198  , loss:0.0014427241 , MAE:0.1297 , RMSE:0.1459 , RE:0.3945 , R2:0.3412\n",
      "seed: 3, 测试集: B0005, epoch:199  , loss:0.0013579049 , MAE:0.1287 , RMSE:0.1448 , RE:0.3945 , R2:0.3511\n",
      "seed: 3, 测试集: B0005, epoch:200  , loss:0.0011057315 , MAE:0.1286 , RMSE:0.1446 , RE:0.3945 , R2:0.3524\n",
      "以电池 B0006 为测试数据的 数据集 开始训练\n",
      "seed: 3, 测试集: B0006, epoch:1    , loss:3.4197087288 , MAE:1.7436 , RMSE:1.7574 , RE:0.9892 , R2:-62.3347\n",
      "seed: 3, 测试集: B0006, epoch:2    , loss:2.9889574051 , MAE:1.7368 , RMSE:1.7507 , RE:0.9892 , R2:-61.8520\n",
      "seed: 3, 测试集: B0006, epoch:3    , loss:2.9611842632 , MAE:1.7303 , RMSE:1.7442 , RE:0.9892 , R2:-61.3850\n",
      "seed: 3, 测试集: B0006, epoch:4    , loss:3.2333424091 , MAE:1.7238 , RMSE:1.7377 , RE:0.9892 , R2:-60.9236\n",
      "seed: 3, 测试集: B0006, epoch:5    , loss:2.6643826962 , MAE:1.7172 , RMSE:1.7312 , RE:0.9892 , R2:-60.4613\n",
      "seed: 3, 测试集: B0006, epoch:6    , loss:3.1255373955 , MAE:1.7105 , RMSE:1.7246 , RE:0.9892 , R2:-59.9877\n",
      "seed: 3, 测试集: B0006, epoch:7    , loss:3.2398138046 , MAE:1.7035 , RMSE:1.7175 , RE:0.9892 , R2:-59.4925\n",
      "seed: 3, 测试集: B0006, epoch:8    , loss:2.4876513481 , MAE:1.6962 , RMSE:1.7102 , RE:0.9892 , R2:-58.9793\n",
      "seed: 3, 测试集: B0006, epoch:9    , loss:2.9004244804 , MAE:1.6886 , RMSE:1.7027 , RE:0.9892 , R2:-58.4488\n",
      "seed: 3, 测试集: B0006, epoch:10   , loss:3.0101721287 , MAE:1.6806 , RMSE:1.6947 , RE:0.9892 , R2:-57.8953\n",
      "seed: 3, 测试集: B0006, epoch:11   , loss:2.2518162727 , MAE:1.6719 , RMSE:1.6860 , RE:0.9892 , R2:-57.2902\n",
      "seed: 3, 测试集: B0006, epoch:12   , loss:2.8971166611 , MAE:1.6623 , RMSE:1.6764 , RE:0.9892 , R2:-56.6286\n",
      "seed: 3, 测试集: B0006, epoch:13   , loss:2.2518916130 , MAE:1.6504 , RMSE:1.6644 , RE:0.9892 , R2:-55.8070\n",
      "seed: 3, 测试集: B0006, epoch:14   , loss:2.1786742210 , MAE:1.6366 , RMSE:1.6506 , RE:0.9892 , R2:-54.8688\n",
      "seed: 3, 测试集: B0006, epoch:15   , loss:2.5693724155 , MAE:1.6207 , RMSE:1.6347 , RE:0.9892 , R2:-53.7977\n",
      "seed: 3, 测试集: B0006, epoch:16   , loss:1.8268170357 , MAE:1.6019 , RMSE:1.6159 , RE:0.9892 , R2:-52.5471\n",
      "seed: 3, 测试集: B0006, epoch:17   , loss:1.6721016169 , MAE:1.5807 , RMSE:1.5947 , RE:0.9892 , R2:-51.1468\n",
      "seed: 3, 测试集: B0006, epoch:18   , loss:1.3511086702 , MAE:1.5565 , RMSE:1.5705 , RE:0.9892 , R2:-49.5778\n",
      "seed: 3, 测试集: B0006, epoch:19   , loss:1.4099905491 , MAE:1.5290 , RMSE:1.5430 , RE:0.9892 , R2:-47.8213\n",
      "seed: 3, 测试集: B0006, epoch:20   , loss:1.1017369032 , MAE:1.4957 , RMSE:1.5098 , RE:0.9892 , R2:-45.7456\n",
      "seed: 3, 测试集: B0006, epoch:21   , loss:0.8058993816 , MAE:1.4565 , RMSE:1.4708 , RE:0.9892 , R2:-43.3574\n",
      "seed: 3, 测试集: B0006, epoch:22   , loss:0.8643597364 , MAE:1.4094 , RMSE:1.4238 , RE:0.9892 , R2:-40.5714\n",
      "seed: 3, 测试集: B0006, epoch:23   , loss:0.5082297921 , MAE:1.3520 , RMSE:1.3667 , RE:0.9892 , R2:-37.3033\n",
      "seed: 3, 测试集: B0006, epoch:24   , loss:0.3371517658 , MAE:1.2861 , RMSE:1.3010 , RE:0.9892 , R2:-33.7111\n",
      "seed: 3, 测试集: B0006, epoch:25   , loss:0.1817263067 , MAE:1.1994 , RMSE:1.2141 , RE:0.9892 , R2:-29.2292\n",
      "seed: 3, 测试集: B0006, epoch:26   , loss:0.1248152405 , MAE:1.0694 , RMSE:1.0840 , RE:0.9677 , R2:-23.0956\n",
      "seed: 3, 测试集: B0006, epoch:27   , loss:0.0463505946 , MAE:0.8841 , RMSE:0.8989 , RE:0.9462 , R2:-15.5678\n",
      "seed: 3, 测试集: B0006, epoch:28   , loss:0.0311655886 , MAE:0.6729 , RMSE:0.6883 , RE:0.9140 , R2:-8.7140\n",
      "seed: 3, 测试集: B0006, epoch:29   , loss:0.0081888819 , MAE:0.4683 , RMSE:0.4838 , RE:0.8495 , R2:-3.8007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0006, epoch:30   , loss:0.0020733038 , MAE:0.2796 , RMSE:0.2965 , RE:0.7312 , R2:-0.8033\n",
      "seed: 3, 测试集: B0006, epoch:31   , loss:0.0001288557 , MAE:0.1358 , RMSE:0.1594 , RE:0.4946 , R2:0.4789\n",
      "seed: 3, 测试集: B0006, epoch:32   , loss:0.0003413736 , MAE:0.1072 , RMSE:0.1287 , RE:0.4301 , R2:0.6604\n",
      "seed: 3, 测试集: B0006, epoch:33   , loss:0.0000445763 , MAE:0.1195 , RMSE:0.1427 , RE:0.6344 , R2:0.5822\n",
      "seed: 3, 测试集: B0006, epoch:34   , loss:0.0004031289 , MAE:0.1282 , RMSE:0.1528 , RE:0.6344 , R2:0.5210\n",
      "seed: 3, 测试集: B0006, epoch:35   , loss:0.0006064777 , MAE:0.1325 , RMSE:0.1577 , RE:0.6344 , R2:0.4898\n",
      "seed: 3, 测试集: B0006, epoch:36   , loss:0.0015107098 , MAE:0.1356 , RMSE:0.1614 , RE:0.6344 , R2:0.4657\n",
      "seed: 3, 测试集: B0006, epoch:37   , loss:0.0020024641 , MAE:0.1371 , RMSE:0.1631 , RE:0.6344 , R2:0.4544\n",
      "seed: 3, 测试集: B0006, epoch:38   , loss:0.0002991478 , MAE:0.1393 , RMSE:0.1658 , RE:0.6344 , R2:0.4361\n",
      "seed: 3, 测试集: B0006, epoch:39   , loss:0.0006605627 , MAE:0.1362 , RMSE:0.1622 , RE:0.6344 , R2:0.4608\n",
      "seed: 3, 测试集: B0006, epoch:40   , loss:0.0007495645 , MAE:0.1350 , RMSE:0.1607 , RE:0.6344 , R2:0.4701\n",
      "seed: 3, 测试集: B0006, epoch:41   , loss:0.0003421407 , MAE:0.1338 , RMSE:0.1593 , RE:0.6344 , R2:0.4799\n",
      "seed: 3, 测试集: B0006, epoch:42   , loss:0.0009398448 , MAE:0.1336 , RMSE:0.1591 , RE:0.6344 , R2:0.4809\n",
      "seed: 3, 测试集: B0006, epoch:43   , loss:0.0003605731 , MAE:0.1325 , RMSE:0.1578 , RE:0.6344 , R2:0.4897\n",
      "seed: 3, 测试集: B0006, epoch:44   , loss:0.0014343471 , MAE:0.1303 , RMSE:0.1552 , RE:0.6344 , R2:0.5060\n",
      "seed: 3, 测试集: B0006, epoch:45   , loss:0.0004251239 , MAE:0.1331 , RMSE:0.1585 , RE:0.6344 , R2:0.4851\n",
      "seed: 3, 测试集: B0006, epoch:46   , loss:0.0004419560 , MAE:0.1333 , RMSE:0.1588 , RE:0.6344 , R2:0.4832\n",
      "seed: 3, 测试集: B0006, epoch:47   , loss:0.0017626795 , MAE:0.1334 , RMSE:0.1589 , RE:0.6344 , R2:0.4822\n",
      "seed: 3, 测试集: B0006, epoch:48   , loss:0.0001747036 , MAE:0.1338 , RMSE:0.1594 , RE:0.6344 , R2:0.4792\n",
      "seed: 3, 测试集: B0006, epoch:49   , loss:0.0003951697 , MAE:0.1323 , RMSE:0.1576 , RE:0.6344 , R2:0.4909\n",
      "seed: 3, 测试集: B0006, epoch:50   , loss:0.0006339503 , MAE:0.1307 , RMSE:0.1558 , RE:0.6344 , R2:0.5023\n",
      "seed: 3, 测试集: B0006, epoch:51   , loss:0.0002227964 , MAE:0.1338 , RMSE:0.1594 , RE:0.6344 , R2:0.4788\n",
      "seed: 3, 测试集: B0006, epoch:52   , loss:0.0011684420 , MAE:0.1313 , RMSE:0.1565 , RE:0.6344 , R2:0.4980\n",
      "seed: 3, 测试集: B0006, epoch:53   , loss:0.0000793887 , MAE:0.1344 , RMSE:0.1600 , RE:0.6344 , R2:0.4747\n",
      "seed: 3, 测试集: B0006, epoch:54   , loss:0.0003176306 , MAE:0.1349 , RMSE:0.1606 , RE:0.6344 , R2:0.4709\n",
      "seed: 3, 测试集: B0006, epoch:55   , loss:0.0003699683 , MAE:0.1347 , RMSE:0.1605 , RE:0.6344 , R2:0.4719\n",
      "seed: 3, 测试集: B0006, epoch:56   , loss:0.0004057854 , MAE:0.1309 , RMSE:0.1560 , RE:0.6344 , R2:0.5012\n",
      "seed: 3, 测试集: B0006, epoch:57   , loss:0.0011831606 , MAE:0.1280 , RMSE:0.1527 , RE:0.6344 , R2:0.5221\n",
      "seed: 3, 测试集: B0006, epoch:58   , loss:0.0000423426 , MAE:0.1208 , RMSE:0.1444 , RE:0.6344 , R2:0.5725\n",
      "seed: 3, 测试集: B0006, epoch:59   , loss:0.0002357308 , MAE:0.1230 , RMSE:0.1472 , RE:0.6344 , R2:0.5559\n",
      "seed: 3, 测试集: B0006, epoch:60   , loss:0.0002362088 , MAE:0.1211 , RMSE:0.1450 , RE:0.6344 , R2:0.5690\n",
      "seed: 3, 测试集: B0006, epoch:61   , loss:0.0002992668 , MAE:0.1187 , RMSE:0.1422 , RE:0.6344 , R2:0.5856\n",
      "seed: 3, 测试集: B0006, epoch:62   , loss:0.0010697332 , MAE:0.1220 , RMSE:0.1461 , RE:0.6344 , R2:0.5621\n",
      "seed: 3, 测试集: B0006, epoch:63   , loss:0.0001928324 , MAE:0.1232 , RMSE:0.1476 , RE:0.6344 , R2:0.5531\n",
      "seed: 3, 测试集: B0006, epoch:64   , loss:0.0001107410 , MAE:0.1184 , RMSE:0.1418 , RE:0.6344 , R2:0.5876\n",
      "seed: 3, 测试集: B0006, epoch:65   , loss:0.0024536508 , MAE:0.1168 , RMSE:0.1399 , RE:0.6344 , R2:0.5985\n",
      "seed: 3, 测试集: B0006, epoch:66   , loss:0.0001825378 , MAE:0.1283 , RMSE:0.1540 , RE:0.6344 , R2:0.5137\n",
      "seed: 3, 测试集: B0006, epoch:67   , loss:0.0011191211 , MAE:0.1192 , RMSE:0.1429 , RE:0.6344 , R2:0.5814\n",
      "seed: 3, 测试集: B0006, epoch:68   , loss:0.0000992378 , MAE:0.1192 , RMSE:0.1429 , RE:0.6344 , R2:0.5810\n",
      "seed: 3, 测试集: B0006, epoch:69   , loss:0.0003441251 , MAE:0.1187 , RMSE:0.1423 , RE:0.6344 , R2:0.5849\n",
      "seed: 3, 测试集: B0006, epoch:70   , loss:0.0001544675 , MAE:0.1153 , RMSE:0.1382 , RE:0.6344 , R2:0.6086\n",
      "seed: 3, 测试集: B0006, epoch:71   , loss:0.0011060914 , MAE:0.1146 , RMSE:0.1373 , RE:0.6344 , R2:0.6134\n",
      "seed: 3, 测试集: B0006, epoch:72   , loss:0.0001491262 , MAE:0.1198 , RMSE:0.1436 , RE:0.6344 , R2:0.5771\n",
      "seed: 3, 测试集: B0006, epoch:73   , loss:0.0007848545 , MAE:0.1082 , RMSE:0.1295 , RE:0.6344 , R2:0.6563\n",
      "seed: 3, 测试集: B0006, epoch:74   , loss:0.0002566959 , MAE:0.1282 , RMSE:0.1537 , RE:0.6344 , R2:0.5156\n",
      "seed: 3, 测试集: B0006, epoch:75   , loss:0.0001324112 , MAE:0.1088 , RMSE:0.1301 , RE:0.6344 , R2:0.6530\n",
      "seed: 3, 测试集: B0006, epoch:76   , loss:0.0001673856 , MAE:0.1122 , RMSE:0.1341 , RE:0.6344 , R2:0.6310\n",
      "seed: 3, 测试集: B0006, epoch:77   , loss:0.0010887941 , MAE:0.1156 , RMSE:0.1382 , RE:0.6344 , R2:0.6083\n",
      "seed: 3, 测试集: B0006, epoch:78   , loss:0.0002174479 , MAE:0.1207 , RMSE:0.1444 , RE:0.6344 , R2:0.5726\n",
      "seed: 3, 测试集: B0006, epoch:79   , loss:0.0000688419 , MAE:0.1072 , RMSE:0.1278 , RE:0.6344 , R2:0.6651\n",
      "seed: 3, 测试集: B0006, epoch:80   , loss:0.0018294140 , MAE:0.1117 , RMSE:0.1331 , RE:0.6344 , R2:0.6367\n",
      "seed: 3, 测试集: B0006, epoch:81   , loss:0.0005099382 , MAE:0.1194 , RMSE:0.1427 , RE:0.6344 , R2:0.5826\n",
      "seed: 3, 测试集: B0006, epoch:82   , loss:0.0014772429 , MAE:0.1123 , RMSE:0.1338 , RE:0.6344 , R2:0.6330\n",
      "seed: 3, 测试集: B0006, epoch:83   , loss:0.0013049041 , MAE:0.1168 , RMSE:0.1393 , RE:0.6344 , R2:0.6023\n",
      "seed: 3, 测试集: B0006, epoch:84   , loss:0.0010310846 , MAE:0.1077 , RMSE:0.1278 , RE:0.6344 , R2:0.6651\n",
      "seed: 3, 测试集: B0006, epoch:85   , loss:0.0001634497 , MAE:0.1195 , RMSE:0.1425 , RE:0.6344 , R2:0.5835\n",
      "seed: 3, 测试集: B0006, epoch:86   , loss:0.0001141671 , MAE:0.1024 , RMSE:0.1211 , RE:0.6344 , R2:0.6992\n",
      "seed: 3, 测试集: B0006, epoch:87   , loss:0.0000900973 , MAE:0.1014 , RMSE:0.1197 , RE:0.6344 , R2:0.7060\n",
      "seed: 3, 测试集: B0006, epoch:88   , loss:0.0005972127 , MAE:0.1092 , RMSE:0.1295 , RE:0.6344 , R2:0.6563\n",
      "seed: 3, 测试集: B0006, epoch:89   , loss:0.0002816768 , MAE:0.1037 , RMSE:0.1225 , RE:0.6344 , R2:0.6921\n",
      "seed: 3, 测试集: B0006, epoch:90   , loss:0.0003926374 , MAE:0.1053 , RMSE:0.1244 , RE:0.6344 , R2:0.6828\n",
      "seed: 3, 测试集: B0006, epoch:91   , loss:0.0005268218 , MAE:0.1027 , RMSE:0.1211 , RE:0.6344 , R2:0.6992\n",
      "seed: 3, 测试集: B0006, epoch:92   , loss:0.0016087496 , MAE:0.1125 , RMSE:0.1333 , RE:0.6344 , R2:0.6358\n",
      "seed: 3, 测试集: B0006, epoch:93   , loss:0.0001094380 , MAE:0.1184 , RMSE:0.1404 , RE:0.6344 , R2:0.5958\n",
      "seed: 3, 测试集: B0006, epoch:94   , loss:0.0000362945 , MAE:0.1001 , RMSE:0.1175 , RE:0.6344 , R2:0.7170\n",
      "seed: 3, 测试集: B0006, epoch:95   , loss:0.0001499414 , MAE:0.0997 , RMSE:0.1170 , RE:0.6344 , R2:0.7194\n",
      "seed: 3, 测试集: B0006, epoch:96   , loss:0.0001084173 , MAE:0.1092 , RMSE:0.1288 , RE:0.6344 , R2:0.6600\n",
      "seed: 3, 测试集: B0006, epoch:97   , loss:0.0011072764 , MAE:0.1101 , RMSE:0.1297 , RE:0.6344 , R2:0.6552\n",
      "seed: 3, 测试集: B0006, epoch:98   , loss:0.0004203846 , MAE:0.1136 , RMSE:0.1340 , RE:0.6344 , R2:0.6319\n",
      "seed: 3, 测试集: B0006, epoch:99   , loss:0.0002954644 , MAE:0.1038 , RMSE:0.1217 , RE:0.6344 , R2:0.6964\n",
      "seed: 3, 测试集: B0006, epoch:100  , loss:0.0000637510 , MAE:0.1051 , RMSE:0.1232 , RE:0.6344 , R2:0.6886\n",
      "seed: 3, 测试集: B0006, epoch:101  , loss:0.0000405164 , MAE:0.0957 , RMSE:0.1114 , RE:0.5806 , R2:0.7455\n",
      "seed: 3, 测试集: B0006, epoch:102  , loss:0.0001976407 , MAE:0.1083 , RMSE:0.1269 , RE:0.6344 , R2:0.6697\n",
      "seed: 3, 测试集: B0006, epoch:103  , loss:0.0001672298 , MAE:0.0955 , RMSE:0.1110 , RE:0.5591 , R2:0.7475\n",
      "seed: 3, 测试集: B0006, epoch:104  , loss:0.0000864532 , MAE:0.0919 , RMSE:0.1065 , RE:0.5054 , R2:0.7676\n",
      "seed: 3, 测试集: B0006, epoch:105  , loss:0.0001067715 , MAE:0.1084 , RMSE:0.1266 , RE:0.6344 , R2:0.6712\n",
      "seed: 3, 测试集: B0006, epoch:106  , loss:0.0000525835 , MAE:0.1065 , RMSE:0.1241 , RE:0.6344 , R2:0.6841\n",
      "seed: 3, 测试集: B0006, epoch:107  , loss:0.0000856687 , MAE:0.1006 , RMSE:0.1169 , RE:0.6129 , R2:0.7197\n",
      "seed: 3, 测试集: B0006, epoch:108  , loss:0.0002525768 , MAE:0.1228 , RMSE:0.1437 , RE:0.6344 , R2:0.5768\n",
      "seed: 3, 测试集: B0006, epoch:109  , loss:0.0001271701 , MAE:0.0891 , RMSE:0.1025 , RE:0.4516 , R2:0.7845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0006, epoch:110  , loss:0.0001465655 , MAE:0.1112 , RMSE:0.1294 , RE:0.6344 , R2:0.6564\n",
      "seed: 3, 测试集: B0006, epoch:111  , loss:0.0001559183 , MAE:0.1068 , RMSE:0.1240 , RE:0.6344 , R2:0.6848\n",
      "seed: 3, 测试集: B0006, epoch:112  , loss:0.0000383015 , MAE:0.1020 , RMSE:0.1180 , RE:0.5914 , R2:0.7146\n",
      "seed: 3, 测试集: B0006, epoch:113  , loss:0.0002269332 , MAE:0.0996 , RMSE:0.1149 , RE:0.5591 , R2:0.7292\n",
      "seed: 3, 测试集: B0006, epoch:114  , loss:0.0000961976 , MAE:0.0996 , RMSE:0.1148 , RE:0.5591 , R2:0.7297\n",
      "seed: 3, 测试集: B0006, epoch:115  , loss:0.0003127322 , MAE:0.1145 , RMSE:0.1327 , RE:0.6344 , R2:0.6387\n",
      "seed: 3, 测试集: B0006, epoch:116  , loss:0.0002927699 , MAE:0.0995 , RMSE:0.1145 , RE:0.5376 , R2:0.7314\n",
      "seed: 3, 测试集: B0006, epoch:117  , loss:0.0000786119 , MAE:0.0935 , RMSE:0.1071 , RE:0.4731 , R2:0.7647\n",
      "seed: 3, 测试集: B0006, epoch:118  , loss:0.0000338577 , MAE:0.1076 , RMSE:0.1240 , RE:0.6237 , R2:0.6847\n",
      "seed: 3, 测试集: B0006, epoch:119  , loss:0.0000341903 , MAE:0.1101 , RMSE:0.1269 , RE:0.6344 , R2:0.6700\n",
      "seed: 3, 测试集: B0006, epoch:120  , loss:0.0003620582 , MAE:0.1008 , RMSE:0.1155 , RE:0.5376 , R2:0.7264\n",
      "seed: 3, 测试集: B0006, epoch:121  , loss:0.0001267361 , MAE:0.1167 , RMSE:0.1344 , RE:0.6344 , R2:0.6294\n",
      "seed: 3, 测试集: B0006, epoch:122  , loss:0.0001486075 , MAE:0.0800 , RMSE:0.0904 , RE:0.3441 , R2:0.8326\n",
      "seed: 3, 测试集: B0006, epoch:123  , loss:0.0001612205 , MAE:0.1235 , RMSE:0.1423 , RE:0.6344 , R2:0.5847\n",
      "seed: 3, 测试集: B0006, epoch:124  , loss:0.0001488365 , MAE:0.0925 , RMSE:0.1052 , RE:0.4409 , R2:0.7730\n",
      "seed: 3, 测试集: B0006, epoch:125  , loss:0.0007787501 , MAE:0.1204 , RMSE:0.1384 , RE:0.6344 , R2:0.6072\n",
      "seed: 3, 测试集: B0006, epoch:126  , loss:0.0018715082 , MAE:0.1191 , RMSE:0.1367 , RE:0.6344 , R2:0.6167\n",
      "seed: 3, 测试集: B0006, epoch:127  , loss:0.0000654785 , MAE:0.1087 , RMSE:0.1243 , RE:0.5914 , R2:0.6832\n",
      "seed: 3, 测试集: B0006, epoch:128  , loss:0.0000452480 , MAE:0.1057 , RMSE:0.1206 , RE:0.5484 , R2:0.7018\n",
      "seed: 3, 测试集: B0006, epoch:129  , loss:0.0002385986 , MAE:0.0991 , RMSE:0.1126 , RE:0.4839 , R2:0.7401\n",
      "seed: 3, 测试集: B0006, epoch:130  , loss:0.0001517793 , MAE:0.1204 , RMSE:0.1379 , RE:0.6344 , R2:0.6102\n",
      "seed: 3, 测试集: B0006, epoch:131  , loss:0.0004191285 , MAE:0.0976 , RMSE:0.1106 , RE:0.4731 , R2:0.7492\n",
      "seed: 3, 测试集: B0006, epoch:132  , loss:0.0004892207 , MAE:0.1056 , RMSE:0.1201 , RE:0.5376 , R2:0.7042\n",
      "seed: 3, 测试集: B0006, epoch:133  , loss:0.0003314707 , MAE:0.1353 , RMSE:0.1550 , RE:0.6344 , R2:0.5073\n",
      "seed: 3, 测试集: B0006, epoch:134  , loss:0.0001021030 , MAE:0.1214 , RMSE:0.1386 , RE:0.6344 , R2:0.6061\n",
      "seed: 3, 测试集: B0006, epoch:135  , loss:0.0003036367 , MAE:0.0868 , RMSE:0.0976 , RE:0.3763 , R2:0.8046\n",
      "seed: 3, 测试集: B0006, epoch:136  , loss:0.0000435165 , MAE:0.1140 , RMSE:0.1297 , RE:0.6022 , R2:0.6550\n",
      "seed: 3, 测试集: B0006, epoch:137  , loss:0.0000867328 , MAE:0.1033 , RMSE:0.1169 , RE:0.5054 , R2:0.7198\n",
      "seed: 3, 测试集: B0006, epoch:138  , loss:0.0001951617 , MAE:0.1102 , RMSE:0.1250 , RE:0.5591 , R2:0.6795\n",
      "seed: 3, 测试集: B0006, epoch:139  , loss:0.0000406809 , MAE:0.1146 , RMSE:0.1301 , RE:0.6022 , R2:0.6526\n",
      "seed: 3, 测试集: B0006, epoch:140  , loss:0.0001285436 , MAE:0.1227 , RMSE:0.1396 , RE:0.6344 , R2:0.6002\n",
      "seed: 3, 测试集: B0006, epoch:141  , loss:0.0001334861 , MAE:0.1052 , RMSE:0.1188 , RE:0.5054 , R2:0.7106\n",
      "seed: 3, 测试集: B0006, epoch:142  , loss:0.0001127704 , MAE:0.1186 , RMSE:0.1347 , RE:0.6237 , R2:0.6280\n",
      "seed: 3, 测试集: B0006, epoch:143  , loss:0.0000727108 , MAE:0.1023 , RMSE:0.1152 , RE:0.4839 , R2:0.7278\n",
      "seed: 3, 测试集: B0006, epoch:144  , loss:0.0000389384 , MAE:0.1216 , RMSE:0.1380 , RE:0.6344 , R2:0.6093\n",
      "seed: 3, 测试集: B0006, epoch:145  , loss:0.0002002582 , MAE:0.1188 , RMSE:0.1347 , RE:0.6129 , R2:0.6281\n",
      "seed: 3, 测试集: B0006, epoch:146  , loss:0.0000580085 , MAE:0.1081 , RMSE:0.1219 , RE:0.5161 , R2:0.6953\n",
      "seed: 3, 测试集: B0006, epoch:147  , loss:0.0005493902 , MAE:0.1279 , RMSE:0.1452 , RE:0.6344 , R2:0.5676\n",
      "seed: 3, 测试集: B0006, epoch:148  , loss:0.0001573143 , MAE:0.1178 , RMSE:0.1333 , RE:0.6022 , R2:0.6354\n",
      "seed: 3, 测试集: B0006, epoch:149  , loss:0.0000565266 , MAE:0.1262 , RMSE:0.1431 , RE:0.6344 , R2:0.5803\n",
      "seed: 3, 测试集: B0006, epoch:150  , loss:0.0003380566 , MAE:0.1084 , RMSE:0.1220 , RE:0.5161 , R2:0.6947\n",
      "seed: 3, 测试集: B0006, epoch:151  , loss:0.0000141396 , MAE:0.1158 , RMSE:0.1308 , RE:0.5699 , R2:0.6493\n",
      "seed: 3, 测试集: B0006, epoch:152  , loss:0.0005817499 , MAE:0.1129 , RMSE:0.1273 , RE:0.5484 , R2:0.6676\n",
      "seed: 3, 测试集: B0006, epoch:153  , loss:0.0001696254 , MAE:0.1306 , RMSE:0.1478 , RE:0.6344 , R2:0.5523\n",
      "seed: 3, 测试集: B0006, epoch:154  , loss:0.0005034554 , MAE:0.1118 , RMSE:0.1258 , RE:0.5269 , R2:0.6754\n",
      "seed: 3, 测试集: B0006, epoch:155  , loss:0.0001503206 , MAE:0.1299 , RMSE:0.1469 , RE:0.6344 , R2:0.5576\n",
      "seed: 3, 测试集: B0006, epoch:156  , loss:0.0000408419 , MAE:0.1076 , RMSE:0.1207 , RE:0.4946 , R2:0.7014\n",
      "seed: 3, 测试集: B0006, epoch:157  , loss:0.0000832432 , MAE:0.1324 , RMSE:0.1497 , RE:0.6344 , R2:0.5407\n",
      "seed: 3, 测试集: B0006, epoch:158  , loss:0.0000638118 , MAE:0.1140 , RMSE:0.1281 , RE:0.5376 , R2:0.6634\n",
      "seed: 3, 测试集: B0006, epoch:159  , loss:0.0001525348 , MAE:0.1191 , RMSE:0.1340 , RE:0.5806 , R2:0.6318\n",
      "seed: 3, 测试集: B0006, epoch:160  , loss:0.0001041668 , MAE:0.0931 , RMSE:0.1034 , RE:0.3871 , R2:0.7806\n",
      "seed: 3, 测试集: B0006, epoch:161  , loss:0.0001606523 , MAE:0.1032 , RMSE:0.1153 , RE:0.4516 , R2:0.7276\n",
      "seed: 3, 测试集: B0006, epoch:162  , loss:0.0006600647 , MAE:0.1252 , RMSE:0.1410 , RE:0.6237 , R2:0.5925\n",
      "seed: 3, 测试集: B0006, epoch:163  , loss:0.0000161768 , MAE:0.1376 , RMSE:0.1554 , RE:0.6344 , R2:0.5047\n",
      "seed: 3, 测试集: B0006, epoch:164  , loss:0.0000989251 , MAE:0.1191 , RMSE:0.1339 , RE:0.5699 , R2:0.6324\n",
      "seed: 3, 测试集: B0006, epoch:165  , loss:0.0001047597 , MAE:0.1120 , RMSE:0.1255 , RE:0.5161 , R2:0.6768\n",
      "seed: 3, 测试集: B0006, epoch:166  , loss:0.0000327908 , MAE:0.1183 , RMSE:0.1328 , RE:0.5591 , R2:0.6383\n",
      "seed: 3, 测试集: B0006, epoch:167  , loss:0.0003716346 , MAE:0.1203 , RMSE:0.1351 , RE:0.5806 , R2:0.6255\n",
      "seed: 3, 测试集: B0006, epoch:168  , loss:0.0001644429 , MAE:0.1124 , RMSE:0.1260 , RE:0.5161 , R2:0.6747\n",
      "seed: 3, 测试集: B0006, epoch:169  , loss:0.0000930443 , MAE:0.1082 , RMSE:0.1210 , RE:0.4839 , R2:0.6999\n",
      "seed: 3, 测试集: B0006, epoch:170  , loss:0.0001087248 , MAE:0.1200 , RMSE:0.1348 , RE:0.5699 , R2:0.6276\n",
      "seed: 3, 测试集: B0006, epoch:171  , loss:0.0000808747 , MAE:0.1054 , RMSE:0.1177 , RE:0.4624 , R2:0.7159\n",
      "seed: 3, 测试集: B0006, epoch:172  , loss:0.0000297375 , MAE:0.1156 , RMSE:0.1297 , RE:0.5376 , R2:0.6553\n",
      "seed: 3, 测试集: B0006, epoch:173  , loss:0.0007494853 , MAE:0.1184 , RMSE:0.1329 , RE:0.5591 , R2:0.6380\n",
      "seed: 3, 测试集: B0006, epoch:174  , loss:0.0001763710 , MAE:0.1378 , RMSE:0.1554 , RE:0.6344 , R2:0.5051\n",
      "seed: 3, 测试集: B0006, epoch:175  , loss:0.0003511219 , MAE:0.1231 , RMSE:0.1381 , RE:0.5914 , R2:0.6088\n",
      "seed: 3, 测试集: B0006, epoch:176  , loss:0.0000926311 , MAE:0.1489 , RMSE:0.1682 , RE:0.6344 , R2:0.4198\n",
      "seed: 3, 测试集: B0006, epoch:177  , loss:0.0000490923 , MAE:0.1127 , RMSE:0.1261 , RE:0.5054 , R2:0.6739\n",
      "seed: 3, 测试集: B0006, epoch:178  , loss:0.0000333282 , MAE:0.1085 , RMSE:0.1211 , RE:0.4839 , R2:0.6991\n",
      "seed: 3, 测试集: B0006, epoch:179  , loss:0.0002130913 , MAE:0.1376 , RMSE:0.1549 , RE:0.6344 , R2:0.5082\n",
      "seed: 3, 测试集: B0006, epoch:180  , loss:0.0000373979 , MAE:0.1087 , RMSE:0.1214 , RE:0.4839 , R2:0.6976\n",
      "seed: 3, 测试集: B0006, epoch:181  , loss:0.0003209201 , MAE:0.1379 , RMSE:0.1553 , RE:0.6344 , R2:0.5057\n",
      "seed: 3, 测试集: B0006, epoch:182  , loss:0.0003397881 , MAE:0.1223 , RMSE:0.1371 , RE:0.5806 , R2:0.6144\n",
      "seed: 3, 测试集: B0006, epoch:183  , loss:0.0000436489 , MAE:0.1002 , RMSE:0.1114 , RE:0.4194 , R2:0.7456\n",
      "seed: 3, 测试集: B0006, epoch:184  , loss:0.0009919831 , MAE:0.1279 , RMSE:0.1436 , RE:0.6237 , R2:0.5769\n",
      "seed: 3, 测试集: B0006, epoch:185  , loss:0.0018657728 , MAE:0.1367 , RMSE:0.1538 , RE:0.6344 , R2:0.5151\n",
      "seed: 3, 测试集: B0006, epoch:186  , loss:0.0005330026 , MAE:0.1341 , RMSE:0.1508 , RE:0.6344 , R2:0.5335\n",
      "seed: 3, 测试集: B0006, epoch:187  , loss:0.0001899233 , MAE:0.1216 , RMSE:0.1363 , RE:0.5699 , R2:0.6190\n",
      "seed: 3, 测试集: B0006, epoch:188  , loss:0.0001378026 , MAE:0.1150 , RMSE:0.1286 , RE:0.5161 , R2:0.6610\n",
      "seed: 3, 测试集: B0006, epoch:189  , loss:0.0000513007 , MAE:0.1071 , RMSE:0.1195 , RE:0.4624 , R2:0.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0006, epoch:190  , loss:0.0003170712 , MAE:0.1350 , RMSE:0.1517 , RE:0.6344 , R2:0.5281\n",
      "seed: 3, 测试集: B0006, epoch:191  , loss:0.0000641409 , MAE:0.1336 , RMSE:0.1500 , RE:0.6344 , R2:0.5383\n",
      "seed: 3, 测试集: B0006, epoch:192  , loss:0.0001384618 , MAE:0.0943 , RMSE:0.1044 , RE:0.3763 , R2:0.7765\n",
      "seed: 3, 测试集: B0006, epoch:193  , loss:0.0000853915 , MAE:0.1186 , RMSE:0.1326 , RE:0.5376 , R2:0.6395\n",
      "seed: 3, 测试集: B0006, epoch:194  , loss:0.0000174368 , MAE:0.1213 , RMSE:0.1357 , RE:0.5591 , R2:0.6222\n",
      "seed: 3, 测试集: B0006, epoch:195  , loss:0.0002051702 , MAE:0.1397 , RMSE:0.1570 , RE:0.6344 , R2:0.4947\n",
      "seed: 3, 测试集: B0006, epoch:196  , loss:0.0002235723 , MAE:0.1102 , RMSE:0.1228 , RE:0.4839 , R2:0.6907\n",
      "seed: 3, 测试集: B0006, epoch:197  , loss:0.0002736522 , MAE:0.1174 , RMSE:0.1311 , RE:0.5269 , R2:0.6473\n",
      "seed: 3, 测试集: B0006, epoch:198  , loss:0.0002176305 , MAE:0.1379 , RMSE:0.1549 , RE:0.6344 , R2:0.5082\n",
      "seed: 3, 测试集: B0006, epoch:199  , loss:0.0001110803 , MAE:0.1046 , RMSE:0.1163 , RE:0.4409 , R2:0.7225\n",
      "seed: 3, 测试集: B0006, epoch:200  , loss:0.0000447187 , MAE:0.1147 , RMSE:0.1279 , RE:0.5054 , R2:0.6643\n",
      "以电池 B0007 为测试数据的 数据集 开始训练\n",
      "seed: 3, 测试集: B0007, epoch:1    , loss:1.9324002266 , MAE:1.3929 , RMSE:1.4009 , RE:0.9934 , R2:-86.6297\n",
      "seed: 3, 测试集: B0007, epoch:2    , loss:1.4955441952 , MAE:1.3818 , RMSE:1.3899 , RE:0.9934 , R2:-85.2495\n",
      "seed: 3, 测试集: B0007, epoch:3    , loss:1.9391162395 , MAE:1.3707 , RMSE:1.3788 , RE:0.9934 , R2:-83.8767\n",
      "seed: 3, 测试集: B0007, epoch:4    , loss:2.1305508614 , MAE:1.3592 , RMSE:1.3674 , RE:0.9934 , R2:-82.4784\n",
      "seed: 3, 测试集: B0007, epoch:5    , loss:1.4383481741 , MAE:1.3471 , RMSE:1.3553 , RE:0.9934 , R2:-81.0125\n",
      "seed: 3, 测试集: B0007, epoch:6    , loss:1.4716246128 , MAE:1.3341 , RMSE:1.3423 , RE:0.9934 , R2:-79.4455\n",
      "seed: 3, 测试集: B0007, epoch:7    , loss:1.1813782454 , MAE:1.3195 , RMSE:1.3278 , RE:0.9934 , R2:-77.7155\n",
      "seed: 3, 测试集: B0007, epoch:8    , loss:1.2492550611 , MAE:1.3030 , RMSE:1.3113 , RE:0.9934 , R2:-75.7723\n",
      "seed: 3, 测试集: B0007, epoch:9    , loss:1.1338746548 , MAE:1.2839 , RMSE:1.2922 , RE:0.9934 , R2:-73.5585\n",
      "seed: 3, 测试集: B0007, epoch:10   , loss:1.3908298016 , MAE:1.2616 , RMSE:1.2700 , RE:0.9934 , R2:-71.0161\n",
      "seed: 3, 测试集: B0007, epoch:11   , loss:1.1514942646 , MAE:1.2343 , RMSE:1.2428 , RE:0.9934 , R2:-67.9603\n",
      "seed: 3, 测试集: B0007, epoch:12   , loss:1.0084913969 , MAE:1.1990 , RMSE:1.2076 , RE:0.9934 , R2:-64.1071\n",
      "seed: 3, 测试集: B0007, epoch:13   , loss:0.7198198438 , MAE:1.1549 , RMSE:1.1637 , RE:0.9934 , R2:-59.4586\n",
      "seed: 3, 测试集: B0007, epoch:14   , loss:0.7927666903 , MAE:1.1006 , RMSE:1.1098 , RE:0.9934 , R2:-53.9881\n",
      "seed: 3, 测试集: B0007, epoch:15   , loss:0.3990020156 , MAE:1.0330 , RMSE:1.0426 , RE:0.9934 , R2:-47.5328\n",
      "seed: 3, 测试集: B0007, epoch:16   , loss:0.3170219958 , MAE:0.9507 , RMSE:0.9609 , RE:0.9934 , R2:-40.2270\n",
      "seed: 3, 测试集: B0007, epoch:17   , loss:0.2318326980 , MAE:0.8485 , RMSE:0.8597 , RE:0.9934 , R2:-31.9961\n",
      "seed: 3, 测试集: B0007, epoch:18   , loss:0.1399096847 , MAE:0.7262 , RMSE:0.7389 , RE:0.9934 , R2:-23.3743\n",
      "seed: 3, 测试集: B0007, epoch:19   , loss:0.0958391279 , MAE:0.5835 , RMSE:0.5985 , RE:0.9803 , R2:-14.9956\n",
      "seed: 3, 测试集: B0007, epoch:20   , loss:0.0273976456 , MAE:0.4341 , RMSE:0.4535 , RE:0.9605 , R2:-8.1826\n",
      "seed: 3, 测试集: B0007, epoch:21   , loss:0.0059046871 , MAE:0.3013 , RMSE:0.3283 , RE:0.9276 , R2:-3.8119\n",
      "seed: 3, 测试集: B0007, epoch:22   , loss:0.0018189399 , MAE:0.2002 , RMSE:0.2391 , RE:0.0000 , R2:-1.5517\n",
      "seed: 3, 测试集: B0007, epoch:23   , loss:0.0111686345 , MAE:0.1500 , RMSE:0.1894 , RE:0.0000 , R2:-0.6025\n",
      "seed: 3, 测试集: B0007, epoch:24   , loss:0.0061973520 , MAE:0.1335 , RMSE:0.1677 , RE:0.0000 , R2:-0.2552\n",
      "seed: 3, 测试集: B0007, epoch:25   , loss:0.0098511577 , MAE:0.1278 , RMSE:0.1590 , RE:0.0000 , R2:-0.1288\n",
      "seed: 3, 测试集: B0007, epoch:26   , loss:0.0102441888 , MAE:0.1254 , RMSE:0.1551 , RE:0.0000 , R2:-0.0744\n",
      "seed: 3, 测试集: B0007, epoch:27   , loss:0.0072807432 , MAE:0.1253 , RMSE:0.1550 , RE:0.0000 , R2:-0.0723\n",
      "seed: 3, 测试集: B0007, epoch:28   , loss:0.0032904809 , MAE:0.1263 , RMSE:0.1566 , RE:0.0000 , R2:-0.0948\n",
      "seed: 3, 测试集: B0007, epoch:29   , loss:0.0049759359 , MAE:0.1269 , RMSE:0.1576 , RE:0.0000 , R2:-0.1086\n",
      "seed: 3, 测试集: B0007, epoch:30   , loss:0.0036762196 , MAE:0.1276 , RMSE:0.1588 , RE:0.0000 , R2:-0.1255\n",
      "seed: 3, 测试集: B0007, epoch:31   , loss:0.0082469452 , MAE:0.1286 , RMSE:0.1603 , RE:0.0000 , R2:-0.1472\n",
      "seed: 3, 测试集: B0007, epoch:32   , loss:0.0039546583 , MAE:0.1309 , RMSE:0.1637 , RE:0.0000 , R2:-0.1969\n",
      "seed: 3, 测试集: B0007, epoch:33   , loss:0.0022753989 , MAE:0.1291 , RMSE:0.1612 , RE:0.0000 , R2:-0.1599\n",
      "seed: 3, 测试集: B0007, epoch:34   , loss:0.0032559594 , MAE:0.1287 , RMSE:0.1605 , RE:0.0000 , R2:-0.1498\n",
      "seed: 3, 测试集: B0007, epoch:35   , loss:0.0051767696 , MAE:0.1289 , RMSE:0.1609 , RE:0.0000 , R2:-0.1557\n",
      "seed: 3, 测试集: B0007, epoch:36   , loss:0.0005168150 , MAE:0.1269 , RMSE:0.1575 , RE:0.0000 , R2:-0.1080\n",
      "seed: 3, 测试集: B0007, epoch:37   , loss:0.0039708130 , MAE:0.1277 , RMSE:0.1590 , RE:0.0000 , R2:-0.1281\n",
      "seed: 3, 测试集: B0007, epoch:38   , loss:0.0032842797 , MAE:0.1265 , RMSE:0.1570 , RE:0.0000 , R2:-0.1007\n",
      "seed: 3, 测试集: B0007, epoch:39   , loss:0.0018466954 , MAE:0.1269 , RMSE:0.1576 , RE:0.0000 , R2:-0.1085\n",
      "seed: 3, 测试集: B0007, epoch:40   , loss:0.0082575064 , MAE:0.1269 , RMSE:0.1576 , RE:0.0000 , R2:-0.1096\n",
      "seed: 3, 测试集: B0007, epoch:41   , loss:0.0075371307 , MAE:0.1257 , RMSE:0.1557 , RE:0.0000 , R2:-0.0830\n",
      "seed: 3, 测试集: B0007, epoch:42   , loss:0.0061796680 , MAE:0.1258 , RMSE:0.1559 , RE:0.0000 , R2:-0.0854\n",
      "seed: 3, 测试集: B0007, epoch:43   , loss:0.0052469112 , MAE:0.1253 , RMSE:0.1550 , RE:0.0000 , R2:-0.0725\n",
      "seed: 3, 测试集: B0007, epoch:44   , loss:0.0028249300 , MAE:0.1274 , RMSE:0.1585 , RE:0.0000 , R2:-0.1217\n",
      "seed: 3, 测试集: B0007, epoch:45   , loss:0.0027489681 , MAE:0.1282 , RMSE:0.1597 , RE:0.0000 , R2:-0.1386\n",
      "seed: 3, 测试集: B0007, epoch:46   , loss:0.0022051248 , MAE:0.1281 , RMSE:0.1596 , RE:0.0000 , R2:-0.1374\n",
      "seed: 3, 测试集: B0007, epoch:47   , loss:0.0032673213 , MAE:0.1300 , RMSE:0.1624 , RE:0.0000 , R2:-0.1775\n",
      "seed: 3, 测试集: B0007, epoch:48   , loss:0.0050957394 , MAE:0.1307 , RMSE:0.1635 , RE:0.0000 , R2:-0.1928\n",
      "seed: 3, 测试集: B0007, epoch:49   , loss:0.0044642268 , MAE:0.1303 , RMSE:0.1629 , RE:0.0000 , R2:-0.1851\n",
      "seed: 3, 测试集: B0007, epoch:50   , loss:0.0011888235 , MAE:0.1289 , RMSE:0.1608 , RE:0.0000 , R2:-0.1549\n",
      "seed: 3, 测试集: B0007, epoch:51   , loss:0.0028494149 , MAE:0.1285 , RMSE:0.1603 , RE:0.0000 , R2:-0.1467\n",
      "seed: 3, 测试集: B0007, epoch:52   , loss:0.0006388233 , MAE:0.1283 , RMSE:0.1599 , RE:0.0000 , R2:-0.1414\n",
      "seed: 3, 测试集: B0007, epoch:53   , loss:0.0016070846 , MAE:0.1284 , RMSE:0.1601 , RE:0.0000 , R2:-0.1447\n",
      "seed: 3, 测试集: B0007, epoch:54   , loss:0.0039356519 , MAE:0.1287 , RMSE:0.1606 , RE:0.0000 , R2:-0.1511\n",
      "seed: 3, 测试集: B0007, epoch:55   , loss:0.0030736229 , MAE:0.1294 , RMSE:0.1615 , RE:0.0000 , R2:-0.1642\n",
      "seed: 3, 测试集: B0007, epoch:56   , loss:0.0002167644 , MAE:0.1302 , RMSE:0.1627 , RE:0.0000 , R2:-0.1822\n",
      "seed: 3, 测试集: B0007, epoch:57   , loss:0.0015214297 , MAE:0.1297 , RMSE:0.1619 , RE:0.0000 , R2:-0.1707\n",
      "seed: 3, 测试集: B0007, epoch:58   , loss:0.0095594088 , MAE:0.1276 , RMSE:0.1589 , RE:0.0000 , R2:-0.1267\n",
      "seed: 3, 测试集: B0007, epoch:59   , loss:0.0043568471 , MAE:0.1267 , RMSE:0.1573 , RE:0.0000 , R2:-0.1045\n",
      "seed: 3, 测试集: B0007, epoch:60   , loss:0.0007156584 , MAE:0.1273 , RMSE:0.1583 , RE:0.0000 , R2:-0.1182\n",
      "seed: 3, 测试集: B0007, epoch:61   , loss:0.0050092414 , MAE:0.1272 , RMSE:0.1581 , RE:0.0000 , R2:-0.1159\n",
      "seed: 3, 测试集: B0007, epoch:62   , loss:0.0049123433 , MAE:0.1288 , RMSE:0.1607 , RE:0.0000 , R2:-0.1531\n",
      "seed: 3, 测试集: B0007, epoch:63   , loss:0.0001323543 , MAE:0.1276 , RMSE:0.1588 , RE:0.0000 , R2:-0.1264\n",
      "seed: 3, 测试集: B0007, epoch:64   , loss:0.0040577427 , MAE:0.1276 , RMSE:0.1589 , RE:0.0000 , R2:-0.1267\n",
      "seed: 3, 测试集: B0007, epoch:65   , loss:0.0038103992 , MAE:0.1265 , RMSE:0.1571 , RE:0.0000 , R2:-0.1015\n",
      "seed: 3, 测试集: B0007, epoch:66   , loss:0.0078475755 , MAE:0.1261 , RMSE:0.1565 , RE:0.0000 , R2:-0.0931\n",
      "seed: 3, 测试集: B0007, epoch:67   , loss:0.0040029678 , MAE:0.1276 , RMSE:0.1589 , RE:0.0000 , R2:-0.1272\n",
      "seed: 3, 测试集: B0007, epoch:68   , loss:0.0073158094 , MAE:0.1249 , RMSE:0.1546 , RE:0.0000 , R2:-0.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0007, epoch:69   , loss:0.0020401194 , MAE:0.1248 , RMSE:0.1543 , RE:0.0000 , R2:-0.0633\n",
      "seed: 3, 测试集: B0007, epoch:70   , loss:0.0031065051 , MAE:0.1257 , RMSE:0.1558 , RE:0.0000 , R2:-0.0841\n",
      "seed: 3, 测试集: B0007, epoch:71   , loss:0.0029279946 , MAE:0.1245 , RMSE:0.1540 , RE:0.0000 , R2:-0.0582\n",
      "seed: 3, 测试集: B0007, epoch:72   , loss:0.0000890610 , MAE:0.1229 , RMSE:0.1514 , RE:0.0000 , R2:-0.0230\n",
      "seed: 3, 测试集: B0007, epoch:73   , loss:0.0006965564 , MAE:0.1277 , RMSE:0.1589 , RE:0.0000 , R2:-0.1270\n",
      "seed: 3, 测试集: B0007, epoch:74   , loss:0.0038463667 , MAE:0.1260 , RMSE:0.1564 , RE:0.0000 , R2:-0.0921\n",
      "seed: 3, 测试集: B0007, epoch:75   , loss:0.0029521475 , MAE:0.1265 , RMSE:0.1571 , RE:0.0000 , R2:-0.1020\n",
      "seed: 3, 测试集: B0007, epoch:76   , loss:0.0007226660 , MAE:0.1271 , RMSE:0.1580 , RE:0.0000 , R2:-0.1146\n",
      "seed: 3, 测试集: B0007, epoch:77   , loss:0.0056279362 , MAE:0.1268 , RMSE:0.1575 , RE:0.0000 , R2:-0.1081\n",
      "seed: 3, 测试集: B0007, epoch:78   , loss:0.0029956363 , MAE:0.1225 , RMSE:0.1508 , RE:0.0000 , R2:-0.0154\n",
      "seed: 3, 测试集: B0007, epoch:79   , loss:0.0006670674 , MAE:0.1280 , RMSE:0.1593 , RE:0.0000 , R2:-0.1325\n",
      "seed: 3, 测试集: B0007, epoch:80   , loss:0.0023550713 , MAE:0.1252 , RMSE:0.1552 , RE:0.0000 , R2:-0.0750\n",
      "seed: 3, 测试集: B0007, epoch:81   , loss:0.0015906767 , MAE:0.1263 , RMSE:0.1568 , RE:0.0000 , R2:-0.0974\n",
      "seed: 3, 测试集: B0007, epoch:82   , loss:0.0024442472 , MAE:0.1241 , RMSE:0.1536 , RE:0.0000 , R2:-0.0528\n",
      "seed: 3, 测试集: B0007, epoch:83   , loss:0.0027489897 , MAE:0.1244 , RMSE:0.1540 , RE:0.0000 , R2:-0.0590\n",
      "seed: 3, 测试集: B0007, epoch:84   , loss:0.0046420903 , MAE:0.1291 , RMSE:0.1607 , RE:0.0000 , R2:-0.1536\n",
      "seed: 3, 测试集: B0007, epoch:85   , loss:0.0012807719 , MAE:0.1223 , RMSE:0.1507 , RE:0.0000 , R2:-0.0143\n",
      "seed: 3, 测试集: B0007, epoch:86   , loss:0.0009999224 , MAE:0.1234 , RMSE:0.1524 , RE:0.0000 , R2:-0.0371\n",
      "seed: 3, 测试集: B0007, epoch:87   , loss:0.0084411176 , MAE:0.1285 , RMSE:0.1599 , RE:0.0000 , R2:-0.1409\n",
      "seed: 3, 测试集: B0007, epoch:88   , loss:0.0013987605 , MAE:0.1166 , RMSE:0.1409 , RE:0.0000 , R2:0.1132\n",
      "seed: 3, 测试集: B0007, epoch:89   , loss:0.0009839109 , MAE:0.1241 , RMSE:0.1535 , RE:0.0000 , R2:-0.0515\n",
      "seed: 3, 测试集: B0007, epoch:90   , loss:0.0023830086 , MAE:0.1280 , RMSE:0.1591 , RE:0.0000 , R2:-0.1305\n",
      "seed: 3, 测试集: B0007, epoch:91   , loss:0.0031453092 , MAE:0.1276 , RMSE:0.1586 , RE:0.0000 , R2:-0.1234\n",
      "seed: 3, 测试集: B0007, epoch:92   , loss:0.0029812751 , MAE:0.1229 , RMSE:0.1517 , RE:0.0000 , R2:-0.0275\n",
      "seed: 3, 测试集: B0007, epoch:93   , loss:0.0049974835 , MAE:0.1239 , RMSE:0.1532 , RE:0.0000 , R2:-0.0475\n",
      "seed: 3, 测试集: B0007, epoch:94   , loss:0.0006626975 , MAE:0.1198 , RMSE:0.1470 , RE:0.0000 , R2:0.0356\n",
      "seed: 3, 测试集: B0007, epoch:95   , loss:0.0041170511 , MAE:0.1250 , RMSE:0.1548 , RE:0.0000 , R2:-0.0695\n",
      "seed: 3, 测试集: B0007, epoch:96   , loss:0.0061134705 , MAE:0.1219 , RMSE:0.1501 , RE:0.0000 , R2:-0.0066\n",
      "seed: 3, 测试集: B0007, epoch:97   , loss:0.0004722429 , MAE:0.1195 , RMSE:0.1466 , RE:0.0000 , R2:0.0408\n",
      "seed: 3, 测试集: B0007, epoch:98   , loss:0.0058034873 , MAE:0.1260 , RMSE:0.1562 , RE:0.0000 , R2:-0.0892\n",
      "seed: 3, 测试集: B0007, epoch:99   , loss:0.0026714830 , MAE:0.1207 , RMSE:0.1484 , RE:0.0000 , R2:0.0166\n",
      "seed: 3, 测试集: B0007, epoch:100  , loss:0.0034886994 , MAE:0.1276 , RMSE:0.1583 , RE:0.0000 , R2:-0.1192\n",
      "seed: 3, 测试集: B0007, epoch:101  , loss:0.0018070415 , MAE:0.1224 , RMSE:0.1508 , RE:0.0000 , R2:-0.0158\n",
      "seed: 3, 测试集: B0007, epoch:102  , loss:0.0045516714 , MAE:0.1210 , RMSE:0.1489 , RE:0.0000 , R2:0.0101\n",
      "seed: 3, 测试集: B0007, epoch:103  , loss:0.0012415866 , MAE:0.1187 , RMSE:0.1455 , RE:0.0000 , R2:0.0544\n",
      "seed: 3, 测试集: B0007, epoch:104  , loss:0.0041826176 , MAE:0.1268 , RMSE:0.1571 , RE:0.0000 , R2:-0.1014\n",
      "seed: 3, 测试集: B0007, epoch:105  , loss:0.0022849238 , MAE:0.1203 , RMSE:0.1478 , RE:0.0000 , R2:0.0248\n",
      "seed: 3, 测试集: B0007, epoch:106  , loss:0.0009856250 , MAE:0.1238 , RMSE:0.1529 , RE:0.0000 , R2:-0.0440\n",
      "seed: 3, 测试集: B0007, epoch:107  , loss:0.0015459988 , MAE:0.1214 , RMSE:0.1494 , RE:0.0000 , R2:0.0029\n",
      "seed: 3, 测试集: B0007, epoch:108  , loss:0.0020120933 , MAE:0.1226 , RMSE:0.1511 , RE:0.0000 , R2:-0.0197\n",
      "seed: 3, 测试集: B0007, epoch:109  , loss:0.0026686036 , MAE:0.1245 , RMSE:0.1539 , RE:0.0000 , R2:-0.0572\n",
      "seed: 3, 测试集: B0007, epoch:110  , loss:0.0008956558 , MAE:0.1181 , RMSE:0.1446 , RE:0.0000 , R2:0.0658\n",
      "seed: 3, 测试集: B0007, epoch:111  , loss:0.0009161715 , MAE:0.1226 , RMSE:0.1511 , RE:0.0000 , R2:-0.0199\n",
      "seed: 3, 测试集: B0007, epoch:112  , loss:0.0004979563 , MAE:0.1257 , RMSE:0.1554 , RE:0.0000 , R2:-0.0786\n",
      "seed: 3, 测试集: B0007, epoch:113  , loss:0.0013546854 , MAE:0.1184 , RMSE:0.1451 , RE:0.0000 , R2:0.0602\n",
      "seed: 3, 测试集: B0007, epoch:114  , loss:0.0005692175 , MAE:0.1222 , RMSE:0.1505 , RE:0.0000 , R2:-0.0119\n",
      "seed: 3, 测试集: B0007, epoch:115  , loss:0.0007605689 , MAE:0.1225 , RMSE:0.1509 , RE:0.0000 , R2:-0.0169\n",
      "seed: 3, 测试集: B0007, epoch:116  , loss:0.0006934013 , MAE:0.1203 , RMSE:0.1477 , RE:0.0000 , R2:0.0258\n",
      "seed: 3, 测试集: B0007, epoch:117  , loss:0.0002065276 , MAE:0.1225 , RMSE:0.1508 , RE:0.0000 , R2:-0.0159\n",
      "seed: 3, 测试集: B0007, epoch:118  , loss:0.0016979777 , MAE:0.1229 , RMSE:0.1513 , RE:0.0000 , R2:-0.0226\n",
      "seed: 3, 测试集: B0007, epoch:119  , loss:0.0005419855 , MAE:0.1273 , RMSE:0.1571 , RE:0.0000 , R2:-0.1020\n",
      "seed: 3, 测试集: B0007, epoch:120  , loss:0.0019300112 , MAE:0.1196 , RMSE:0.1468 , RE:0.0000 , R2:0.0375\n",
      "seed: 3, 测试集: B0007, epoch:121  , loss:0.0005119897 , MAE:0.1232 , RMSE:0.1517 , RE:0.0000 , R2:-0.0278\n",
      "seed: 3, 测试集: B0007, epoch:122  , loss:0.0026702280 , MAE:0.1210 , RMSE:0.1486 , RE:0.0000 , R2:0.0135\n",
      "seed: 3, 测试集: B0007, epoch:123  , loss:0.0004182073 , MAE:0.1202 , RMSE:0.1475 , RE:0.0000 , R2:0.0280\n",
      "seed: 3, 测试集: B0007, epoch:124  , loss:0.0009280321 , MAE:0.1233 , RMSE:0.1518 , RE:0.0000 , R2:-0.0284\n",
      "seed: 3, 测试集: B0007, epoch:125  , loss:0.0056884652 , MAE:0.1187 , RMSE:0.1455 , RE:0.0000 , R2:0.0553\n",
      "seed: 3, 测试集: B0007, epoch:126  , loss:0.0031437678 , MAE:0.1191 , RMSE:0.1460 , RE:0.0000 , R2:0.0481\n",
      "seed: 3, 测试集: B0007, epoch:127  , loss:0.0049914978 , MAE:0.1167 , RMSE:0.1426 , RE:0.0000 , R2:0.0921\n",
      "seed: 3, 测试集: B0007, epoch:128  , loss:0.0031311288 , MAE:0.1154 , RMSE:0.1408 , RE:0.0000 , R2:0.1145\n",
      "seed: 3, 测试集: B0007, epoch:129  , loss:0.0004820697 , MAE:0.1250 , RMSE:0.1534 , RE:0.0000 , R2:-0.0513\n",
      "seed: 3, 测试集: B0007, epoch:130  , loss:0.0004525313 , MAE:0.1233 , RMSE:0.1512 , RE:0.0000 , R2:-0.0213\n",
      "seed: 3, 测试集: B0007, epoch:131  , loss:0.0008962083 , MAE:0.1213 , RMSE:0.1487 , RE:0.0000 , R2:0.0133\n",
      "seed: 3, 测试集: B0007, epoch:132  , loss:0.0010549277 , MAE:0.1223 , RMSE:0.1499 , RE:0.0000 , R2:-0.0027\n",
      "seed: 3, 测试集: B0007, epoch:133  , loss:0.0011029760 , MAE:0.1145 , RMSE:0.1396 , RE:0.0000 , R2:0.1296\n",
      "seed: 3, 测试集: B0007, epoch:134  , loss:0.0022862218 , MAE:0.1192 , RMSE:0.1459 , RE:0.0000 , R2:0.0502\n",
      "seed: 3, 测试集: B0007, epoch:135  , loss:0.0011869107 , MAE:0.1142 , RMSE:0.1392 , RE:0.0000 , R2:0.1352\n",
      "seed: 3, 测试集: B0007, epoch:136  , loss:0.0008547777 , MAE:0.1276 , RMSE:0.1557 , RE:0.0000 , R2:-0.0829\n",
      "seed: 3, 测试集: B0007, epoch:137  , loss:0.0044883844 , MAE:0.1110 , RMSE:0.1348 , RE:0.0000 , R2:0.1890\n",
      "seed: 3, 测试集: B0007, epoch:138  , loss:0.0011350259 , MAE:0.1215 , RMSE:0.1483 , RE:0.0000 , R2:0.0181\n",
      "seed: 3, 测试集: B0007, epoch:139  , loss:0.0015540723 , MAE:0.1206 , RMSE:0.1472 , RE:0.0000 , R2:0.0332\n",
      "seed: 3, 测试集: B0007, epoch:140  , loss:0.0006608117 , MAE:0.1081 , RMSE:0.1306 , RE:0.0000 , R2:0.2380\n",
      "seed: 3, 测试集: B0007, epoch:141  , loss:0.0004566652 , MAE:0.1347 , RMSE:0.1631 , RE:0.0000 , R2:-0.1878\n",
      "seed: 3, 测试集: B0007, epoch:142  , loss:0.0013769502 , MAE:0.1102 , RMSE:0.1337 , RE:0.0000 , R2:0.2019\n",
      "seed: 3, 测试集: B0007, epoch:143  , loss:0.0004548916 , MAE:0.1230 , RMSE:0.1495 , RE:0.0000 , R2:0.0015\n",
      "seed: 3, 测试集: B0007, epoch:144  , loss:0.0002977682 , MAE:0.1158 , RMSE:0.1409 , RE:0.0000 , R2:0.1140\n",
      "seed: 3, 测试集: B0007, epoch:145  , loss:0.0007742062 , MAE:0.1229 , RMSE:0.1493 , RE:0.0000 , R2:0.0050\n",
      "seed: 3, 测试集: B0007, epoch:146  , loss:0.0004156591 , MAE:0.1178 , RMSE:0.1431 , RE:0.0000 , R2:0.0862\n",
      "seed: 3, 测试集: B0007, epoch:147  , loss:0.0004476099 , MAE:0.1201 , RMSE:0.1457 , RE:0.0000 , R2:0.0527\n",
      "seed: 3, 测试集: B0007, epoch:148  , loss:0.0003577084 , MAE:0.1186 , RMSE:0.1438 , RE:0.0000 , R2:0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0007, epoch:149  , loss:0.0002220357 , MAE:0.1165 , RMSE:0.1412 , RE:0.0000 , R2:0.1093\n",
      "seed: 3, 测试集: B0007, epoch:150  , loss:0.0011123390 , MAE:0.1238 , RMSE:0.1497 , RE:0.0000 , R2:-0.0010\n",
      "seed: 3, 测试集: B0007, epoch:151  , loss:0.0004079378 , MAE:0.1099 , RMSE:0.1332 , RE:0.0000 , R2:0.2081\n",
      "seed: 3, 测试集: B0007, epoch:152  , loss:0.0003086660 , MAE:0.1276 , RMSE:0.1535 , RE:0.0000 , R2:-0.0526\n",
      "seed: 3, 测试集: B0007, epoch:153  , loss:0.0024129162 , MAE:0.1113 , RMSE:0.1347 , RE:0.0000 , R2:0.1897\n",
      "seed: 3, 测试集: B0007, epoch:154  , loss:0.0003860483 , MAE:0.1213 , RMSE:0.1464 , RE:0.0000 , R2:0.0436\n",
      "seed: 3, 测试集: B0007, epoch:155  , loss:0.0004181825 , MAE:0.1164 , RMSE:0.1406 , RE:0.0000 , R2:0.1180\n",
      "seed: 3, 测试集: B0007, epoch:156  , loss:0.0000885582 , MAE:0.1165 , RMSE:0.1405 , RE:0.0000 , R2:0.1180\n",
      "seed: 3, 测试集: B0007, epoch:157  , loss:0.0003357908 , MAE:0.1122 , RMSE:0.1354 , RE:0.0000 , R2:0.1811\n",
      "seed: 3, 测试集: B0007, epoch:158  , loss:0.0003001267 , MAE:0.1211 , RMSE:0.1454 , RE:0.0000 , R2:0.0557\n",
      "seed: 3, 测试集: B0007, epoch:159  , loss:0.0004932783 , MAE:0.1106 , RMSE:0.1333 , RE:0.0000 , R2:0.2069\n",
      "seed: 3, 测试集: B0007, epoch:160  , loss:0.0002030423 , MAE:0.1158 , RMSE:0.1393 , RE:0.0000 , R2:0.1335\n",
      "seed: 3, 测试集: B0007, epoch:161  , loss:0.0019932378 , MAE:0.1110 , RMSE:0.1336 , RE:0.0000 , R2:0.2027\n",
      "seed: 3, 测试集: B0007, epoch:162  , loss:0.0010559028 , MAE:0.1114 , RMSE:0.1340 , RE:0.0000 , R2:0.1986\n",
      "seed: 3, 测试集: B0007, epoch:163  , loss:0.0057654036 , MAE:0.1113 , RMSE:0.1337 , RE:0.0000 , R2:0.2014\n",
      "seed: 3, 测试集: B0007, epoch:164  , loss:0.0005037729 , MAE:0.1140 , RMSE:0.1367 , RE:0.0000 , R2:0.1654\n",
      "seed: 3, 测试集: B0007, epoch:165  , loss:0.0001301840 , MAE:0.1244 , RMSE:0.1471 , RE:0.0000 , R2:0.0341\n",
      "seed: 3, 测试集: B0007, epoch:166  , loss:0.0002629180 , MAE:0.1102 , RMSE:0.1322 , RE:0.0000 , R2:0.2202\n",
      "seed: 3, 测试集: B0007, epoch:167  , loss:0.0005434889 , MAE:0.1105 , RMSE:0.1324 , RE:0.0000 , R2:0.2172\n",
      "seed: 3, 测试集: B0007, epoch:168  , loss:0.0002483882 , MAE:0.1161 , RMSE:0.1382 , RE:0.0000 , R2:0.1473\n",
      "seed: 3, 测试集: B0007, epoch:169  , loss:0.0005257626 , MAE:0.1201 , RMSE:0.1419 , RE:0.0000 , R2:0.1012\n",
      "seed: 3, 测试集: B0007, epoch:170  , loss:0.0003784398 , MAE:0.1062 , RMSE:0.1272 , RE:0.0000 , R2:0.2781\n",
      "seed: 3, 测试集: B0007, epoch:171  , loss:0.0002274210 , MAE:0.1337 , RMSE:0.1537 , RE:0.0000 , R2:-0.0544\n",
      "seed: 3, 测试集: B0007, epoch:172  , loss:0.0011056557 , MAE:0.1047 , RMSE:0.1253 , RE:0.0000 , R2:0.2992\n",
      "seed: 3, 测试集: B0007, epoch:173  , loss:0.0006247677 , MAE:0.1167 , RMSE:0.1374 , RE:0.0000 , R2:0.1568\n",
      "seed: 3, 测试集: B0007, epoch:174  , loss:0.0024735173 , MAE:0.1107 , RMSE:0.1314 , RE:0.0000 , R2:0.2291\n",
      "seed: 3, 测试集: B0007, epoch:175  , loss:0.0030550435 , MAE:0.1103 , RMSE:0.1307 , RE:0.0000 , R2:0.2372\n",
      "seed: 3, 测试集: B0007, epoch:176  , loss:0.0000893721 , MAE:0.1172 , RMSE:0.1369 , RE:0.0000 , R2:0.1629\n",
      "seed: 3, 测试集: B0007, epoch:177  , loss:0.0002050831 , MAE:0.1096 , RMSE:0.1295 , RE:0.0000 , R2:0.2515\n",
      "seed: 3, 测试集: B0007, epoch:178  , loss:0.0003517920 , MAE:0.1140 , RMSE:0.1334 , RE:0.0000 , R2:0.2054\n",
      "seed: 3, 测试集: B0007, epoch:179  , loss:0.0004266193 , MAE:0.1220 , RMSE:0.1403 , RE:0.0000 , R2:0.1215\n",
      "seed: 3, 测试集: B0007, epoch:180  , loss:0.0004023659 , MAE:0.1101 , RMSE:0.1292 , RE:0.0000 , R2:0.2550\n",
      "seed: 3, 测试集: B0007, epoch:181  , loss:0.0006745742 , MAE:0.1225 , RMSE:0.1401 , RE:0.0000 , R2:0.1241\n",
      "seed: 3, 测试集: B0007, epoch:182  , loss:0.0002198592 , MAE:0.1189 , RMSE:0.1365 , RE:0.0000 , R2:0.1687\n",
      "seed: 3, 测试集: B0007, epoch:183  , loss:0.0001943406 , MAE:0.1029 , RMSE:0.1215 , RE:0.0000 , R2:0.3411\n",
      "seed: 3, 测试集: B0007, epoch:184  , loss:0.0028253028 , MAE:0.1220 , RMSE:0.1385 , RE:0.0000 , R2:0.1440\n",
      "seed: 3, 测试集: B0007, epoch:185  , loss:0.0020582255 , MAE:0.1013 , RMSE:0.1194 , RE:0.0000 , R2:0.3632\n",
      "seed: 3, 测试集: B0007, epoch:186  , loss:0.0004820205 , MAE:0.1168 , RMSE:0.1333 , RE:0.0000 , R2:0.2069\n",
      "seed: 3, 测试集: B0007, epoch:187  , loss:0.0002997206 , MAE:0.1230 , RMSE:0.1383 , RE:0.0263 , R2:0.1461\n",
      "seed: 3, 测试集: B0007, epoch:188  , loss:0.0003096764 , MAE:0.1191 , RMSE:0.1346 , RE:0.0000 , R2:0.1915\n",
      "seed: 3, 测试集: B0007, epoch:189  , loss:0.0003079411 , MAE:0.1192 , RMSE:0.1343 , RE:0.0000 , R2:0.1946\n",
      "seed: 3, 测试集: B0007, epoch:190  , loss:0.0003538315 , MAE:0.1157 , RMSE:0.1310 , RE:0.0000 , R2:0.2342\n",
      "seed: 3, 测试集: B0007, epoch:191  , loss:0.0003313348 , MAE:0.1234 , RMSE:0.1372 , RE:0.1447 , R2:0.1597\n",
      "seed: 3, 测试集: B0007, epoch:192  , loss:0.0005634430 , MAE:0.0991 , RMSE:0.1156 , RE:0.0000 , R2:0.4036\n",
      "seed: 3, 测试集: B0007, epoch:193  , loss:0.0049944189 , MAE:0.1091 , RMSE:0.1242 , RE:0.0000 , R2:0.3111\n",
      "seed: 3, 测试集: B0007, epoch:194  , loss:0.0002151549 , MAE:0.1248 , RMSE:0.1372 , RE:0.2105 , R2:0.1597\n",
      "seed: 3, 测试集: B0007, epoch:195  , loss:0.0002803795 , MAE:0.1257 , RMSE:0.1376 , RE:0.2368 , R2:0.1540\n",
      "seed: 3, 测试集: B0007, epoch:196  , loss:0.0004648776 , MAE:0.1157 , RMSE:0.1286 , RE:0.1053 , R2:0.2616\n",
      "seed: 3, 测试集: B0007, epoch:197  , loss:0.0005469639 , MAE:0.1126 , RMSE:0.1257 , RE:0.0658 , R2:0.2951\n",
      "seed: 3, 测试集: B0007, epoch:198  , loss:0.0001861965 , MAE:0.1103 , RMSE:0.1233 , RE:0.0329 , R2:0.3209\n",
      "seed: 3, 测试集: B0007, epoch:199  , loss:0.0002070676 , MAE:0.1344 , RMSE:0.1442 , RE:0.3355 , R2:0.0710\n",
      "seed: 3, 测试集: B0007, epoch:200  , loss:0.0003076073 , MAE:0.1205 , RMSE:0.1315 , RE:0.2171 , R2:0.2278\n",
      "以电池 B0018 为测试数据的 数据集 开始训练\n",
      "seed: 3, 测试集: B0018, epoch:1    , loss:2.6985507011 , MAE:1.6313 , RMSE:1.6364 , RE:0.9877 , R2:-159.9036\n",
      "seed: 3, 测试集: B0018, epoch:2    , loss:2.5998778343 , MAE:1.6216 , RMSE:1.6266 , RE:0.9877 , R2:-157.9910\n",
      "seed: 3, 测试集: B0018, epoch:3    , loss:2.3391227722 , MAE:1.6115 , RMSE:1.6165 , RE:0.9877 , R2:-156.0290\n",
      "seed: 3, 测试集: B0018, epoch:4    , loss:2.4049458504 , MAE:1.6008 , RMSE:1.6058 , RE:0.9877 , R2:-153.9583\n",
      "seed: 3, 测试集: B0018, epoch:5    , loss:2.0097684860 , MAE:1.5893 , RMSE:1.5943 , RE:0.9877 , R2:-151.7479\n",
      "seed: 3, 测试集: B0018, epoch:6    , loss:2.1290822029 , MAE:1.5768 , RMSE:1.5819 , RE:0.9877 , R2:-149.3652\n",
      "seed: 3, 测试集: B0018, epoch:7    , loss:2.1527206898 , MAE:1.5628 , RMSE:1.5679 , RE:0.9877 , R2:-146.7176\n",
      "seed: 3, 测试集: B0018, epoch:8    , loss:2.0678391457 , MAE:1.5465 , RMSE:1.5516 , RE:0.9877 , R2:-143.6677\n",
      "seed: 3, 测试集: B0018, epoch:9    , loss:1.7858798504 , MAE:1.5277 , RMSE:1.5328 , RE:0.9877 , R2:-140.1778\n",
      "seed: 3, 测试集: B0018, epoch:10   , loss:2.0407686234 , MAE:1.5051 , RMSE:1.5102 , RE:0.9877 , R2:-136.0429\n",
      "seed: 3, 测试集: B0018, epoch:11   , loss:1.5341460705 , MAE:1.4785 , RMSE:1.4836 , RE:0.9877 , R2:-131.2611\n",
      "seed: 3, 测试集: B0018, epoch:12   , loss:1.3496656418 , MAE:1.4473 , RMSE:1.4524 , RE:0.9877 , R2:-125.7576\n",
      "seed: 3, 测试集: B0018, epoch:13   , loss:1.2288228273 , MAE:1.4107 , RMSE:1.4158 , RE:0.9877 , R2:-119.4596\n",
      "seed: 3, 测试集: B0018, epoch:14   , loss:1.2977880239 , MAE:1.3634 , RMSE:1.3687 , RE:0.9877 , R2:-111.5657\n",
      "seed: 3, 测试集: B0018, epoch:15   , loss:0.9160682559 , MAE:1.3004 , RMSE:1.3060 , RE:0.9877 , R2:-101.4873\n",
      "seed: 3, 测试集: B0018, epoch:16   , loss:0.6754441261 , MAE:1.2220 , RMSE:1.2280 , RE:0.9877 , R2:-89.6131\n",
      "seed: 3, 测试集: B0018, epoch:17   , loss:0.4325166941 , MAE:1.1263 , RMSE:1.1329 , RE:0.9877 , R2:-76.1205\n",
      "seed: 3, 测试集: B0018, epoch:18   , loss:0.2732958198 , MAE:1.0080 , RMSE:1.0153 , RE:0.9877 , R2:-60.9435\n",
      "seed: 3, 测试集: B0018, epoch:19   , loss:0.1669493914 , MAE:0.8638 , RMSE:0.8720 , RE:0.9877 , R2:-44.6916\n",
      "seed: 3, 测试集: B0018, epoch:20   , loss:0.0893835351 , MAE:0.6972 , RMSE:0.7065 , RE:0.9753 , R2:-28.9959\n",
      "seed: 3, 测试集: B0018, epoch:21   , loss:0.0362736396 , MAE:0.5039 , RMSE:0.5150 , RE:0.9506 , R2:-14.9348\n",
      "seed: 3, 测试集: B0018, epoch:22   , loss:0.0223939195 , MAE:0.3180 , RMSE:0.3335 , RE:0.9136 , R2:-5.6833\n",
      "seed: 3, 测试集: B0018, epoch:23   , loss:0.0039490531 , MAE:0.1641 , RMSE:0.1919 , RE:0.8025 , R2:-1.2118\n",
      "seed: 3, 测试集: B0018, epoch:24   , loss:0.0024027121 , MAE:0.0964 , RMSE:0.1198 , RE:0.4321 , R2:0.1379\n",
      "seed: 3, 测试集: B0018, epoch:25   , loss:0.0027136309 , MAE:0.0938 , RMSE:0.1045 , RE:0.4321 , R2:0.3438\n",
      "seed: 3, 测试集: B0018, epoch:26   , loss:0.0059603378 , MAE:0.0981 , RMSE:0.1083 , RE:0.4321 , R2:0.2957\n",
      "seed: 3, 测试集: B0018, epoch:27   , loss:0.0036388463 , MAE:0.1004 , RMSE:0.1115 , RE:0.4321 , R2:0.2525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0018, epoch:28   , loss:0.0017528451 , MAE:0.1007 , RMSE:0.1119 , RE:0.4321 , R2:0.2473\n",
      "seed: 3, 测试集: B0018, epoch:29   , loss:0.0041151908 , MAE:0.1008 , RMSE:0.1121 , RE:0.4321 , R2:0.2448\n",
      "seed: 3, 测试集: B0018, epoch:30   , loss:0.0018077937 , MAE:0.1011 , RMSE:0.1126 , RE:0.4321 , R2:0.2384\n",
      "seed: 3, 测试集: B0018, epoch:31   , loss:0.0006955509 , MAE:0.1018 , RMSE:0.1136 , RE:0.4321 , R2:0.2252\n",
      "seed: 3, 测试集: B0018, epoch:32   , loss:0.0031011221 , MAE:0.1014 , RMSE:0.1130 , RE:0.4321 , R2:0.2324\n",
      "seed: 3, 测试集: B0018, epoch:33   , loss:0.0026865536 , MAE:0.1004 , RMSE:0.1117 , RE:0.4321 , R2:0.2508\n",
      "seed: 3, 测试集: B0018, epoch:34   , loss:0.0032988167 , MAE:0.1013 , RMSE:0.1129 , RE:0.4321 , R2:0.2337\n",
      "seed: 3, 测试集: B0018, epoch:35   , loss:0.0035213777 , MAE:0.1008 , RMSE:0.1123 , RE:0.4321 , R2:0.2419\n",
      "seed: 3, 测试集: B0018, epoch:36   , loss:0.0038583500 , MAE:0.1008 , RMSE:0.1123 , RE:0.4321 , R2:0.2424\n",
      "seed: 3, 测试集: B0018, epoch:37   , loss:0.0010362666 , MAE:0.1021 , RMSE:0.1142 , RE:0.4321 , R2:0.2158\n",
      "seed: 3, 测试集: B0018, epoch:38   , loss:0.0014933859 , MAE:0.1014 , RMSE:0.1132 , RE:0.4321 , R2:0.2303\n",
      "seed: 3, 测试集: B0018, epoch:39   , loss:0.0023482961 , MAE:0.0999 , RMSE:0.1112 , RE:0.4321 , R2:0.2576\n",
      "seed: 3, 测试集: B0018, epoch:40   , loss:0.0010973132 , MAE:0.1016 , RMSE:0.1136 , RE:0.4321 , R2:0.2251\n",
      "seed: 3, 测试集: B0018, epoch:41   , loss:0.0077361106 , MAE:0.1006 , RMSE:0.1121 , RE:0.4321 , R2:0.2444\n",
      "seed: 3, 测试集: B0018, epoch:42   , loss:0.0012674897 , MAE:0.1004 , RMSE:0.1119 , RE:0.4321 , R2:0.2474\n",
      "seed: 3, 测试集: B0018, epoch:43   , loss:0.0016872098 , MAE:0.1002 , RMSE:0.1117 , RE:0.4321 , R2:0.2505\n",
      "seed: 3, 测试集: B0018, epoch:44   , loss:0.0017340647 , MAE:0.1003 , RMSE:0.1119 , RE:0.4321 , R2:0.2475\n",
      "seed: 3, 测试集: B0018, epoch:45   , loss:0.0013391462 , MAE:0.1000 , RMSE:0.1115 , RE:0.4321 , R2:0.2527\n",
      "seed: 3, 测试集: B0018, epoch:46   , loss:0.0017579652 , MAE:0.0999 , RMSE:0.1113 , RE:0.4321 , R2:0.2555\n",
      "seed: 3, 测试集: B0018, epoch:47   , loss:0.0018018604 , MAE:0.0993 , RMSE:0.1105 , RE:0.4321 , R2:0.2666\n",
      "seed: 3, 测试集: B0018, epoch:48   , loss:0.0018719182 , MAE:0.0995 , RMSE:0.1109 , RE:0.4321 , R2:0.2609\n",
      "seed: 3, 测试集: B0018, epoch:49   , loss:0.0077523026 , MAE:0.0989 , RMSE:0.1101 , RE:0.4321 , R2:0.2719\n",
      "seed: 3, 测试集: B0018, epoch:50   , loss:0.0025715383 , MAE:0.1001 , RMSE:0.1118 , RE:0.4321 , R2:0.2494\n",
      "seed: 3, 测试集: B0018, epoch:51   , loss:0.0010846409 , MAE:0.1003 , RMSE:0.1121 , RE:0.4321 , R2:0.2442\n",
      "seed: 3, 测试集: B0018, epoch:52   , loss:0.0029958251 , MAE:0.0992 , RMSE:0.1106 , RE:0.4321 , R2:0.2645\n",
      "seed: 3, 测试集: B0018, epoch:53   , loss:0.0018316865 , MAE:0.0991 , RMSE:0.1105 , RE:0.4321 , R2:0.2667\n",
      "seed: 3, 测试集: B0018, epoch:54   , loss:0.0010768869 , MAE:0.1001 , RMSE:0.1119 , RE:0.4321 , R2:0.2474\n",
      "seed: 3, 测试集: B0018, epoch:55   , loss:0.0022513431 , MAE:0.0984 , RMSE:0.1096 , RE:0.4321 , R2:0.2784\n",
      "seed: 3, 测试集: B0018, epoch:56   , loss:0.0049180151 , MAE:0.0987 , RMSE:0.1100 , RE:0.4321 , R2:0.2732\n",
      "seed: 3, 测试集: B0018, epoch:57   , loss:0.0010788837 , MAE:0.0994 , RMSE:0.1111 , RE:0.4321 , R2:0.2587\n",
      "seed: 3, 测试集: B0018, epoch:58   , loss:0.0016811647 , MAE:0.0987 , RMSE:0.1102 , RE:0.4321 , R2:0.2709\n",
      "seed: 3, 测试集: B0018, epoch:59   , loss:0.0019392235 , MAE:0.0988 , RMSE:0.1104 , RE:0.4321 , R2:0.2681\n",
      "seed: 3, 测试集: B0018, epoch:60   , loss:0.0046590497 , MAE:0.0995 , RMSE:0.1113 , RE:0.4321 , R2:0.2554\n",
      "seed: 3, 测试集: B0018, epoch:61   , loss:0.0021259896 , MAE:0.0989 , RMSE:0.1105 , RE:0.4321 , R2:0.2658\n",
      "seed: 3, 测试集: B0018, epoch:62   , loss:0.0025791051 , MAE:0.0998 , RMSE:0.1118 , RE:0.4321 , R2:0.2483\n",
      "seed: 3, 测试集: B0018, epoch:63   , loss:0.0017539111 , MAE:0.0985 , RMSE:0.1100 , RE:0.4321 , R2:0.2728\n",
      "seed: 3, 测试集: B0018, epoch:64   , loss:0.0013441143 , MAE:0.0982 , RMSE:0.1096 , RE:0.4321 , R2:0.2782\n",
      "seed: 3, 测试集: B0018, epoch:65   , loss:0.0019493775 , MAE:0.0967 , RMSE:0.1077 , RE:0.4321 , R2:0.3036\n",
      "seed: 3, 测试集: B0018, epoch:66   , loss:0.0019050026 , MAE:0.0979 , RMSE:0.1094 , RE:0.4321 , R2:0.2814\n",
      "seed: 3, 测试集: B0018, epoch:67   , loss:0.0022658263 , MAE:0.0973 , RMSE:0.1085 , RE:0.4321 , R2:0.2921\n",
      "seed: 3, 测试集: B0018, epoch:68   , loss:0.0021755472 , MAE:0.0976 , RMSE:0.1090 , RE:0.4321 , R2:0.2865\n",
      "seed: 3, 测试集: B0018, epoch:69   , loss:0.0027128360 , MAE:0.0974 , RMSE:0.1087 , RE:0.4321 , R2:0.2895\n",
      "seed: 3, 测试集: B0018, epoch:70   , loss:0.0014551154 , MAE:0.0989 , RMSE:0.1110 , RE:0.4321 , R2:0.2600\n",
      "seed: 3, 测试集: B0018, epoch:71   , loss:0.0014852275 , MAE:0.0982 , RMSE:0.1100 , RE:0.4321 , R2:0.2729\n",
      "seed: 3, 测试集: B0018, epoch:72   , loss:0.0012422772 , MAE:0.0976 , RMSE:0.1092 , RE:0.4321 , R2:0.2839\n",
      "seed: 3, 测试集: B0018, epoch:73   , loss:0.0016856203 , MAE:0.0972 , RMSE:0.1087 , RE:0.4321 , R2:0.2898\n",
      "seed: 3, 测试集: B0018, epoch:74   , loss:0.0030044424 , MAE:0.0961 , RMSE:0.1072 , RE:0.4321 , R2:0.3096\n",
      "seed: 3, 测试集: B0018, epoch:75   , loss:0.0025117872 , MAE:0.0972 , RMSE:0.1087 , RE:0.4321 , R2:0.2897\n",
      "seed: 3, 测试集: B0018, epoch:76   , loss:0.0042749350 , MAE:0.0972 , RMSE:0.1087 , RE:0.4321 , R2:0.2894\n",
      "seed: 3, 测试集: B0018, epoch:77   , loss:0.0016994003 , MAE:0.0969 , RMSE:0.1085 , RE:0.4321 , R2:0.2927\n",
      "seed: 3, 测试集: B0018, epoch:78   , loss:0.0013583344 , MAE:0.0979 , RMSE:0.1099 , RE:0.4321 , R2:0.2738\n",
      "seed: 3, 测试集: B0018, epoch:79   , loss:0.0011215629 , MAE:0.0962 , RMSE:0.1075 , RE:0.4321 , R2:0.3055\n",
      "seed: 3, 测试集: B0018, epoch:80   , loss:0.0019069945 , MAE:0.0967 , RMSE:0.1084 , RE:0.4321 , R2:0.2943\n",
      "seed: 3, 测试集: B0018, epoch:81   , loss:0.0023971372 , MAE:0.0959 , RMSE:0.1072 , RE:0.4321 , R2:0.3089\n",
      "seed: 3, 测试集: B0018, epoch:82   , loss:0.0013572683 , MAE:0.0954 , RMSE:0.1065 , RE:0.4321 , R2:0.3185\n",
      "seed: 3, 测试集: B0018, epoch:83   , loss:0.0014813327 , MAE:0.0955 , RMSE:0.1068 , RE:0.4321 , R2:0.3146\n",
      "seed: 3, 测试集: B0018, epoch:84   , loss:0.0019257450 , MAE:0.0968 , RMSE:0.1087 , RE:0.4321 , R2:0.2899\n",
      "seed: 3, 测试集: B0018, epoch:85   , loss:0.0020821642 , MAE:0.0951 , RMSE:0.1063 , RE:0.4321 , R2:0.3214\n",
      "seed: 3, 测试集: B0018, epoch:86   , loss:0.0023393177 , MAE:0.0948 , RMSE:0.1060 , RE:0.4321 , R2:0.3251\n",
      "seed: 3, 测试集: B0018, epoch:87   , loss:0.0013166143 , MAE:0.0949 , RMSE:0.1062 , RE:0.4321 , R2:0.3228\n",
      "seed: 3, 测试集: B0018, epoch:88   , loss:0.0025309653 , MAE:0.0959 , RMSE:0.1076 , RE:0.4321 , R2:0.3046\n",
      "seed: 3, 测试集: B0018, epoch:89   , loss:0.0013820193 , MAE:0.0949 , RMSE:0.1062 , RE:0.4321 , R2:0.3225\n",
      "seed: 3, 测试集: B0018, epoch:90   , loss:0.0004032739 , MAE:0.0954 , RMSE:0.1070 , RE:0.4321 , R2:0.3114\n",
      "seed: 3, 测试集: B0018, epoch:91   , loss:0.0010781838 , MAE:0.0952 , RMSE:0.1068 , RE:0.4321 , R2:0.3142\n",
      "seed: 3, 测试集: B0018, epoch:92   , loss:0.0016592031 , MAE:0.0955 , RMSE:0.1073 , RE:0.4321 , R2:0.3084\n",
      "seed: 3, 测试集: B0018, epoch:93   , loss:0.0012557660 , MAE:0.0955 , RMSE:0.1074 , RE:0.4321 , R2:0.3071\n",
      "seed: 3, 测试集: B0018, epoch:94   , loss:0.0026579970 , MAE:0.0932 , RMSE:0.1041 , RE:0.4321 , R2:0.3494\n",
      "seed: 3, 测试集: B0018, epoch:95   , loss:0.0028079962 , MAE:0.0932 , RMSE:0.1041 , RE:0.4321 , R2:0.3482\n",
      "seed: 3, 测试集: B0018, epoch:96   , loss:0.0006598312 , MAE:0.0959 , RMSE:0.1081 , RE:0.4321 , R2:0.2984\n",
      "seed: 3, 测试集: B0018, epoch:97   , loss:0.0014358526 , MAE:0.0943 , RMSE:0.1059 , RE:0.4321 , R2:0.3259\n",
      "seed: 3, 测试集: B0018, epoch:98   , loss:0.0031079156 , MAE:0.0941 , RMSE:0.1056 , RE:0.4321 , R2:0.3299\n",
      "seed: 3, 测试集: B0018, epoch:99   , loss:0.0010514391 , MAE:0.0945 , RMSE:0.1063 , RE:0.4321 , R2:0.3212\n",
      "seed: 3, 测试集: B0018, epoch:100  , loss:0.0005579653 , MAE:0.0941 , RMSE:0.1057 , RE:0.4321 , R2:0.3283\n",
      "seed: 3, 测试集: B0018, epoch:101  , loss:0.0015701337 , MAE:0.0934 , RMSE:0.1048 , RE:0.4321 , R2:0.3403\n",
      "seed: 3, 测试集: B0018, epoch:102  , loss:0.0024769069 , MAE:0.0931 , RMSE:0.1045 , RE:0.4321 , R2:0.3442\n",
      "seed: 3, 测试集: B0018, epoch:103  , loss:0.0015219655 , MAE:0.0961 , RMSE:0.1089 , RE:0.4321 , R2:0.2871\n",
      "seed: 3, 测试集: B0018, epoch:104  , loss:0.0010941420 , MAE:0.0944 , RMSE:0.1065 , RE:0.4321 , R2:0.3182\n",
      "seed: 3, 测试集: B0018, epoch:105  , loss:0.0009747974 , MAE:0.0925 , RMSE:0.1037 , RE:0.4321 , R2:0.3532\n",
      "seed: 3, 测试集: B0018, epoch:106  , loss:0.0027301158 , MAE:0.0938 , RMSE:0.1057 , RE:0.4321 , R2:0.3288\n",
      "seed: 3, 测试集: B0018, epoch:107  , loss:0.0016489949 , MAE:0.0938 , RMSE:0.1058 , RE:0.4321 , R2:0.3269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 3, 测试集: B0018, epoch:108  , loss:0.0011720640 , MAE:0.0928 , RMSE:0.1045 , RE:0.4321 , R2:0.3437\n",
      "seed: 3, 测试集: B0018, epoch:109  , loss:0.0007618553 , MAE:0.0921 , RMSE:0.1035 , RE:0.4321 , R2:0.3562\n",
      "seed: 3, 测试集: B0018, epoch:110  , loss:0.0028202888 , MAE:0.0912 , RMSE:0.1022 , RE:0.4321 , R2:0.3722\n",
      "seed: 3, 测试集: B0018, epoch:111  , loss:0.0015529981 , MAE:0.0927 , RMSE:0.1045 , RE:0.4321 , R2:0.3440\n",
      "seed: 3, 测试集: B0018, epoch:112  , loss:0.0010366412 , MAE:0.0917 , RMSE:0.1032 , RE:0.4321 , R2:0.3602\n",
      "seed: 3, 测试集: B0018, epoch:113  , loss:0.0016118258 , MAE:0.0937 , RMSE:0.1062 , RE:0.4321 , R2:0.3220\n",
      "seed: 3, 测试集: B0018, epoch:114  , loss:0.0022424031 , MAE:0.0908 , RMSE:0.1018 , RE:0.4321 , R2:0.3769\n",
      "seed: 3, 测试集: B0018, epoch:115  , loss:0.0004172908 , MAE:0.0921 , RMSE:0.1039 , RE:0.4321 , R2:0.3508\n",
      "seed: 3, 测试集: B0018, epoch:116  , loss:0.0047719665 , MAE:0.0906 , RMSE:0.1017 , RE:0.4321 , R2:0.3783\n",
      "seed: 3, 测试集: B0018, epoch:117  , loss:0.0004197662 , MAE:0.0943 , RMSE:0.1074 , RE:0.4321 , R2:0.3064\n",
      "seed: 3, 测试集: B0018, epoch:118  , loss:0.0021276874 , MAE:0.0912 , RMSE:0.1029 , RE:0.4321 , R2:0.3634\n",
      "seed: 3, 测试集: B0018, epoch:119  , loss:0.0020278622 , MAE:0.0891 , RMSE:0.0997 , RE:0.4321 , R2:0.4025\n",
      "seed: 3, 测试集: B0018, epoch:120  , loss:0.0020197658 , MAE:0.0909 , RMSE:0.1026 , RE:0.4321 , R2:0.3676\n",
      "seed: 3, 测试集: B0018, epoch:121  , loss:0.0027918289 , MAE:0.0920 , RMSE:0.1044 , RE:0.4321 , R2:0.3456\n",
      "seed: 3, 测试集: B0018, epoch:122  , loss:0.0022104199 , MAE:0.0929 , RMSE:0.1058 , RE:0.4321 , R2:0.3279\n",
      "seed: 3, 测试集: B0018, epoch:123  , loss:0.0005258023 , MAE:0.0886 , RMSE:0.0993 , RE:0.4321 , R2:0.4073\n",
      "seed: 3, 测试集: B0018, epoch:124  , loss:0.0007965250 , MAE:0.0892 , RMSE:0.1003 , RE:0.4321 , R2:0.3956\n",
      "seed: 3, 测试集: B0018, epoch:125  , loss:0.0008299783 , MAE:0.0908 , RMSE:0.1029 , RE:0.4321 , R2:0.3633\n",
      "seed: 3, 测试集: B0018, epoch:126  , loss:0.0011013912 , MAE:0.0922 , RMSE:0.1051 , RE:0.4321 , R2:0.3364\n",
      "seed: 3, 测试集: B0018, epoch:127  , loss:0.0012636773 , MAE:0.0880 , RMSE:0.0988 , RE:0.4321 , R2:0.4134\n",
      "seed: 3, 测试集: B0018, epoch:128  , loss:0.0011726595 , MAE:0.0892 , RMSE:0.1008 , RE:0.4321 , R2:0.3897\n",
      "seed: 3, 测试集: B0018, epoch:129  , loss:0.0018292676 , MAE:0.0891 , RMSE:0.1008 , RE:0.4321 , R2:0.3900\n",
      "seed: 3, 测试集: B0018, epoch:130  , loss:0.0008838510 , MAE:0.0892 , RMSE:0.1010 , RE:0.4321 , R2:0.3867\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m以电池 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mBattery_list[i]\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 为测试数据的 数据集 开始训练\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity)\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m mae, rmse, re, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRated_Capacity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m mae_s\u001b[38;5;241m.\u001b[39mappend(mae)\n\u001b[0;32m     39\u001b[0m rmse_s\u001b[38;5;241m.\u001b[39mappend(rmse)\n",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\u001b[0m\n\u001b[0;32m      9\u001b[0m pre_list \u001b[38;5;241m=\u001b[39m predict(net, train_data, test_data, Rated_Capacity)\n\u001b[0;32m     11\u001b[0m test_y \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 13\u001b[0m mae, rmse, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m re \u001b[38;5;241m=\u001b[39m relative_error(test_y, pre_list, threshold\u001b[38;5;241m=\u001b[39mRated_Capacity \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# if (len(re_epoch_list) == 0 or (r2_epoch_list[-1] < r2)):\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mevaluation\u001b[1;34m(y_test, y_predict)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation\u001b[39m(y_test, y_predict):\n\u001b[1;32m----> 3\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_predict)\n\u001b[0;32m      5\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m sqrt(mean_squared_error(y_test, y_predict))\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\_regression.py:204\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    141\u001b[0m     {\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m ):\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    208\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    100\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    104\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# 电池额定容量\n",
    "Rated_Capacity = 2.0\n",
    "\n",
    "# 超参数\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "weight_decay = 0.0005\n",
    "num_epochs = 200\n",
    "# num_epochs = 1\n",
    "window_size = 16\n",
    "kernel_size = 2\n",
    "dropout = 0.0\n",
    "\n",
    "# 获取数据集，生成train_iter\n",
    "# 使用留一评估\n",
    "re_seed_all, mae_seed_all, rmse_seed_all, r2_seed_all = [], [], [], []\n",
    "for seed in range(2, 10):\n",
    "    print('*******************************************************************************************************************')\n",
    "    print('当前的 seed 为', seed)\n",
    "    setup_seed(seed)\n",
    "    mae_s, rmse_s, re_s, r2_s = [], [], [], []\n",
    "    for i in range(4):\n",
    "    # for i in range(1):\n",
    "        train_x, train_y, train_data, test_data = get_train_test_data(Battery_data_list, i, window_size=window_size)\n",
    "        train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "        train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "        train_iter = load_capacity_data((train_x, train_y), batch_size, is_train=True)\n",
    "\n",
    "        # 模型、损失函数、优化器\n",
    "        net = Net(1, [16] * 2, kernel_size, dropout)\n",
    "        loss = nn.MSELoss()\n",
    "        updater = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # 开始训练\n",
    "        print(f'以电池 { Battery_list[i] } 为测试数据的 数据集 开始训练')\n",
    "        #train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity)\n",
    "        mae, rmse, re, r2 = train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\n",
    "        mae_s.append(mae)\n",
    "        rmse_s.append(rmse)\n",
    "        re_s.append(re)\n",
    "        r2_s.append(r2)\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('re_s', re_s)\n",
    "    print('---------------------------------')\n",
    "    print(f're mean: {np.array(re_s).mean()}')\n",
    "    print(f'mae mean: {np.array(mae_s).mean()}')\n",
    "    print(f'rmse mean: {np.array(rmse_s).mean()}')\n",
    "    print(f'r2 mean: {np.array(r2_s).mean()}')\n",
    "    print('---------------------------------')\n",
    "\n",
    "    re_seed_all.append(np.array(re_s).mean())\n",
    "    mae_seed_all.append(np.array(mae_s).mean())\n",
    "    rmse_seed_all.append(np.array(rmse_s).mean())\n",
    "    r2_seed_all.append(np.array(r2_s).mean())\n",
    "\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "print('------------   平均值   ---------------------')\n",
    "print(f're mean: {np.array(re_seed_all).mean()}')\n",
    "print(f'mae mean: {np.array(mae_seed_all).mean()}')\n",
    "print(f'rmse mean: {np.array(rmse_seed_all).mean()}')\n",
    "print(f'r2 mean: {np.array(r2_seed_all).mean()}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "print('------------   最小值   ---------------------')\n",
    "print(f're min: {np.array(re_seed_all).min()}')\n",
    "print(f'mae min: {np.array(mae_seed_all).min()}')\n",
    "print(f'rmse min: {np.array(rmse_seed_all).min()}')\n",
    "print(f'r2 min: {np.array(r2_seed_all).max()}')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f79f9d88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T06:33:43.588255Z",
     "start_time": "2023-11-30T06:33:43.569305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = torch.Tensor([[1.8565, 1.8463, 1.8353, 1.8353, 1.8346, 1.8357, 1.8351, 1.8258, 1.8248,\n",
    "         1.8246, 1.8246, 1.8142, 1.8138, 1.8134, 1.8026, 1.8021]])\n",
    "aa = aa.type(torch.float32).to(device)\n",
    "\n",
    "print(net(aa))\n",
    "\n",
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19835692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T06:40:14.486001Z",
     "start_time": "2023-11-30T06:40:14.431426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan], device='cuda:0')),\n",
       "             ('tcn.network.0.conv1.weight_g',\n",
       "              tensor([[[nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.conv1.weight_v',\n",
       "              tensor([[[nan, nan, nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.conv2.bias', tensor([nan], device='cuda:0')),\n",
       "             ('tcn.network.0.conv2.weight_g',\n",
       "              tensor([[[nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.conv2.weight_v',\n",
       "              tensor([[[nan, nan, nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.net.0.bias', tensor([nan], device='cuda:0')),\n",
       "             ('tcn.network.0.net.0.weight_g',\n",
       "              tensor([[[nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.net.0.weight_v',\n",
       "              tensor([[[nan, nan, nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.net.4.bias', tensor([nan], device='cuda:0')),\n",
       "             ('tcn.network.0.net.4.weight_g',\n",
       "              tensor([[[nan]]], device='cuda:0')),\n",
       "             ('tcn.network.0.net.4.weight_v',\n",
       "              tensor([[[nan, nan, nan]]], device='cuda:0')),\n",
       "             ('linear.weight', tensor([[nan]], device='cuda:0')),\n",
       "             ('linear.bias', tensor([nan], device='cuda:0'))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f682c",
   "metadata": {},
   "source": [
    "## 查看模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3633b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:05:10.003864Z",
     "start_time": "2023-11-30T09:04:10.490406Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************************************\n",
      "当前的 seed 为 2\n",
      "以电池 B0005 为测试数据的 数据集 开始训练\n",
      "seed: 2, 测试集: B0005, epoch:1    , loss:1.3432395458 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4662, 0.3185], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.3972]],\n",
      "\n",
      "        [[0.3532]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[ 0.2929, -0.0030]],\n",
      "\n",
      "        [[ 0.1106,  0.0984]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-3.5668e-06,  3.5069e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.5118]],\n",
      "\n",
      "        [[0.5931]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-0.0018, -0.3052],\n",
      "         [ 0.0331, -0.3431]],\n",
      "\n",
      "        [[ 0.2064,  0.1806],\n",
      "         [ 0.0458,  0.3046]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4662, 0.3185], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.3972]],\n",
      "\n",
      "        [[0.3532]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[ 0.2929, -0.0030]],\n",
      "\n",
      "        [[ 0.1106,  0.0984]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-3.5668e-06,  3.5069e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.5118]],\n",
      "\n",
      "        [[0.5931]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-0.0018, -0.3052],\n",
      "         [ 0.0331, -0.3431]],\n",
      "\n",
      "        [[ 0.2064,  0.1806],\n",
      "         [ 0.0458,  0.3046]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[5.6152e-08]],\n",
      "\n",
      "        [[1.2768e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.2857,  1.1051], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0517, 0.2657], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.5973]],\n",
      "\n",
      "        [[0.5022]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 4.6189e-06,  5.8400e-08],\n",
      "         [ 3.0220e-01,  3.0141e-01]],\n",
      "\n",
      "        [[ 3.3260e-01,  2.6336e-01],\n",
      "         [-1.4677e-01, -4.7266e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3082, -0.3401], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.8469]],\n",
      "\n",
      "        [[0.8185]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.1363e-01,  5.8635e-01],\n",
      "         [ 9.5869e-02, -2.6617e-01]],\n",
      "\n",
      "        [[ 2.8720e-01,  5.8942e-01],\n",
      "         [ 2.9998e-01,  2.3764e-07]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0517, 0.2657], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.5973]],\n",
      "\n",
      "        [[0.5022]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 4.6189e-06,  5.8400e-08],\n",
      "         [ 3.0220e-01,  3.0141e-01]],\n",
      "\n",
      "        [[ 3.3260e-01,  2.6336e-01],\n",
      "         [-1.4677e-01, -4.7266e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3082, -0.3401], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.8469]],\n",
      "\n",
      "        [[0.8185]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.1363e-01,  5.8635e-01],\n",
      "         [ 9.5869e-02, -2.6617e-01]],\n",
      "\n",
      "        [[ 2.8720e-01,  5.8942e-01],\n",
      "         [ 2.9998e-01,  2.3764e-07]]], device='cuda:0')), ('linear.weight', tensor([[0.1306, 0.1187]], device='cuda:0')), ('linear.bias', tensor([-0.5879], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:2    , loss:0.0124150496 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5426, 0.3834], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.4854]],\n",
      "\n",
      "        [[0.4219]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2395, 0.0713]],\n",
      "\n",
      "        [[0.1025, 0.1024]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-7.7866e-11,  4.0931e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.4198]],\n",
      "\n",
      "        [[0.6719]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-6.8162e-07, -2.2070e-01],\n",
      "         [ 4.6659e-03, -2.5665e-01]],\n",
      "\n",
      "        [[ 2.1870e-01,  2.1160e-01],\n",
      "         [ 1.0604e-01,  2.3330e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5426, 0.3834], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.4854]],\n",
      "\n",
      "        [[0.4219]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2395, 0.0713]],\n",
      "\n",
      "        [[0.1025, 0.1024]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-7.7866e-11,  4.0931e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.4198]],\n",
      "\n",
      "        [[0.6719]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-6.8162e-07, -2.2070e-01],\n",
      "         [ 4.6659e-03, -2.5665e-01]],\n",
      "\n",
      "        [[ 2.1870e-01,  2.1160e-01],\n",
      "         [ 1.0604e-01,  2.3330e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-2.7725e-13]],\n",
      "\n",
      "        [[ 1.8702e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.2024,  1.1637], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.1100, 0.2652], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6699]],\n",
      "\n",
      "        [[0.5002]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 8.8506e-10,  7.0274e-11],\n",
      "         [ 3.0105e-01,  3.0179e-01]],\n",
      "\n",
      "        [[ 3.3092e-01,  2.6170e-01],\n",
      "         [-1.4655e-01, -4.7200e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3573, -0.2900], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9220]],\n",
      "\n",
      "        [[0.8928]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7735e-01,  5.4945e-01],\n",
      "         [ 4.2793e-02, -1.9715e-01]],\n",
      "\n",
      "        [[ 3.4908e-01,  5.6433e-01],\n",
      "         [ 2.3234e-01, -1.3252e-09]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.1100, 0.2652], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6699]],\n",
      "\n",
      "        [[0.5002]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 8.8506e-10,  7.0274e-11],\n",
      "         [ 3.0105e-01,  3.0179e-01]],\n",
      "\n",
      "        [[ 3.3092e-01,  2.6170e-01],\n",
      "         [-1.4655e-01, -4.7200e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3573, -0.2900], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9220]],\n",
      "\n",
      "        [[0.8928]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7735e-01,  5.4945e-01],\n",
      "         [ 4.2793e-02, -1.9715e-01]],\n",
      "\n",
      "        [[ 3.4908e-01,  5.6433e-01],\n",
      "         [ 2.3234e-01, -1.3252e-09]]], device='cuda:0')), ('linear.weight', tensor([[0.1845, 0.1676]], device='cuda:0')), ('linear.bias', tensor([-0.5656], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:3    , loss:0.0036042626 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5406, 0.3817], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.4878]],\n",
      "\n",
      "        [[0.4236]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2358, 0.0732]],\n",
      "\n",
      "        [[0.1024, 0.1024]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([1.0025e-15, 4.0788e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.3373]],\n",
      "\n",
      "        [[0.6726]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-8.5666e-12, -1.5152e-01],\n",
      "         [ 2.9355e-04, -1.8401e-01]],\n",
      "\n",
      "        [[ 2.1770e-01,  2.1110e-01],\n",
      "         [ 1.0669e-01,  2.3339e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5406, 0.3817], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.4878]],\n",
      "\n",
      "        [[0.4236]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2358, 0.0732]],\n",
      "\n",
      "        [[0.1024, 0.1024]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([1.0025e-15, 4.0788e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.3373]],\n",
      "\n",
      "        [[0.6726]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-8.5666e-12, -1.5152e-01],\n",
      "         [ 2.9355e-04, -1.8401e-01]],\n",
      "\n",
      "        [[ 2.1770e-01,  2.1110e-01],\n",
      "         [ 1.0669e-01,  2.3339e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-1.5300e-17]],\n",
      "\n",
      "        [[ 1.8845e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.1353,  1.1622], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.1086, 0.2645], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6695]],\n",
      "\n",
      "        [[0.4974]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 3.3878e-10, -2.0647e-13],\n",
      "         [ 3.0022e-01,  3.0146e-01]],\n",
      "\n",
      "        [[ 3.2863e-01,  2.5943e-01],\n",
      "         [-1.4624e-01, -4.7109e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3562, -0.2911], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9216]],\n",
      "\n",
      "        [[0.8924]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7705e-01,  5.4984e-01],\n",
      "         [ 4.2991e-02, -1.9750e-01]],\n",
      "\n",
      "        [[ 3.4879e-01,  5.6456e-01],\n",
      "         [ 2.3267e-01, -1.6910e-09]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.1086, 0.2645], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6695]],\n",
      "\n",
      "        [[0.4974]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 3.3878e-10, -2.0647e-13],\n",
      "         [ 3.0022e-01,  3.0146e-01]],\n",
      "\n",
      "        [[ 3.2863e-01,  2.5943e-01],\n",
      "         [-1.4624e-01, -4.7109e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3562, -0.2911], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9216]],\n",
      "\n",
      "        [[0.8924]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7705e-01,  5.4984e-01],\n",
      "         [ 4.2991e-02, -1.9750e-01]],\n",
      "\n",
      "        [[ 3.4879e-01,  5.6456e-01],\n",
      "         [ 2.3267e-01, -1.6910e-09]]], device='cuda:0')), ('linear.weight', tensor([[0.1842, 0.1675]], device='cuda:0')), ('linear.bias', tensor([-0.5660], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:4    , loss:0.0024452398 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5378, 0.3793], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.4903]],\n",
      "\n",
      "        [[0.4254]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2320, 0.0751]],\n",
      "\n",
      "        [[0.1022, 0.1025]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-4.2721e-21,  4.0585e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.2646]],\n",
      "\n",
      "        [[0.6731]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 3.7817e-17, -9.7762e-02],\n",
      "         [ 7.8266e-06, -1.2542e-01]],\n",
      "\n",
      "        [[ 2.1649e-01,  2.1045e-01],\n",
      "         [ 1.0724e-01,  2.3379e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5378, 0.3793], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.4903]],\n",
      "\n",
      "        [[0.4254]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2320, 0.0751]],\n",
      "\n",
      "        [[0.1022, 0.1025]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-4.2721e-21,  4.0585e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.2646]],\n",
      "\n",
      "        [[0.6731]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 3.7817e-17, -9.7762e-02],\n",
      "         [ 7.8266e-06, -1.2542e-01]],\n",
      "\n",
      "        [[ 2.1649e-01,  2.1045e-01],\n",
      "         [ 1.0724e-01,  2.3379e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-1.9534e-22]],\n",
      "\n",
      "        [[ 1.8996e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.0843,  1.1602], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.1066, 0.2637], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6688]],\n",
      "\n",
      "        [[0.4940]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 2.3026e-10,  1.2324e-14],\n",
      "         [ 2.9610e-01,  3.0510e-01]],\n",
      "\n",
      "        [[ 3.2577e-01,  2.5662e-01],\n",
      "         [-1.4586e-01, -4.6996e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3546, -0.2927], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9207]],\n",
      "\n",
      "        [[0.8916]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7639e-01,  5.5071e-01],\n",
      "         [ 4.3438e-02, -1.9825e-01]],\n",
      "\n",
      "        [[ 3.4816e-01,  5.6514e-01],\n",
      "         [ 2.3340e-01, -3.7033e-10]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.1066, 0.2637], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6688]],\n",
      "\n",
      "        [[0.4940]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 2.3026e-10,  1.2324e-14],\n",
      "         [ 2.9610e-01,  3.0510e-01]],\n",
      "\n",
      "        [[ 3.2577e-01,  2.5662e-01],\n",
      "         [-1.4586e-01, -4.6996e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3546, -0.2927], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9207]],\n",
      "\n",
      "        [[0.8916]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7639e-01,  5.5071e-01],\n",
      "         [ 4.3438e-02, -1.9825e-01]],\n",
      "\n",
      "        [[ 3.4816e-01,  5.6514e-01],\n",
      "         [ 2.3340e-01, -3.7033e-10]]], device='cuda:0')), ('linear.weight', tensor([[0.1835, 0.1670]], device='cuda:0')), ('linear.bias', tensor([-0.5666], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:5    , loss:0.0047022947 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5349, 0.3768], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.4935]],\n",
      "\n",
      "        [[0.4277]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2272, 0.0775]],\n",
      "\n",
      "        [[0.1020, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([2.5904e-25, 4.0374e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.2017]],\n",
      "\n",
      "        [[0.6740]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-2.0986e-21, -5.8660e-02],\n",
      "         [ 7.8853e-08, -8.0561e-02]],\n",
      "\n",
      "        [[ 2.1516e-01,  2.0978e-01],\n",
      "         [ 1.0810e-01,  2.3390e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5349, 0.3768], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.4935]],\n",
      "\n",
      "        [[0.4277]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2272, 0.0775]],\n",
      "\n",
      "        [[0.1020, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([2.5904e-25, 4.0374e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.2017]],\n",
      "\n",
      "        [[0.6740]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-2.0986e-21, -5.8660e-02],\n",
      "         [ 7.8853e-08, -8.0561e-02]],\n",
      "\n",
      "        [[ 2.1516e-01,  2.0978e-01],\n",
      "         [ 1.0810e-01,  2.3390e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-9.2319e-28]],\n",
      "\n",
      "        [[ 1.9192e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.0485,  1.1581], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.1045, 0.2626], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6682]],\n",
      "\n",
      "        [[0.4899]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-4.0695e-11,  4.5691e-13],\n",
      "         [ 2.9983e-01,  3.0029e-01]],\n",
      "\n",
      "        [[ 3.2238e-01,  2.5328e-01],\n",
      "         [-1.4540e-01, -4.6859e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3530, -0.2943], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9200]],\n",
      "\n",
      "        [[0.8909]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7589e-01,  5.5135e-01],\n",
      "         [ 4.3762e-02, -1.9882e-01]],\n",
      "\n",
      "        [[ 3.4769e-01,  5.6554e-01],\n",
      "         [ 2.3394e-01,  2.4405e-09]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.1045, 0.2626], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6682]],\n",
      "\n",
      "        [[0.4899]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-4.0695e-11,  4.5691e-13],\n",
      "         [ 2.9983e-01,  3.0029e-01]],\n",
      "\n",
      "        [[ 3.2238e-01,  2.5328e-01],\n",
      "         [-1.4540e-01, -4.6859e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3530, -0.2943], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9200]],\n",
      "\n",
      "        [[0.8909]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7589e-01,  5.5135e-01],\n",
      "         [ 4.3762e-02, -1.9882e-01]],\n",
      "\n",
      "        [[ 3.4769e-01,  5.6554e-01],\n",
      "         [ 2.3394e-01,  2.4405e-09]]], device='cuda:0')), ('linear.weight', tensor([[0.1830, 0.1667]], device='cuda:0')), ('linear.bias', tensor([-0.5673], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:6    , loss:0.0014827098 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5318, 0.3741], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.4975]],\n",
      "\n",
      "        [[0.4307]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2210, 0.0805]],\n",
      "\n",
      "        [[0.1019, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-4.2845e-30,  4.0148e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.1487]],\n",
      "\n",
      "        [[0.6755]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-2.8711e-26, -3.2398e-02],\n",
      "         [ 2.4222e-10, -4.8324e-02]],\n",
      "\n",
      "        [[ 2.1364e-01,  2.0907e-01],\n",
      "         [ 1.0926e-01,  2.3368e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5318, 0.3741], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.4975]],\n",
      "\n",
      "        [[0.4307]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2210, 0.0805]],\n",
      "\n",
      "        [[0.1019, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-4.2845e-30,  4.0148e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.1487]],\n",
      "\n",
      "        [[0.6755]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-2.8711e-26, -3.2398e-02],\n",
      "         [ 2.4222e-10, -4.8324e-02]],\n",
      "\n",
      "        [[ 2.1364e-01,  2.0907e-01],\n",
      "         [ 1.0926e-01,  2.3368e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-6.8450e-32]],\n",
      "\n",
      "        [[ 1.9443e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.0254,  1.1558], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.1023, 0.2615], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6679]],\n",
      "\n",
      "        [[0.4851]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-7.9137e-12, -1.5087e-14],\n",
      "         [ 2.9690e-01,  3.0224e-01]],\n",
      "\n",
      "        [[ 3.1843e-01,  2.4941e-01],\n",
      "         [-1.4486e-01, -4.6700e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3512, -0.2961], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9196]],\n",
      "\n",
      "        [[0.8905]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7556e-01,  5.5174e-01],\n",
      "         [ 4.3975e-02, -1.9917e-01]],\n",
      "\n",
      "        [[ 3.4736e-01,  5.6576e-01],\n",
      "         [ 2.3428e-01, -6.5802e-10]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.1023, 0.2615], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6679]],\n",
      "\n",
      "        [[0.4851]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-7.9137e-12, -1.5087e-14],\n",
      "         [ 2.9690e-01,  3.0224e-01]],\n",
      "\n",
      "        [[ 3.1843e-01,  2.4941e-01],\n",
      "         [-1.4486e-01, -4.6700e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3512, -0.2961], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9196]],\n",
      "\n",
      "        [[0.8905]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7556e-01,  5.5174e-01],\n",
      "         [ 4.3975e-02, -1.9917e-01]],\n",
      "\n",
      "        [[ 3.4736e-01,  5.6576e-01],\n",
      "         [ 2.3428e-01, -6.5802e-10]]], device='cuda:0')), ('linear.weight', tensor([[0.1826, 0.1666]], device='cuda:0')), ('linear.bias', tensor([-0.5680], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:7    , loss:0.0019323200 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5291, 0.3718], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5027]],\n",
      "\n",
      "        [[0.4346]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2134, 0.0843]],\n",
      "\n",
      "        [[0.1018, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([1.7903e-35, 3.9951e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.1056]],\n",
      "\n",
      "        [[0.6777]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-4.1762e-31, -1.6308e-02],\n",
      "         [ 1.4617e-13, -2.6828e-02]],\n",
      "\n",
      "        [[ 2.1224e-01,  2.0851e-01],\n",
      "         [ 1.1095e-01,  2.3265e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5291, 0.3718], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5027]],\n",
      "\n",
      "        [[0.4346]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2134, 0.0843]],\n",
      "\n",
      "        [[0.1018, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([1.7903e-35, 3.9951e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.1056]],\n",
      "\n",
      "        [[0.6777]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-4.1762e-31, -1.6308e-02],\n",
      "         [ 1.4617e-13, -2.6828e-02]],\n",
      "\n",
      "        [[ 2.1224e-01,  2.0851e-01],\n",
      "         [ 1.1095e-01,  2.3265e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[1.0690e-36]],\n",
      "\n",
      "        [[1.9767e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.0120,  1.1538], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.1004, 0.2601], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6683]],\n",
      "\n",
      "        [[0.4797]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 2.3575e-13,  3.7018e-13],\n",
      "         [ 2.9827e-01,  2.9962e-01]],\n",
      "\n",
      "        [[ 3.1391e-01,  2.4500e-01],\n",
      "         [-1.4424e-01, -4.6515e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3496, -0.2977], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9199]],\n",
      "\n",
      "        [[0.8907]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7576e-01,  5.5145e-01],\n",
      "         [ 4.3785e-02, -1.9892e-01]],\n",
      "\n",
      "        [[ 3.4754e-01,  5.6544e-01],\n",
      "         [ 2.3403e-01,  6.3147e-10]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.1004, 0.2601], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6683]],\n",
      "\n",
      "        [[0.4797]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 2.3575e-13,  3.7018e-13],\n",
      "         [ 2.9827e-01,  2.9962e-01]],\n",
      "\n",
      "        [[ 3.1391e-01,  2.4500e-01],\n",
      "         [-1.4424e-01, -4.6515e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3496, -0.2977], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9199]],\n",
      "\n",
      "        [[0.8907]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7576e-01,  5.5145e-01],\n",
      "         [ 4.3785e-02, -1.9892e-01]],\n",
      "\n",
      "        [[ 3.4754e-01,  5.6544e-01],\n",
      "         [ 2.3403e-01,  6.3147e-10]]], device='cuda:0')), ('linear.weight', tensor([[0.1826, 0.1669]], device='cuda:0')), ('linear.bias', tensor([-0.5686], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:8    , loss:0.0119727682 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5237, 0.3670], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5056]],\n",
      "\n",
      "        [[0.4368]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2091, 0.0865]],\n",
      "\n",
      "        [[0.1016, 0.1027]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-7.3130e-40,  3.9547e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0717]],\n",
      "\n",
      "        [[0.6778]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 8.1836e-36, -7.4089e-03],\n",
      "         [ 2.5691e-18, -1.3664e-02]],\n",
      "\n",
      "        [[ 2.1031e-01,  2.0742e-01],\n",
      "         [ 1.1139e-01,  2.3375e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5237, 0.3670], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5056]],\n",
      "\n",
      "        [[0.4368]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2091, 0.0865]],\n",
      "\n",
      "        [[0.1016, 0.1027]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-7.3130e-40,  3.9547e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0717]],\n",
      "\n",
      "        [[0.6778]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 8.1836e-36, -7.4089e-03],\n",
      "         [ 2.5691e-18, -1.3664e-02]],\n",
      "\n",
      "        [[ 2.1031e-01,  2.0742e-01],\n",
      "         [ 1.1139e-01,  2.3375e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[1.3740e-40]],\n",
      "\n",
      "        [[1.9954e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.0051,  1.1497], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0964, 0.2585], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6663]],\n",
      "\n",
      "        [[0.4735]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-6.4160e-14, -1.9551e-13],\n",
      "         [ 2.9606e-01,  3.0070e-01]],\n",
      "\n",
      "        [[ 3.0882e-01,  2.4004e-01],\n",
      "         [-1.4353e-01, -4.6305e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3464, -0.3009], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9177]],\n",
      "\n",
      "        [[0.8886]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7407e-01,  5.5358e-01],\n",
      "         [ 4.4985e-02, -2.0083e-01]],\n",
      "\n",
      "        [[ 3.4592e-01,  5.6698e-01],\n",
      "         [ 2.3589e-01, -1.8287e-07]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0964, 0.2585], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6663]],\n",
      "\n",
      "        [[0.4735]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-6.4160e-14, -1.9551e-13],\n",
      "         [ 2.9606e-01,  3.0070e-01]],\n",
      "\n",
      "        [[ 3.0882e-01,  2.4004e-01],\n",
      "         [-1.4353e-01, -4.6305e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3464, -0.3009], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9177]],\n",
      "\n",
      "        [[0.8886]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7407e-01,  5.5358e-01],\n",
      "         [ 4.4985e-02, -2.0083e-01]],\n",
      "\n",
      "        [[ 3.4592e-01,  5.6698e-01],\n",
      "         [ 2.3589e-01, -1.8287e-07]]], device='cuda:0')), ('linear.weight', tensor([[0.1809, 0.1657]], device='cuda:0')), ('linear.bias', tensor([-0.5699], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:9    , loss:0.0064064851 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5203, 0.3639], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5112]],\n",
      "\n",
      "        [[0.4412]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.2011, 0.0905]],\n",
      "\n",
      "        [[0.1016, 0.1027]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-1.6678e-40,  3.9287e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0464]],\n",
      "\n",
      "        [[0.6802]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-1.3973e-40, -3.0064e-03],\n",
      "         [ 5.8235e-23, -6.3257e-03]],\n",
      "\n",
      "        [[ 2.0891e-01,  2.0683e-01],\n",
      "         [ 1.1321e-01,  2.3252e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5203, 0.3639], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5112]],\n",
      "\n",
      "        [[0.4412]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.2011, 0.0905]],\n",
      "\n",
      "        [[0.1016, 0.1027]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-1.6678e-40,  3.9287e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0464]],\n",
      "\n",
      "        [[0.6802]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-1.3973e-40, -3.0064e-03],\n",
      "         [ 5.8235e-23, -6.3257e-03]],\n",
      "\n",
      "        [[ 2.0891e-01,  2.0683e-01],\n",
      "         [ 1.1321e-01,  2.3252e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[2.7442e-40]],\n",
      "\n",
      "        [[2.0321e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-0.0019,  1.1471], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0939, 0.2568], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6665]],\n",
      "\n",
      "        [[0.4666]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 6.0942e-17,  1.3125e-10],\n",
      "         [ 2.9703e-01,  2.9828e-01]],\n",
      "\n",
      "        [[ 3.0312e-01,  2.3452e-01],\n",
      "         [-1.4273e-01, -4.6067e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3443, -0.3030], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9178]],\n",
      "\n",
      "        [[0.8887]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 0.2741,  0.5534],\n",
      "         [ 0.0449, -0.2007]],\n",
      "\n",
      "        [[ 0.3460,  0.5668],\n",
      "         [ 0.2358, -0.0011]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0939, 0.2568], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6665]],\n",
      "\n",
      "        [[0.4666]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 6.0942e-17,  1.3125e-10],\n",
      "         [ 2.9703e-01,  2.9828e-01]],\n",
      "\n",
      "        [[ 3.0312e-01,  2.3452e-01],\n",
      "         [-1.4273e-01, -4.6067e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3443, -0.3030], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9178]],\n",
      "\n",
      "        [[0.8887]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 0.2741,  0.5534],\n",
      "         [ 0.0449, -0.2007]],\n",
      "\n",
      "        [[ 0.3460,  0.5668],\n",
      "         [ 0.2358, -0.0011]]], device='cuda:0')), ('linear.weight', tensor([[0.1808, 0.1659]], device='cuda:0')), ('linear.bias', tensor([-0.5707], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:10   , loss:0.0152884806 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5146, 0.3587], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5149]],\n",
      "\n",
      "        [[0.4442]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1959, 0.0931]],\n",
      "\n",
      "        [[0.1015, 0.1027]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([1.4396e-40, 3.8849e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0283]],\n",
      "\n",
      "        [[0.6807]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 1.2741e-40, -1.0772e-03],\n",
      "         [ 8.8425e-28, -2.6357e-03]],\n",
      "\n",
      "        [[ 2.0693e-01,  2.0577e-01],\n",
      "         [ 1.1402e-01,  2.3309e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5146, 0.3587], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5149]],\n",
      "\n",
      "        [[0.4442]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1959, 0.0931]],\n",
      "\n",
      "        [[0.1015, 0.1027]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([1.4396e-40, 3.8849e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0283]],\n",
      "\n",
      "        [[0.6807]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 1.2741e-40, -1.0772e-03],\n",
      "         [ 8.8425e-28, -2.6357e-03]],\n",
      "\n",
      "        [[ 2.0693e-01,  2.0577e-01],\n",
      "         [ 1.1402e-01,  2.3309e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[1.4975e-40]],\n",
      "\n",
      "        [[2.0568e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-6.2101e-04,  1.1427e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0896, 0.2548], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6647]],\n",
      "\n",
      "        [[0.4589]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-3.0746e-16,  7.4976e-09],\n",
      "         [ 2.9034e-01,  3.0407e-01]],\n",
      "\n",
      "        [[ 2.9680e-01,  2.2842e-01],\n",
      "         [-1.4183e-01, -4.5799e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3408, -0.3065], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9159]],\n",
      "\n",
      "        [[0.8868]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 0.2726,  0.5554],\n",
      "         [ 0.0460, -0.2025]],\n",
      "\n",
      "        [[ 0.3444,  0.5682],\n",
      "         [ 0.2375, -0.0044]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0896, 0.2548], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6647]],\n",
      "\n",
      "        [[0.4589]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-3.0746e-16,  7.4976e-09],\n",
      "         [ 2.9034e-01,  3.0407e-01]],\n",
      "\n",
      "        [[ 2.9680e-01,  2.2842e-01],\n",
      "         [-1.4183e-01, -4.5799e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3408, -0.3065], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9159]],\n",
      "\n",
      "        [[0.8868]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 0.2726,  0.5554],\n",
      "         [ 0.0460, -0.2025]],\n",
      "\n",
      "        [[ 0.3444,  0.5682],\n",
      "         [ 0.2375, -0.0044]]], device='cuda:0')), ('linear.weight', tensor([[0.1792, 0.1648]], device='cuda:0')), ('linear.bias', tensor([-0.5722], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:11   , loss:0.0088387392 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5122, 0.3565], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5231]],\n",
      "\n",
      "        [[0.4507]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1852, 0.0985]],\n",
      "\n",
      "        [[0.1016, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-6.5848e-41,  3.8663e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0162]],\n",
      "\n",
      "        [[0.6853]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-6.5257e-41, -3.3623e-04],\n",
      "         [ 9.3069e-33, -9.7745e-04]],\n",
      "\n",
      "        [[ 2.0643e-01,  2.0579e-01],\n",
      "         [ 1.1707e-01,  2.2962e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5122, 0.3565], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5231]],\n",
      "\n",
      "        [[0.4507]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1852, 0.0985]],\n",
      "\n",
      "        [[0.1016, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-6.5848e-41,  3.8663e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0162]],\n",
      "\n",
      "        [[0.6853]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-6.5257e-41, -3.3623e-04],\n",
      "         [ 9.3069e-33, -9.7745e-04]],\n",
      "\n",
      "        [[ 2.0643e-01,  2.0579e-01],\n",
      "         [ 1.1707e-01,  2.2962e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[1.5589e-40]],\n",
      "\n",
      "        [[2.1119e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-1.7405e-04,  1.1408e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0878, 0.2526], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6666]],\n",
      "\n",
      "        [[0.4503]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-9.4503e-19, -6.1653e-08],\n",
      "         [ 2.9637e-01,  2.9690e-01]],\n",
      "\n",
      "        [[ 2.8984e-01,  2.2174e-01],\n",
      "         [-1.4082e-01, -4.5498e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3393, -0.3080], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9177]],\n",
      "\n",
      "        [[0.8886]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7403e-01,  5.5357e-01],\n",
      "         [ 4.4789e-02, -2.0076e-01]],\n",
      "\n",
      "        [[ 3.4585e-01,  5.6660e-01],\n",
      "         [ 2.3580e-01,  2.4121e-05]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0878, 0.2526], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6666]],\n",
      "\n",
      "        [[0.4503]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-9.4503e-19, -6.1653e-08],\n",
      "         [ 2.9637e-01,  2.9690e-01]],\n",
      "\n",
      "        [[ 2.8984e-01,  2.2174e-01],\n",
      "         [-1.4082e-01, -4.5498e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3393, -0.3080], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9177]],\n",
      "\n",
      "        [[0.8886]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7403e-01,  5.5357e-01],\n",
      "         [ 4.4789e-02, -2.0076e-01]],\n",
      "\n",
      "        [[ 3.4585e-01,  5.6660e-01],\n",
      "         [ 2.3580e-01,  2.4121e-05]]], device='cuda:0')), ('linear.weight', tensor([[0.1804, 0.1662]], device='cuda:0')), ('linear.bias', tensor([-0.5728], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:12   , loss:0.0017849543 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5065, 0.3511], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5279]],\n",
      "\n",
      "        [[0.4547]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1790, 0.1015]],\n",
      "\n",
      "        [[0.1015, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([2.1252e-41, 3.8207e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0087]],\n",
      "\n",
      "        [[0.6867]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-7.2949e-41, -9.0039e-05],\n",
      "         [-2.0310e-37, -3.1853e-04]],\n",
      "\n",
      "        [[ 2.0470e-01,  2.0488e-01],\n",
      "         [ 1.1836e-01,  2.2933e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5065, 0.3511], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5279]],\n",
      "\n",
      "        [[0.4547]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1790, 0.1015]],\n",
      "\n",
      "        [[0.1015, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([2.1252e-41, 3.8207e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0087]],\n",
      "\n",
      "        [[0.6867]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-7.2949e-41, -9.0039e-05],\n",
      "         [-2.0310e-37, -3.1853e-04]],\n",
      "\n",
      "        [[ 2.0470e-01,  2.0488e-01],\n",
      "         [ 1.1836e-01,  2.2933e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[3.0944e-40]],\n",
      "\n",
      "        [[2.1455e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-4.1216e-05,  1.1362e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0833, 0.2502], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6654]],\n",
      "\n",
      "        [[0.4409]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-2.0404e-20, -9.5614e-07],\n",
      "         [ 2.9519e-01,  2.9682e-01]],\n",
      "\n",
      "        [[ 2.8222e-01,  2.1447e-01],\n",
      "         [-1.3969e-01, -4.5163e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3356, -0.3118], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9163]],\n",
      "\n",
      "        [[0.8872]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7289e-01,  5.5488e-01],\n",
      "         [ 4.5594e-02, -2.0199e-01]],\n",
      "\n",
      "        [[ 3.4472e-01,  5.6751e-01],\n",
      "         [ 2.3701e-01,  2.0048e-06]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0833, 0.2502], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6654]],\n",
      "\n",
      "        [[0.4409]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-2.0404e-20, -9.5614e-07],\n",
      "         [ 2.9519e-01,  2.9682e-01]],\n",
      "\n",
      "        [[ 2.8222e-01,  2.1447e-01],\n",
      "         [-1.3969e-01, -4.5163e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3356, -0.3118], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9163]],\n",
      "\n",
      "        [[0.8872]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7289e-01,  5.5488e-01],\n",
      "         [ 4.5594e-02, -2.0199e-01]],\n",
      "\n",
      "        [[ 3.4472e-01,  5.6751e-01],\n",
      "         [ 2.3701e-01,  2.0048e-06]]], device='cuda:0')), ('linear.weight', tensor([[0.1791, 0.1655]], device='cuda:0')), ('linear.bias', tensor([-0.5743], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:13   , loss:0.0021102733 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.5023, 0.3471], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5350]],\n",
      "\n",
      "        [[0.4607]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1705, 0.1056]],\n",
      "\n",
      "        [[0.1016, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([4.8565e-41, 3.7873e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0043]],\n",
      "\n",
      "        [[0.6902]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 1.1247e-40, -2.0317e-05],\n",
      "         [-7.9943e-41, -8.9875e-05]],\n",
      "\n",
      "        [[ 2.0415e-01,  2.0467e-01],\n",
      "         [ 1.2084e-01,  2.2682e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.5023, 0.3471], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5350]],\n",
      "\n",
      "        [[0.4607]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1705, 0.1056]],\n",
      "\n",
      "        [[0.1016, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([4.8565e-41, 3.7873e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0043]],\n",
      "\n",
      "        [[0.6902]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 1.1247e-40, -2.0317e-05],\n",
      "         [-7.9943e-41, -8.9875e-05]],\n",
      "\n",
      "        [[ 2.0415e-01,  2.0467e-01],\n",
      "         [ 1.2084e-01,  2.2682e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[3.2076e-40]],\n",
      "\n",
      "        [[2.1957e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-8.0821e-06,  1.1328e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0800, 0.2474], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6660]],\n",
      "\n",
      "        [[0.4306]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 1.1814e-20,  5.1737e-05],\n",
      "         [ 2.9485e-01,  2.9580e-01]],\n",
      "\n",
      "        [[ 2.7391e-01,  2.0661e-01],\n",
      "         [-1.3844e-01, -4.4790e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3328, -0.3145], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9168]],\n",
      "\n",
      "        [[0.8877]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7334e-01,  5.5431e-01],\n",
      "         [ 4.5135e-02, -2.0145e-01]],\n",
      "\n",
      "        [[ 3.4515e-01,  5.6685e-01],\n",
      "         [ 2.3647e-01,  1.1527e-08]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0800, 0.2474], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6660]],\n",
      "\n",
      "        [[0.4306]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 1.1814e-20,  5.1737e-05],\n",
      "         [ 2.9485e-01,  2.9580e-01]],\n",
      "\n",
      "        [[ 2.7391e-01,  2.0661e-01],\n",
      "         [-1.3844e-01, -4.4790e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3328, -0.3145], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9168]],\n",
      "\n",
      "        [[0.8877]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7334e-01,  5.5431e-01],\n",
      "         [ 4.5135e-02, -2.0145e-01]],\n",
      "\n",
      "        [[ 3.4515e-01,  5.6685e-01],\n",
      "         [ 2.3647e-01,  1.1527e-08]]], device='cuda:0')), ('linear.weight', tensor([[0.1793, 0.1661]], device='cuda:0')), ('linear.bias', tensor([-0.5755], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:14   , loss:0.0362962633 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4944, 0.3396], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5379]],\n",
      "\n",
      "        [[0.4632]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1669, 0.1074]],\n",
      "\n",
      "        [[0.1012, 0.1027]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([5.3838e-41, 3.7231e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0020]],\n",
      "\n",
      "        [[0.6899]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-1.5357e-40, -3.7829e-06],\n",
      "         [-1.2051e-40, -2.1586e-05]],\n",
      "\n",
      "        [[ 2.0140e-01,  2.0314e-01],\n",
      "         [ 1.2124e-01,  2.2822e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4944, 0.3396], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5379]],\n",
      "\n",
      "        [[0.4632]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1669, 0.1074]],\n",
      "\n",
      "        [[0.1012, 0.1027]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([5.3838e-41, 3.7231e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0020]],\n",
      "\n",
      "        [[0.6899]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-1.5357e-40, -3.7829e-06],\n",
      "         [-1.2051e-40, -2.1586e-05]],\n",
      "\n",
      "        [[ 2.0140e-01,  2.0314e-01],\n",
      "         [ 1.2124e-01,  2.2822e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[3.3137e-40]],\n",
      "\n",
      "        [[2.2180e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-1.2819e-06,  1.1264e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0737, 0.2444], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6630]],\n",
      "\n",
      "        [[0.4194]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 2.1794e-20,  6.4521e-04],\n",
      "         [ 2.9436e-01,  2.9499e-01]],\n",
      "\n",
      "        [[ 2.6492e-01,  1.9816e-01],\n",
      "         [-1.3705e-01, -4.4377e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3274, -0.3199], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9137]],\n",
      "\n",
      "        [[0.8846]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7062e-01,  5.5743e-01],\n",
      "         [ 4.7194e-02, -2.0436e-01]],\n",
      "\n",
      "        [[ 3.4246e-01,  5.6935e-01],\n",
      "         [ 2.3936e-01, -1.5938e-08]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0737, 0.2444], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6630]],\n",
      "\n",
      "        [[0.4194]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 2.1794e-20,  6.4521e-04],\n",
      "         [ 2.9436e-01,  2.9499e-01]],\n",
      "\n",
      "        [[ 2.6492e-01,  1.9816e-01],\n",
      "         [-1.3705e-01, -4.4377e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3274, -0.3199], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9137]],\n",
      "\n",
      "        [[0.8846]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7062e-01,  5.5743e-01],\n",
      "         [ 4.7194e-02, -2.0436e-01]],\n",
      "\n",
      "        [[ 3.4246e-01,  5.6935e-01],\n",
      "         [ 2.3936e-01, -1.5938e-08]]], device='cuda:0')), ('linear.weight', tensor([[0.1766, 0.1641]], device='cuda:0')), ('linear.bias', tensor([-0.5779], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:15   , loss:0.0027449885 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4895, 0.3349], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5451]],\n",
      "\n",
      "        [[0.4695]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1592, 0.1111]],\n",
      "\n",
      "        [[0.1014, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-6.6894e-41,  3.6825e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[0.0008]],\n",
      "\n",
      "        [[0.6934]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-1.5553e-40, -5.6725e-07],\n",
      "         [ 9.6573e-41, -4.3270e-06]],\n",
      "\n",
      "        [[ 2.0096e-01,  2.0293e-01],\n",
      "         [ 1.2379e-01,  2.2564e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4895, 0.3349], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5451]],\n",
      "\n",
      "        [[0.4695]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1592, 0.1111]],\n",
      "\n",
      "        [[0.1014, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-6.6894e-41,  3.6825e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[0.0008]],\n",
      "\n",
      "        [[0.6934]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-1.5553e-40, -5.6725e-07],\n",
      "         [ 9.6573e-41, -4.3270e-06]],\n",
      "\n",
      "        [[ 2.0096e-01,  2.0293e-01],\n",
      "         [ 1.2379e-01,  2.2564e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-4.1269e-40]],\n",
      "\n",
      "        [[ 2.2712e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-1.6000e-07,  1.1223e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0697, 0.2411], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6635]],\n",
      "\n",
      "        [[0.4072]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-1.5281e-20, -1.3042e-04],\n",
      "         [ 2.9289e-01,  2.9543e-01]],\n",
      "\n",
      "        [[ 2.5522e-01,  1.8913e-01],\n",
      "         [-1.3552e-01, -4.3919e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3240, -0.3234], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9140]],\n",
      "\n",
      "        [[0.8849]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7092e-01,  5.5702e-01],\n",
      "         [ 4.6836e-02, -2.0397e-01]],\n",
      "\n",
      "        [[ 3.4274e-01,  5.6884e-01],\n",
      "         [ 2.3896e-01,  3.0149e-10]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0697, 0.2411], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6635]],\n",
      "\n",
      "        [[0.4072]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-1.5281e-20, -1.3042e-04],\n",
      "         [ 2.9289e-01,  2.9543e-01]],\n",
      "\n",
      "        [[ 2.5522e-01,  1.8913e-01],\n",
      "         [-1.3552e-01, -4.3919e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3240, -0.3234], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9140]],\n",
      "\n",
      "        [[0.8849]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7092e-01,  5.5702e-01],\n",
      "         [ 4.6836e-02, -2.0397e-01]],\n",
      "\n",
      "        [[ 3.4274e-01,  5.6884e-01],\n",
      "         [ 2.3896e-01,  3.0149e-10]]], device='cuda:0')), ('linear.weight', tensor([[0.1766, 0.1646]], device='cuda:0')), ('linear.bias', tensor([-0.5794], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:16   , loss:0.0008435361 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4847, 0.3303], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5521]],\n",
      "\n",
      "        [[0.4756]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1525, 0.1142]],\n",
      "\n",
      "        [[0.1014, 0.1026]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-1.5377e-40,  3.6431e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[2.9714e-04]],\n",
      "\n",
      "        [[6.9701e-01]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-6.6936e-41, -6.6567e-08],\n",
      "         [-1.2587e-40, -7.0747e-07]],\n",
      "\n",
      "        [[ 2.0080e-01,  2.0285e-01],\n",
      "         [ 1.2632e-01,  2.2301e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4847, 0.3303], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5521]],\n",
      "\n",
      "        [[0.4756]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1525, 0.1142]],\n",
      "\n",
      "        [[0.1014, 0.1026]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-1.5377e-40,  3.6431e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[2.9714e-04]],\n",
      "\n",
      "        [[6.9701e-01]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-6.6936e-41, -6.6567e-08],\n",
      "         [-1.2587e-40, -7.0747e-07]],\n",
      "\n",
      "        [[ 2.0080e-01,  2.0285e-01],\n",
      "         [ 1.2632e-01,  2.2301e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-3.7008e-41]],\n",
      "\n",
      "        [[ 2.3243e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-1.5211e-08,  1.1183e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0658, 0.2374], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6641]],\n",
      "\n",
      "        [[0.3941]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 9.4218e-22,  5.4277e-08],\n",
      "         [ 2.9268e-01,  2.9413e-01]],\n",
      "\n",
      "        [[ 2.4482e-01,  1.7954e-01],\n",
      "         [-1.3383e-01, -4.3414e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3206, -0.3267], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9145]],\n",
      "\n",
      "        [[0.8854]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7136e-01,  5.5646e-01],\n",
      "         [ 4.6355e-02, -2.0344e-01]],\n",
      "\n",
      "        [[ 3.4315e-01,  5.6813e-01],\n",
      "         [ 2.3843e-01, -4.3474e-12]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0658, 0.2374], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6641]],\n",
      "\n",
      "        [[0.3941]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 9.4218e-22,  5.4277e-08],\n",
      "         [ 2.9268e-01,  2.9413e-01]],\n",
      "\n",
      "        [[ 2.4482e-01,  1.7954e-01],\n",
      "         [-1.3383e-01, -4.3414e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3206, -0.3267], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9145]],\n",
      "\n",
      "        [[0.8854]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7136e-01,  5.5646e-01],\n",
      "         [ 4.6355e-02, -2.0344e-01]],\n",
      "\n",
      "        [[ 3.4315e-01,  5.6813e-01],\n",
      "         [ 2.3843e-01, -4.3474e-12]]], device='cuda:0')), ('linear.weight', tensor([[0.1768, 0.1653]], device='cuda:0')), ('linear.bias', tensor([-0.5810], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:17   , loss:0.0051841438 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4782, 0.3240], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5578]],\n",
      "\n",
      "        [[0.4807]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1473, 0.1165]],\n",
      "\n",
      "        [[0.1014, 0.1025]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-2.9486e-41,  3.5881e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[9.7428e-05]],\n",
      "\n",
      "        [[6.9924e-01]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 4.6795e-41, -5.9103e-09],\n",
      "         [ 2.0030e-41, -9.1859e-08]],\n",
      "\n",
      "        [[ 1.9979e-01,  2.0225e-01],\n",
      "         [ 1.2820e-01,  2.2171e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4782, 0.3240], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5578]],\n",
      "\n",
      "        [[0.4807]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1473, 0.1165]],\n",
      "\n",
      "        [[0.1014, 0.1025]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-2.9486e-41,  3.5881e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[9.7428e-05]],\n",
      "\n",
      "        [[6.9924e-01]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 4.6795e-41, -5.9103e-09],\n",
      "         [ 2.0030e-41, -9.1859e-08]],\n",
      "\n",
      "        [[ 1.9979e-01,  2.0225e-01],\n",
      "         [ 1.2820e-01,  2.2171e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[3.5657e-40]],\n",
      "\n",
      "        [[2.3688e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-1.0595e-09,  1.1127e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0604, 0.2334], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6633]],\n",
      "\n",
      "        [[0.3800]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 9.6973e-21,  4.2285e-08],\n",
      "         [ 2.9161e-01,  2.9368e-01]],\n",
      "\n",
      "        [[ 2.3374e-01,  1.6943e-01],\n",
      "         [-1.3197e-01, -4.2858e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3159, -0.3315], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9135]],\n",
      "\n",
      "        [[0.8844]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7052e-01,  5.5740e-01],\n",
      "         [ 4.6873e-02, -2.0428e-01]],\n",
      "\n",
      "        [[ 3.4230e-01,  5.6877e-01],\n",
      "         [ 2.3926e-01, -2.9825e-11]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0604, 0.2334], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6633]],\n",
      "\n",
      "        [[0.3800]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 9.6973e-21,  4.2285e-08],\n",
      "         [ 2.9161e-01,  2.9368e-01]],\n",
      "\n",
      "        [[ 2.3374e-01,  1.6943e-01],\n",
      "         [-1.3197e-01, -4.2858e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3159, -0.3315], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9135]],\n",
      "\n",
      "        [[0.8844]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7052e-01,  5.5740e-01],\n",
      "         [ 4.6873e-02, -2.0428e-01]],\n",
      "\n",
      "        [[ 3.4230e-01,  5.6877e-01],\n",
      "         [ 2.3926e-01, -2.9825e-11]]], device='cuda:0')), ('linear.weight', tensor([[0.1758, 0.1649]], device='cuda:0')), ('linear.bias', tensor([-0.5832], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:18   , loss:0.0024234673 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4724, 0.3182], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5641]],\n",
      "\n",
      "        [[0.4865]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1423, 0.1187]],\n",
      "\n",
      "        [[0.1013, 0.1025]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-1.5638e-40,  3.5382e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[2.7911e-05]],\n",
      "\n",
      "        [[7.0225e-01]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 5.2589e-41, -3.8132e-10],\n",
      "         [ 2.6414e-42, -9.1780e-09]],\n",
      "\n",
      "        [[ 1.9912e-01,  2.0185e-01],\n",
      "         [ 1.3048e-01,  2.1977e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4724, 0.3182], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5641]],\n",
      "\n",
      "        [[0.4865]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1423, 0.1187]],\n",
      "\n",
      "        [[0.1013, 0.1025]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-1.5638e-40,  3.5382e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[2.7911e-05]],\n",
      "\n",
      "        [[7.0225e-01]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 5.2589e-41, -3.8132e-10],\n",
      "         [ 2.6414e-42, -9.1780e-09]],\n",
      "\n",
      "        [[ 1.9912e-01,  2.0185e-01],\n",
      "         [ 1.3048e-01,  2.1977e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[4.7867e-40]],\n",
      "\n",
      "        [[2.4195e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-5.1607e-11,  1.1077e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0555, 0.2290], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6633]],\n",
      "\n",
      "        [[0.3648]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-1.7239e-21, -3.6719e-13],\n",
      "         [ 2.9023e-01,  2.9340e-01]],\n",
      "\n",
      "        [[ 2.2200e-01,  1.5885e-01],\n",
      "         [-1.2992e-01, -4.2247e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3116, -0.3359], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9133]],\n",
      "\n",
      "        [[0.8842]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.7036e-01,  5.5751e-01],\n",
      "         [ 4.6853e-02, -2.0436e-01]],\n",
      "\n",
      "        [[ 3.4212e-01,  5.6868e-01],\n",
      "         [ 2.3934e-01,  1.3455e-14]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0555, 0.2290], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6633]],\n",
      "\n",
      "        [[0.3648]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-1.7239e-21, -3.6719e-13],\n",
      "         [ 2.9023e-01,  2.9340e-01]],\n",
      "\n",
      "        [[ 2.2200e-01,  1.5885e-01],\n",
      "         [-1.2992e-01, -4.2247e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3116, -0.3359], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9133]],\n",
      "\n",
      "        [[0.8842]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.7036e-01,  5.5751e-01],\n",
      "         [ 4.6853e-02, -2.0436e-01]],\n",
      "\n",
      "        [[ 3.4212e-01,  5.6868e-01],\n",
      "         [ 2.3934e-01,  1.3455e-14]]], device='cuda:0')), ('linear.weight', tensor([[0.1754, 0.1651]], device='cuda:0')), ('linear.bias', tensor([-0.5853], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:19   , loss:0.0161645990 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4656, 0.3116], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5694]],\n",
      "\n",
      "        [[0.4914]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1385, 0.1204]],\n",
      "\n",
      "        [[0.1012, 0.1025]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-1.5475e-40,  3.4797e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[6.8708e-06]],\n",
      "\n",
      "        [[7.0436e-01]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-7.5147e-41, -1.7025e-11],\n",
      "         [-1.4428e-40, -6.7978e-10]],\n",
      "\n",
      "        [[ 1.9787e-01,  2.0104e-01],\n",
      "         [ 1.3231e-01,  2.1869e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4656, 0.3116], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5694]],\n",
      "\n",
      "        [[0.4914]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1385, 0.1204]],\n",
      "\n",
      "        [[0.1012, 0.1025]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-1.5475e-40,  3.4797e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[6.8708e-06]],\n",
      "\n",
      "        [[7.0436e-01]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-7.5147e-41, -1.7025e-11],\n",
      "         [-1.4428e-40, -6.7978e-10]],\n",
      "\n",
      "        [[ 1.9787e-01,  2.0104e-01],\n",
      "         [ 1.3231e-01,  2.1869e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[1.9448e-40]],\n",
      "\n",
      "        [[2.4631e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-1.6594e-12,  1.1018e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0497, 0.2242], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6624]],\n",
      "\n",
      "        [[0.3487]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[ 7.3929e-19, -5.5877e-12],\n",
      "         [ 2.8937e-01,  2.9259e-01]],\n",
      "\n",
      "        [[ 2.0963e-01,  1.4784e-01],\n",
      "         [-1.2769e-01, -4.1576e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3065, -0.3410], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9123]],\n",
      "\n",
      "        [[0.8832]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.6944e-01,  5.5844e-01],\n",
      "         [ 4.7471e-02, -2.0526e-01]],\n",
      "\n",
      "        [[ 3.4117e-01,  5.6928e-01],\n",
      "         [ 2.4024e-01,  1.0071e-14]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0497, 0.2242], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6624]],\n",
      "\n",
      "        [[0.3487]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[ 7.3929e-19, -5.5877e-12],\n",
      "         [ 2.8937e-01,  2.9259e-01]],\n",
      "\n",
      "        [[ 2.0963e-01,  1.4784e-01],\n",
      "         [-1.2769e-01, -4.1576e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3065, -0.3410], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9123]],\n",
      "\n",
      "        [[0.8832]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.6944e-01,  5.5844e-01],\n",
      "         [ 4.7471e-02, -2.0526e-01]],\n",
      "\n",
      "        [[ 3.4117e-01,  5.6928e-01],\n",
      "         [ 2.4024e-01,  1.0071e-14]]], device='cuda:0')), ('linear.weight', tensor([[0.1742, 0.1646]], device='cuda:0')), ('linear.bias', tensor([-0.5879], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:20   , loss:0.0030362611 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4598, 0.3058], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5766]],\n",
      "\n",
      "        [[0.4981]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1343, 0.1221]],\n",
      "\n",
      "        [[0.1014, 0.1024]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([5.8670e-41, 3.4286e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[1.4258e-06]],\n",
      "\n",
      "        [[7.0816e-01]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[ 1.5267e-40, -4.9535e-13],\n",
      "         [ 1.5541e-40, -3.5685e-11]],\n",
      "\n",
      "        [[ 1.9771e-01,  2.0093e-01],\n",
      "         [ 1.3508e-01,  2.1610e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4598, 0.3058], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5766]],\n",
      "\n",
      "        [[0.4981]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1343, 0.1221]],\n",
      "\n",
      "        [[0.1014, 0.1024]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([5.8670e-41, 3.4286e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[1.4258e-06]],\n",
      "\n",
      "        [[7.0816e-01]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[ 1.5267e-40, -4.9535e-13],\n",
      "         [ 1.5541e-40, -3.5685e-11]],\n",
      "\n",
      "        [[ 1.9771e-01,  2.0093e-01],\n",
      "         [ 1.3508e-01,  2.1610e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-2.7889e-40]],\n",
      "\n",
      "        [[ 2.5229e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-3.2777e-14,  1.0966e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0447, 0.2190], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6629]],\n",
      "\n",
      "        [[0.3317]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-4.3685e-17,  1.7544e-12],\n",
      "         [ 2.8954e-01,  2.9071e-01]],\n",
      "\n",
      "        [[ 1.9668e-01,  1.3650e-01],\n",
      "         [-1.2524e-01, -4.0842e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.3019, -0.3456], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9128]],\n",
      "\n",
      "        [[0.8836]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.6984e-01,  5.5797e-01],\n",
      "         [ 4.6924e-02, -2.0475e-01]],\n",
      "\n",
      "        [[ 3.4155e-01,  5.6864e-01],\n",
      "         [ 2.3972e-01, -5.1881e-14]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0447, 0.2190], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6629]],\n",
      "\n",
      "        [[0.3317]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-4.3685e-17,  1.7544e-12],\n",
      "         [ 2.8954e-01,  2.9071e-01]],\n",
      "\n",
      "        [[ 1.9668e-01,  1.3650e-01],\n",
      "         [-1.2524e-01, -4.0842e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.3019, -0.3456], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9128]],\n",
      "\n",
      "        [[0.8836]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.6984e-01,  5.5797e-01],\n",
      "         [ 4.6924e-02, -2.0475e-01]],\n",
      "\n",
      "        [[ 3.4155e-01,  5.6864e-01],\n",
      "         [ 2.3972e-01, -5.1881e-14]]], device='cuda:0')), ('linear.weight', tensor([[0.1743, 0.1653]], device='cuda:0')), ('linear.bias', tensor([-0.5902], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:21   , loss:0.0007057716 \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([0.4532, 0.2993], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[0.5825]],\n",
      "\n",
      "        [[0.5038]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[0.1314, 0.1233]],\n",
      "\n",
      "        [[0.1011, 0.1024]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([-1.6522e-40,  3.3704e-01], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[2.4395e-07]],\n",
      "\n",
      "        [[7.1100e-01]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[-1.7128e-40, -8.7045e-15],\n",
      "         [ 1.8217e-41, -1.2570e-12]],\n",
      "\n",
      "        [[ 1.9686e-01,  2.0033e-01],\n",
      "         [ 1.3736e-01,  2.1444e-01]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([0.4532, 0.2993], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[0.5825]],\n",
      "\n",
      "        [[0.5038]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[0.1314, 0.1233]],\n",
      "\n",
      "        [[0.1011, 0.1024]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([-1.6522e-40,  3.3704e-01], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[2.4395e-07]],\n",
      "\n",
      "        [[7.1100e-01]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[-1.7128e-40, -8.7045e-15],\n",
      "         [ 1.8217e-41, -1.2570e-12]],\n",
      "\n",
      "        [[ 1.9686e-01,  2.0033e-01],\n",
      "         [ 1.3736e-01,  2.1444e-01]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[-5.2512e-40]],\n",
      "\n",
      "        [[ 2.5743e-01]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([-3.6209e-16,  1.0907e+00], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([0.0390, 0.2134], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[0.6627]],\n",
      "\n",
      "        [[0.3137]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[-2.2323e-15,  1.7139e-12],\n",
      "         [ 2.8819e-01,  2.9029e-01]],\n",
      "\n",
      "        [[ 1.8324e-01,  1.2491e-01],\n",
      "         [-1.2258e-01, -4.0041e-02]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([ 0.2967, -0.3508], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[0.9124]],\n",
      "\n",
      "        [[0.8833]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[ 2.6949e-01,  5.5830e-01],\n",
      "         [ 4.7013e-02, -2.0502e-01]],\n",
      "\n",
      "        [[ 3.4118e-01,  5.6873e-01],\n",
      "         [ 2.3999e-01, -6.3385e-13]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([0.0390, 0.2134], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[0.6627]],\n",
      "\n",
      "        [[0.3137]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[-2.2323e-15,  1.7139e-12],\n",
      "         [ 2.8819e-01,  2.9029e-01]],\n",
      "\n",
      "        [[ 1.8324e-01,  1.2491e-01],\n",
      "         [-1.2258e-01, -4.0041e-02]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([ 0.2967, -0.3508], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[0.9124]],\n",
      "\n",
      "        [[0.8833]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[ 2.6949e-01,  5.5830e-01],\n",
      "         [ 4.7013e-02, -2.0502e-01]],\n",
      "\n",
      "        [[ 3.4118e-01,  5.6873e-01],\n",
      "         [ 2.3999e-01, -6.3385e-13]]], device='cuda:0')), ('linear.weight', tensor([[0.1738, 0.1654]], device='cuda:0')), ('linear.bias', tensor([-0.5930], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:22   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:23   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:24   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:25   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:26   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:27   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:28   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:29   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:30   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:31   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:32   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:33   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:34   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:35   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:36   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:37   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:38   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:39   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:40   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:41   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 2, 测试集: B0005, epoch:42   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:43   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n",
      "seed: 2, 测试集: B0005, epoch:44   , loss:nan    \n",
      "OrderedDict([('tcn.network.0.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv1.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.0.weight_v', tensor([[[nan, nan]],\n",
      "\n",
      "        [[nan, nan]]], device='cuda:0')), ('tcn.network.0.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.0.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.0.downsample.weight', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.0.downsample.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv1.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv1.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.conv2.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.conv2.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.conv2.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.0.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.0.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.0.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('tcn.network.1.net.4.bias', tensor([nan, nan], device='cuda:0')), ('tcn.network.1.net.4.weight_g', tensor([[[nan]],\n",
      "\n",
      "        [[nan]]], device='cuda:0')), ('tcn.network.1.net.4.weight_v', tensor([[[nan, nan],\n",
      "         [nan, nan]],\n",
      "\n",
      "        [[nan, nan],\n",
      "         [nan, nan]]], device='cuda:0')), ('linear.weight', tensor([[nan, nan]], device='cuda:0')), ('linear.bias', tensor([nan], device='cuda:0'))])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# 开始训练\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m以电池 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mBattery_list[i]\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 为测试数据的 数据集 开始训练\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRated_Capacity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# mae, rmse, re, r2 = train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# mae_s.append(mae)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# rmse_s.append(rmse)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# re_s.append(re)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# r2_s.append(r2)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[63], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\u001b[0m\n\u001b[0;32m      4\u001b[0m mae_epoch_list, rmse_epoch_list, re_epoch_list, r2_epoch_list \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# if (epoch + 1) % 100 == 0:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# pre_list = predict(net, train_data, test_data, Rated_Capacity)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# if (len(re_epoch_list) == 0 or (r2_epoch_list[-1] < r2)):\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, 测试集: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, epoch:\u001b[39m\u001b[38;5;132;01m{:<4d}\u001b[39;00m\u001b[38;5;124m , loss:\u001b[39m\u001b[38;5;132;01m{:<6.10f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(seed, Battery_list[i], epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, train_loss))\n",
      "Cell \u001b[1;32mIn[50], line 34\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(net, train_iter, loss, updater)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#print('222out', out[-1, :, :].cpu().data.numpy().shape) # (50, 153, 1)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m#print('222tgt_y', tgt_y.shape) # (50, 153)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mupdater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m l\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\optim\\adam.py:259\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    256\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 259\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    262\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed):\n",
    "    net = net.to(device)\n",
    "    \n",
    "    mae_epoch_list, rmse_epoch_list, re_epoch_list, r2_epoch_list = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(net, train_iter, loss, updater)\n",
    "        \n",
    "        # if (epoch + 1) % 100 == 0:\n",
    "        # pre_list = predict(net, train_data, test_data, Rated_Capacity)\n",
    "        \n",
    "        # test_y = test_data.copy()\n",
    "\n",
    "        # mae, rmse, r2 = evaluation(test_data, pre_list)\n",
    "        # re = relative_error(test_y, pre_list, threshold=Rated_Capacity * 0.7)\n",
    "\n",
    "        # if (len(re_epoch_list) == 0 or (r2_epoch_list[-1] < r2)):\n",
    "        print('seed: {}, 测试集: {}, epoch:{:<4d} , loss:{:<6.10f} '.format(seed, Battery_list[i], epoch + 1, train_loss))\n",
    "        print(net.state_dict())\n",
    "        print()\n",
    "        # mae_epoch_list.append(mae)\n",
    "        # rmse_epoch_list.append(rmse)\n",
    "        # re_epoch_list.append(re)\n",
    "        # r2_epoch_list.append(r2)\n",
    "\n",
    "\n",
    "        # matlab_make(pre_list, test_y)\n",
    "\n",
    "        # if (train_loss < 1e-3) and len(re_epoch_list) > 0 and 0.0 < re_epoch_list[-1] < 0.2 and (re_epoch_list[-1] < re):\n",
    "        #     break\n",
    "\n",
    "    # return mae_epoch_list[-1], rmse_epoch_list[-1], re_epoch_list[-1], r2_epoch_list[-1]\n",
    "\n",
    "\n",
    "# 电池额定容量\n",
    "Rated_Capacity = 2.0\n",
    "\n",
    "# 超参数\n",
    "batch_size = 2\n",
    "lr = 0.0005\n",
    "weight_decay = 0.00005\n",
    "num_epochs = 300\n",
    "# num_epochs = 1\n",
    "window_size = 16\n",
    "kernel_size = 2\n",
    "dropout = 0.0\n",
    "\n",
    "# 获取数据集，生成train_iter\n",
    "# 使用留一评估\n",
    "re_seed_all, mae_seed_all, rmse_seed_all, r2_seed_all = [], [], [], []\n",
    "for seed in range(2, 3):\n",
    "    print('*******************************************************************************************************************')\n",
    "    print('当前的 seed 为', seed)\n",
    "    setup_seed(seed)\n",
    "    mae_s, rmse_s, re_s, r2_s = [], [], [], []\n",
    "    #for i in range(4):\n",
    "    for i in range(1):\n",
    "        train_x, train_y, train_data, test_data = get_train_test_data(Battery_data_list, i, window_size=window_size)\n",
    "        train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "        train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "        train_iter = load_capacity_data((train_x, train_y), batch_size, is_train=True)\n",
    "\n",
    "        # 模型、损失函数、优化器\n",
    "        net = Net(1, [2,2], kernel_size, dropout)\n",
    "        loss = nn.MSELoss()\n",
    "        updater = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # 开始训练\n",
    "        print(f'以电池 { Battery_list[i] } 为测试数据的 数据集 开始训练')\n",
    "        train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\n",
    "        # mae, rmse, re, r2 = train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\n",
    "        # mae_s.append(mae)\n",
    "        # rmse_s.append(rmse)\n",
    "        # re_s.append(re)\n",
    "        # r2_s.append(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
