{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db88bd91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T03:56:24.335641Z",
     "start_time": "2023-12-18T03:56:22.473657Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib_inline import backend_inline\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "# device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba32c85",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dc654c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:09:20.607621Z",
     "start_time": "2023-11-30T01:09:18.182913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Dataset B0005.mat ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coyle\\AppData\\Local\\Temp\\ipykernel_11412\\3199085973.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  d1['type'], d1['temp'], d1['time'], d1['data'] = str(col[i][0][0]), int(col[i][1][0]), str(convert_to_time(col[i][2][0])), d2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Dataset B0006.mat ...\n",
      "Load Dataset B0007.mat ...\n",
      "Load Dataset B0018.mat ...\n"
     ]
    }
   ],
   "source": [
    "# convert str to datatime\n",
    "# 将字符串转换为时间\n",
    "def convert_to_time(hmm):\n",
    "    year, month, day, hour, minute, second = int(hmm[0]), int(hmm[1]), int(hmm[2]), int(hmm[3]), int(hmm[4]), int(hmm[5])\n",
    "    return datetime(year=year, month=month, day=day, hour=hour, minute=minute, second=second)\n",
    "\n",
    "\n",
    "# load .mat data\n",
    "# 加载.mat格式的数据\n",
    "def loadMat(matfile):\n",
    "    data_mat = scipy.io.loadmat(matfile)\n",
    "    filename = matfile.split(\"/\")[-1].split(\".\")[0]\n",
    "    col = data_mat[filename]\n",
    "    col = col[0][0][0][0]\n",
    "    size = col.shape[0]\n",
    "\n",
    "    data_mat = []\n",
    "    for i in range(size):\n",
    "        k = list(col[i][3][0].dtype.fields.keys())\n",
    "        d1, d2 = {}, {}\n",
    "        if str(col[i][0][0]) != 'impedance':\n",
    "            for j in range(len(k)):\n",
    "                t = col[i][3][0][0][j][0];\n",
    "                l = [t[m] for m in range(len(t))]\n",
    "                d2[k[j]] = l\n",
    "        d1['type'], d1['temp'], d1['time'], d1['data'] = str(col[i][0][0]), int(col[i][1][0]), str(convert_to_time(col[i][2][0])), d2\n",
    "        data_mat.append(d1)\n",
    "\n",
    "    return data_mat\n",
    "\n",
    "# get capacity data\n",
    "# 得到电池容量的数据\n",
    "def getBatteryCapacity(Battery):\n",
    "    cycle, capacity = [], []\n",
    "    i = 1\n",
    "    for Bat in Battery:\n",
    "        if Bat['type'] == 'discharge':\n",
    "            capacity.append(Bat['data']['Capacity'][0])\n",
    "            cycle.append(i)\n",
    "            i += 1\n",
    "    return [cycle, capacity]\n",
    "\n",
    "Battery_list = ['B0005', 'B0006', 'B0007', 'B0018']\n",
    "dir_path = './datasets/NASA/'\n",
    "\n",
    "Battery = {}\n",
    "for name in Battery_list:\n",
    "    print('Load Dataset ' + name + '.mat ...')\n",
    "    path = dir_path + name + '.mat'\n",
    "    data_mat = loadMat(path)\n",
    "    Battery[name] = getBatteryCapacity(data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f428a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T06:17:06.215530Z",
     "start_time": "2023-10-20T06:17:06.195562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 168)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Battery['B0006'][0]), len(Battery['B0006'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd08b17",
   "metadata": {},
   "source": [
    "## 画出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90eb42aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:11:01.960230Z",
     "start_time": "2023-11-30T01:11:00.920534Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"607.764796pt\" height=\"264.386563pt\" viewBox=\"0 0 607.764796 264.386563\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-11-30T09:11:01.920337</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 264.386563 \n",
       "L 607.764796 264.386563 \n",
       "L 607.764796 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 42.41875 228.96 \n",
       "L 600.41875 228.96 \n",
       "L 600.41875 7.2 \n",
       "L 42.41875 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m9026906862\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"67.782386\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(65.282386 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-30\" d=\"M 2975 2250 \n",
       "Q 2975 1350 2650 700 \n",
       "Q 2325 50 1600 50 \n",
       "Q 875 50 537 700 \n",
       "Q 200 1350 200 2250 \n",
       "Q 200 3150 537 3787 \n",
       "Q 875 4425 1600 4425 \n",
       "Q 2325 4425 2650 3787 \n",
       "Q 2975 3150 2975 2250 \n",
       "z\n",
       "M 2375 2250 \n",
       "Q 2375 3050 2187 3500 \n",
       "Q 2000 3950 1600 3950 \n",
       "Q 1200 3950 1000 3500 \n",
       "Q 800 3050 800 2250 \n",
       "Q 800 1450 1000 987 \n",
       "Q 1200 525 1600 525 \n",
       "Q 2000 525 2187 987 \n",
       "Q 2375 1450 2375 2250 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"142.822731\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(137.822731 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-32\" d=\"M 2850 100 \n",
       "L 300 100 \n",
       "L 300 500 \n",
       "Q 450 900 712 1237 \n",
       "Q 975 1575 1475 2000 \n",
       "Q 1850 2325 2012 2600 \n",
       "Q 2175 2875 2175 3200 \n",
       "Q 2175 3525 2037 3737 \n",
       "Q 1900 3950 1600 3950 \n",
       "Q 1350 3950 1162 3725 \n",
       "Q 975 3500 975 2925 \n",
       "L 400 2925 \n",
       "Q 425 3650 737 4037 \n",
       "Q 1050 4425 1625 4425 \n",
       "Q 2175 4425 2475 4087 \n",
       "Q 2775 3750 2775 3175 \n",
       "Q 2775 2700 2500 2350 \n",
       "Q 2225 2000 1825 1650 \n",
       "Q 1375 1250 1200 1050 \n",
       "Q 1025 850 875 575 \n",
       "L 2850 575 \n",
       "L 2850 100 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"SimHei-35\" d=\"M 2825 1650 \n",
       "Q 2825 900 2462 475 \n",
       "Q 2100 50 1500 50 \n",
       "Q 975 50 637 400 \n",
       "Q 300 750 275 1350 \n",
       "L 850 1350 \n",
       "Q 850 975 1025 750 \n",
       "Q 1200 525 1525 525 \n",
       "Q 1850 525 2037 800 \n",
       "Q 2225 1075 2225 1650 \n",
       "Q 2225 2150 2062 2387 \n",
       "Q 1900 2625 1625 2625 \n",
       "Q 1400 2625 1237 2525 \n",
       "Q 1075 2425 925 2175 \n",
       "L 425 2175 \n",
       "L 575 4375 \n",
       "L 2725 4375 \n",
       "L 2725 3900 \n",
       "L 1050 3900 \n",
       "L 950 2750 \n",
       "Q 1100 2900 1275 2975 \n",
       "Q 1450 3050 1750 3050 \n",
       "Q 2225 3050 2525 2687 \n",
       "Q 2825 2325 2825 1650 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"217.863075\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(212.863075 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-35\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"292.903419\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 75 -->\n",
       "      <g transform=\"translate(287.903419 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-37\" d=\"M 2775 3850 \n",
       "L 1600 100 \n",
       "L 1025 100 \n",
       "L 2225 3900 \n",
       "L 400 3900 \n",
       "L 400 4375 \n",
       "L 2775 4375 \n",
       "L 2775 3850 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-37\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"367.943763\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(360.443763 242.795938)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-31\" d=\"M 1950 100 \n",
       "L 1375 100 \n",
       "L 1375 3425 \n",
       "L 625 3425 \n",
       "L 625 3725 \n",
       "Q 1075 3725 1325 3900 \n",
       "Q 1575 4075 1650 4425 \n",
       "L 1950 4425 \n",
       "L 1950 100 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"442.984108\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 125 -->\n",
       "      <g transform=\"translate(435.484108 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-32\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"518.024452\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(510.524452 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9026906862\" x=\"593.064796\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 175 -->\n",
       "      <g transform=\"translate(585.564796 242.795938)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-37\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- 循环次数 -->\n",
       "     <g transform=\"translate(301.41875 255.8975)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-5faa\" d=\"M 5500 5100 \n",
       "Q 5675 4750 5850 4550 \n",
       "Q 5375 4525 4625 4425 \n",
       "L 4575 3725 \n",
       "L 5325 3725 \n",
       "Q 5725 3725 6075 3750 \n",
       "L 6075 3350 \n",
       "Q 5725 3375 5325 3375 \n",
       "L 4550 3375 \n",
       "L 4500 2725 \n",
       "L 5675 2725 \n",
       "Q 5650 2300 5650 1162 \n",
       "Q 5650 25 5675 -500 \n",
       "L 5225 -500 \n",
       "L 5225 -100 \n",
       "L 3650 -100 \n",
       "L 3650 -550 \n",
       "L 3200 -550 \n",
       "Q 3225 25 3225 1150 \n",
       "Q 3225 2275 3200 2725 \n",
       "L 4025 2725 \n",
       "L 4075 3375 \n",
       "Q 3450 3375 3050 3350 \n",
       "L 3050 3750 \n",
       "Q 3450 3725 4125 3725 \n",
       "L 4150 4400 \n",
       "Q 3550 4375 2750 4350 \n",
       "Q 2750 2925 2725 2275 \n",
       "Q 2700 1625 2587 950 \n",
       "Q 2475 275 2200 -425 \n",
       "Q 2025 -175 1750 -25 \n",
       "Q 1975 300 2100 800 \n",
       "Q 2225 1300 2275 1812 \n",
       "Q 2325 2325 2325 3275 \n",
       "Q 2325 4225 2300 4750 \n",
       "Q 2950 4725 3887 4800 \n",
       "Q 4825 4875 5500 5100 \n",
       "z\n",
       "M 3650 2375 \n",
       "L 3650 1925 \n",
       "L 5225 1925 \n",
       "L 5225 2375 \n",
       "L 3650 2375 \n",
       "z\n",
       "M 3650 1600 \n",
       "L 3650 1100 \n",
       "L 5225 1100 \n",
       "L 5225 1600 \n",
       "L 3650 1600 \n",
       "z\n",
       "M 3650 775 \n",
       "L 3650 250 \n",
       "L 5225 250 \n",
       "L 5225 775 \n",
       "L 3650 775 \n",
       "z\n",
       "M 1475 5125 \n",
       "Q 1700 4975 1950 4825 \n",
       "Q 1325 3900 650 3200 \n",
       "Q 500 3375 350 3575 \n",
       "Q 925 4100 1475 5125 \n",
       "z\n",
       "M 1650 3750 \n",
       "Q 1875 3625 2150 3500 \n",
       "Q 1900 3200 1500 2550 \n",
       "L 1500 525 \n",
       "Q 1500 0 1525 -550 \n",
       "L 1050 -550 \n",
       "Q 1075 0 1075 525 \n",
       "L 1075 2100 \n",
       "Q 800 1725 600 1500 \n",
       "Q 450 1775 300 1900 \n",
       "Q 750 2300 1050 2737 \n",
       "Q 1350 3175 1650 3750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-73af\" d=\"M 375 4675 \n",
       "Q 700 4650 1000 4650 \n",
       "L 1850 4650 \n",
       "Q 2100 4650 2425 4675 \n",
       "L 2425 4225 \n",
       "Q 2100 4250 1850 4250 \n",
       "L 1675 4250 \n",
       "L 1675 3100 \n",
       "Q 2025 3100 2450 3125 \n",
       "L 2450 2675 \n",
       "Q 2000 2700 1675 2700 \n",
       "L 1675 1350 \n",
       "Q 1925 1400 2325 1525 \n",
       "Q 2275 1275 2275 1075 \n",
       "Q 1750 950 1262 812 \n",
       "Q 775 675 325 500 \n",
       "Q 250 750 150 1025 \n",
       "Q 400 1050 1225 1225 \n",
       "L 1225 2700 \n",
       "Q 825 2700 450 2650 \n",
       "L 450 3125 \n",
       "Q 825 3100 1225 3100 \n",
       "L 1225 4250 \n",
       "L 1025 4250 \n",
       "Q 700 4250 375 4225 \n",
       "L 375 4675 \n",
       "z\n",
       "M 2625 4675 \n",
       "Q 3050 4650 3425 4650 \n",
       "L 5100 4650 \n",
       "Q 5450 4650 5850 4675 \n",
       "L 5850 4225 \n",
       "Q 5450 4250 5100 4250 \n",
       "L 4425 4250 \n",
       "Q 4375 3850 4275 3400 \n",
       "L 4275 375 \n",
       "Q 4275 -175 4300 -575 \n",
       "L 3775 -575 \n",
       "Q 3825 -200 3825 375 \n",
       "L 3825 2300 \n",
       "Q 3500 1625 3100 1075 \n",
       "Q 2700 525 2425 225 \n",
       "Q 2200 425 1950 550 \n",
       "Q 2300 800 2625 1187 \n",
       "Q 2950 1575 3225 2087 \n",
       "Q 3500 2600 3675 3162 \n",
       "Q 3850 3725 3925 4250 \n",
       "L 3425 4250 \n",
       "Q 3050 4250 2625 4225 \n",
       "L 2625 4675 \n",
       "z\n",
       "M 4525 2550 \n",
       "Q 4725 2675 4925 2850 \n",
       "Q 5200 2425 5400 2100 \n",
       "Q 5600 1775 6125 925 \n",
       "Q 5900 825 5650 625 \n",
       "Q 5325 1275 5050 1725 \n",
       "Q 4775 2175 4525 2550 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6b21\" d=\"M 525 4300 \n",
       "Q 725 4425 1000 4550 \n",
       "Q 1150 4300 1350 3950 \n",
       "Q 1550 3600 1750 3250 \n",
       "Q 1475 3125 1250 2975 \n",
       "Q 1100 3275 937 3625 \n",
       "Q 775 3975 525 4300 \n",
       "z\n",
       "M 1475 2225 \n",
       "Q 1650 2075 1950 1925 \n",
       "Q 1800 1700 1512 1150 \n",
       "Q 1225 600 900 -50 \n",
       "Q 675 125 400 300 \n",
       "Q 775 700 1037 1237 \n",
       "Q 1300 1775 1475 2225 \n",
       "z\n",
       "M 3000 5075 \n",
       "Q 3275 4975 3650 4825 \n",
       "Q 3500 4725 3387 4450 \n",
       "Q 3275 4175 3150 3900 \n",
       "L 5800 3900 \n",
       "Q 5725 3700 5600 3337 \n",
       "Q 5475 2975 5325 2450 \n",
       "Q 5050 2525 4775 2575 \n",
       "Q 4875 2800 4950 3025 \n",
       "Q 5025 3250 5100 3500 \n",
       "L 2975 3500 \n",
       "Q 2850 3300 2712 3000 \n",
       "Q 2575 2700 2400 2400 \n",
       "Q 2225 2550 1950 2650 \n",
       "Q 2125 2875 2287 3175 \n",
       "Q 2450 3475 2587 3800 \n",
       "Q 2725 4125 2825 4450 \n",
       "Q 2925 4775 3000 5075 \n",
       "z\n",
       "M 3500 3050 \n",
       "Q 3800 3025 4100 2975 \n",
       "Q 4025 2725 4012 2250 \n",
       "Q 4000 1775 4212 1375 \n",
       "Q 4425 975 4725 700 \n",
       "Q 5025 425 5375 262 \n",
       "Q 5725 100 6000 25 \n",
       "Q 5850 -75 5775 -212 \n",
       "Q 5700 -350 5625 -550 \n",
       "Q 5075 -250 4750 12 \n",
       "Q 4425 275 4237 525 \n",
       "Q 4050 775 3950 1012 \n",
       "Q 3850 1250 3775 1475 \n",
       "Q 3650 1100 3512 812 \n",
       "Q 3375 525 3162 300 \n",
       "Q 2950 75 2675 -137 \n",
       "Q 2400 -350 2025 -600 \n",
       "Q 1850 -325 1600 -150 \n",
       "Q 2225 75 2600 412 \n",
       "Q 2975 750 3175 1100 \n",
       "Q 3375 1450 3437 1787 \n",
       "Q 3500 2125 3512 2362 \n",
       "Q 3525 2600 3500 3050 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6570\" d=\"M 700 4850 \n",
       "Q 950 4925 1100 5025 \n",
       "Q 1300 4700 1475 4375 \n",
       "Q 1250 4275 1075 4175 \n",
       "Q 925 4550 700 4850 \n",
       "z\n",
       "M 2875 5025 \n",
       "Q 3150 4900 3400 4800 \n",
       "Q 3250 4700 3150 4525 \n",
       "Q 3050 4350 2925 4125 \n",
       "Q 2725 4225 2525 4275 \n",
       "Q 2725 4600 2875 5025 \n",
       "z\n",
       "M 2450 3175 \n",
       "Q 2675 3275 2825 3425 \n",
       "Q 3125 3000 3325 2650 \n",
       "Q 3100 2550 2900 2400 \n",
       "Q 2700 2875 2450 3175 \n",
       "z\n",
       "M 525 3950 \n",
       "Q 925 3925 1800 3925 \n",
       "Q 1800 4650 1775 5175 \n",
       "L 2275 5175 \n",
       "Q 2250 4650 2250 3925 \n",
       "Q 3075 3925 3450 3950 \n",
       "L 3450 3500 \n",
       "Q 3075 3525 2250 3525 \n",
       "Q 2250 2950 2275 2525 \n",
       "L 1775 2525 \n",
       "Q 1800 2900 1800 3325 \n",
       "Q 1675 3075 1387 2787 \n",
       "Q 1100 2500 750 2300 \n",
       "Q 650 2525 425 2675 \n",
       "Q 650 2750 987 3000 \n",
       "Q 1325 3250 1475 3525 \n",
       "Q 950 3525 525 3500 \n",
       "L 525 3950 \n",
       "z\n",
       "M 1725 1550 \n",
       "Q 1600 1300 1450 1050 \n",
       "Q 1750 975 2250 850 \n",
       "Q 2425 1075 2575 1550 \n",
       "L 1725 1550 \n",
       "z\n",
       "M 1550 2450 \n",
       "Q 1825 2350 2100 2275 \n",
       "Q 2000 2175 1875 1950 \n",
       "L 2850 1950 \n",
       "L 3125 1950 \n",
       "Q 2975 1300 2700 725 \n",
       "Q 3125 600 3375 525 \n",
       "Q 3175 250 3075 25 \n",
       "Q 2850 175 2400 350 \n",
       "Q 1800 -250 600 -650 \n",
       "Q 500 -400 300 -250 \n",
       "Q 1375 0 2000 525 \n",
       "Q 1300 700 850 825 \n",
       "Q 1000 1025 1250 1550 \n",
       "Q 850 1550 300 1525 \n",
       "L 300 1975 \n",
       "Q 775 1950 1400 1950 \n",
       "Q 1475 2150 1550 2450 \n",
       "z\n",
       "M 4075 5150 \n",
       "Q 4375 5025 4700 4975 \n",
       "Q 4575 4825 4512 4625 \n",
       "Q 4450 4425 4350 4050 \n",
       "L 5475 4050 \n",
       "Q 5700 4050 6050 4075 \n",
       "L 6050 3625 \n",
       "Q 5775 3650 5600 3650 \n",
       "Q 5575 3125 5475 2262 \n",
       "Q 5375 1400 5000 750 \n",
       "Q 5250 400 5575 175 \n",
       "Q 5900 -50 6150 -150 \n",
       "Q 5800 -375 5700 -600 \n",
       "Q 5275 -300 5075 -87 \n",
       "Q 4875 125 4700 375 \n",
       "Q 4400 75 4137 -125 \n",
       "Q 3875 -325 3300 -650 \n",
       "Q 3175 -425 2900 -250 \n",
       "Q 3375 -75 3775 200 \n",
       "Q 4175 475 4450 775 \n",
       "Q 4175 1325 4025 1862 \n",
       "Q 3875 2400 3850 2625 \n",
       "Q 3800 2450 3725 2225 \n",
       "Q 3500 2325 3225 2425 \n",
       "Q 3525 2975 3775 3750 \n",
       "Q 4025 4525 4075 5150 \n",
       "z\n",
       "M 4250 3650 \n",
       "Q 4150 3400 4100 3237 \n",
       "Q 4050 3075 4287 2350 \n",
       "Q 4525 1625 4750 1225 \n",
       "Q 4975 1825 5062 2475 \n",
       "Q 5150 3125 5150 3650 \n",
       "L 4250 3650 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-5faa\"/>\n",
       "      <use xlink:href=\"#SimHei-73af\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-6b21\" x=\"200\"/>\n",
       "      <use xlink:href=\"#SimHei-6570\" x=\"300\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path id=\"mc84f383583\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc84f383583\" x=\"42.41875\" y=\"208.318433\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1.2 -->\n",
       "      <g transform=\"translate(20.41875 211.736402)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-2e\" d=\"M 1100 100 \n",
       "L 525 100 \n",
       "L 525 650 \n",
       "L 1100 650 \n",
       "L 1100 100 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-32\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc84f383583\" x=\"42.41875\" y=\"162.579217\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.4 -->\n",
       "      <g transform=\"translate(20.41875 165.997186)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-34\" d=\"M 2975 1200 \n",
       "L 2450 1200 \n",
       "L 2450 100 \n",
       "L 1875 100 \n",
       "L 1875 1200 \n",
       "L 200 1200 \n",
       "L 200 1675 \n",
       "L 1875 4425 \n",
       "L 2450 4425 \n",
       "L 2450 1675 \n",
       "L 2975 1675 \n",
       "L 2975 1200 \n",
       "z\n",
       "M 1875 1675 \n",
       "L 1875 3525 \n",
       "L 750 1675 \n",
       "L 1875 1675 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-34\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc84f383583\" x=\"42.41875\" y=\"116.840001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.6 -->\n",
       "      <g transform=\"translate(20.41875 120.25797)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-36\" d=\"M 2850 1550 \n",
       "Q 2850 850 2550 450 \n",
       "Q 2250 50 1650 50 \n",
       "Q 1050 50 700 550 \n",
       "Q 350 1050 350 2175 \n",
       "Q 350 3200 712 3812 \n",
       "Q 1075 4425 1750 4425 \n",
       "Q 2225 4425 2512 4075 \n",
       "Q 2800 3725 2800 3300 \n",
       "L 2225 3300 \n",
       "Q 2225 3550 2087 3750 \n",
       "Q 1950 3950 1725 3950 \n",
       "Q 1350 3950 1150 3562 \n",
       "Q 950 3175 925 2375 \n",
       "Q 1100 2700 1300 2825 \n",
       "Q 1500 2950 1775 2950 \n",
       "Q 2250 2950 2550 2575 \n",
       "Q 2850 2200 2850 1550 \n",
       "z\n",
       "M 2250 1550 \n",
       "Q 2250 2000 2100 2250 \n",
       "Q 1950 2500 1675 2500 \n",
       "Q 1350 2500 1162 2250 \n",
       "Q 975 2000 975 1650 \n",
       "Q 975 1100 1162 800 \n",
       "Q 1350 500 1675 500 \n",
       "Q 1900 500 2075 725 \n",
       "Q 2250 950 2250 1550 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-36\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc84f383583\" x=\"42.41875\" y=\"71.100785\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.8 -->\n",
       "      <g transform=\"translate(20.41875 74.518754)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-38\" d=\"M 2875 1325 \n",
       "Q 2875 700 2525 375 \n",
       "Q 2175 50 1575 50 \n",
       "Q 975 50 625 375 \n",
       "Q 275 700 275 1325 \n",
       "Q 275 1650 475 1912 \n",
       "Q 675 2175 1025 2300 \n",
       "Q 725 2425 562 2650 \n",
       "Q 400 2875 400 3225 \n",
       "Q 400 3775 750 4100 \n",
       "Q 1100 4425 1575 4425 \n",
       "Q 2050 4425 2400 4100 \n",
       "Q 2750 3775 2750 3225 \n",
       "Q 2750 2875 2587 2650 \n",
       "Q 2425 2425 2125 2300 \n",
       "Q 2475 2175 2675 1912 \n",
       "Q 2875 1650 2875 1325 \n",
       "z\n",
       "M 2200 3225 \n",
       "Q 2200 3625 2025 3800 \n",
       "Q 1850 3975 1575 3975 \n",
       "Q 1300 3975 1125 3800 \n",
       "Q 950 3625 950 3225 \n",
       "Q 950 2825 1137 2662 \n",
       "Q 1325 2500 1575 2500 \n",
       "Q 1825 2500 2012 2662 \n",
       "Q 2200 2825 2200 3225 \n",
       "z\n",
       "M 2300 1325 \n",
       "Q 2300 1675 2112 1875 \n",
       "Q 1925 2075 1575 2075 \n",
       "Q 1225 2075 1037 1875 \n",
       "Q 850 1675 850 1325 \n",
       "Q 850 925 1050 712 \n",
       "Q 1250 500 1575 500 \n",
       "Q 1900 500 2100 712 \n",
       "Q 2300 925 2300 1325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-38\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc84f383583\" x=\"42.41875\" y=\"25.361569\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(20.41875 28.779537)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-2e\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- 容量 -->\n",
       "     <g transform=\"translate(15.129688 128.08)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-5bb9\" d=\"M 1125 2475 \n",
       "Q 1000 2725 800 2875 \n",
       "Q 1875 3325 2250 3800 \n",
       "Q 2425 3650 2675 3425 \n",
       "Q 1725 2775 1125 2475 \n",
       "z\n",
       "M 3725 3425 \n",
       "Q 3925 3625 4000 3800 \n",
       "Q 5150 3125 5525 2900 \n",
       "Q 5325 2700 5200 2475 \n",
       "Q 4375 3075 3725 3425 \n",
       "z\n",
       "M 800 3400 \n",
       "Q 825 3675 825 3937 \n",
       "Q 825 4200 800 4425 \n",
       "L 3175 4425 \n",
       "Q 3100 4625 2900 5050 \n",
       "Q 3025 5125 3300 5250 \n",
       "Q 3400 5075 3575 4650 \n",
       "Q 3400 4575 3200 4425 \n",
       "L 5650 4425 \n",
       "Q 5650 4200 5650 3962 \n",
       "Q 5650 3725 5650 3475 \n",
       "L 5225 3475 \n",
       "L 5225 4075 \n",
       "L 1250 4075 \n",
       "L 1250 3400 \n",
       "L 800 3400 \n",
       "z\n",
       "M 3075 3350 \n",
       "Q 3350 3200 3675 3075 \n",
       "L 3425 2750 \n",
       "Q 4050 2175 4700 1875 \n",
       "Q 5350 1575 6100 1525 \n",
       "Q 5875 1325 5775 975 \n",
       "Q 5325 1100 4850 1300 \n",
       "Q 4850 -175 4875 -575 \n",
       "L 4400 -575 \n",
       "L 4400 -200 \n",
       "L 2050 -200 \n",
       "L 2050 -650 \n",
       "L 1575 -650 \n",
       "Q 1600 -300 1600 1300 \n",
       "Q 1100 975 550 700 \n",
       "Q 500 1000 225 1250 \n",
       "Q 1425 1675 2137 2250 \n",
       "Q 2850 2825 3075 3350 \n",
       "z\n",
       "M 3150 2525 \n",
       "Q 2550 1875 1750 1425 \n",
       "L 4600 1425 \n",
       "Q 3900 1650 3150 2525 \n",
       "z\n",
       "M 2050 1050 \n",
       "L 2050 175 \n",
       "L 4400 175 \n",
       "L 4400 1050 \n",
       "L 2050 1050 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-91cf\" d=\"M 3450 2175 \n",
       "L 3450 1800 \n",
       "L 4750 1800 \n",
       "L 4750 2175 \n",
       "L 3450 2175 \n",
       "z\n",
       "M 3450 1525 \n",
       "L 3450 1175 \n",
       "L 4750 1175 \n",
       "L 4750 1525 \n",
       "L 3450 1525 \n",
       "z\n",
       "M 1675 2175 \n",
       "L 1675 1800 \n",
       "L 3000 1800 \n",
       "L 3000 2175 \n",
       "L 1675 2175 \n",
       "z\n",
       "M 1675 1525 \n",
       "L 1675 1175 \n",
       "L 3000 1175 \n",
       "L 3000 1525 \n",
       "L 1675 1525 \n",
       "z\n",
       "M 1200 2450 \n",
       "L 5250 2450 \n",
       "Q 5200 2150 5200 1737 \n",
       "Q 5200 1325 5250 900 \n",
       "L 3450 900 \n",
       "L 3450 500 \n",
       "L 4600 500 \n",
       "Q 5000 525 5375 525 \n",
       "L 5375 175 \n",
       "Q 5000 225 4600 225 \n",
       "L 3450 225 \n",
       "L 3450 -225 \n",
       "L 5125 -225 \n",
       "Q 5550 -200 5950 -200 \n",
       "L 5950 -525 \n",
       "Q 5550 -500 5125 -500 \n",
       "L 1300 -500 \n",
       "Q 900 -500 475 -525 \n",
       "L 475 -200 \n",
       "Q 925 -200 1300 -225 \n",
       "L 3000 -225 \n",
       "L 3000 225 \n",
       "L 1750 225 \n",
       "Q 1375 225 1000 175 \n",
       "L 1000 525 \n",
       "Q 1400 525 1750 500 \n",
       "L 3000 500 \n",
       "L 3000 900 \n",
       "L 1200 900 \n",
       "Q 1225 1300 1225 1712 \n",
       "Q 1225 2125 1200 2450 \n",
       "z\n",
       "M 1675 4775 \n",
       "L 1675 4350 \n",
       "L 4750 4350 \n",
       "L 4750 4775 \n",
       "L 1675 4775 \n",
       "z\n",
       "M 1675 4075 \n",
       "L 1675 3675 \n",
       "L 4750 3675 \n",
       "L 4750 4075 \n",
       "L 1675 4075 \n",
       "z\n",
       "M 1200 5050 \n",
       "L 5250 5050 \n",
       "Q 5200 4650 5200 4300 \n",
       "Q 5200 3950 5250 3400 \n",
       "L 1200 3400 \n",
       "Q 1225 3950 1212 4300 \n",
       "Q 1200 4650 1200 5050 \n",
       "z\n",
       "M 475 3150 \n",
       "Q 1100 3125 1750 3100 \n",
       "L 4825 3100 \n",
       "Q 5400 3125 5900 3150 \n",
       "L 5900 2800 \n",
       "Q 5400 2825 4850 2825 \n",
       "L 1750 2825 \n",
       "Q 1100 2825 475 2800 \n",
       "L 475 3150 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-5bb9\"/>\n",
       "      <use xlink:href=\"#SimHei-91cf\" x=\"100\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 67.782386 58.182333 \n",
       "L 70.784 60.505924 \n",
       "L 73.785614 63.016563 \n",
       "L 76.787228 63.036383 \n",
       "L 79.788841 63.177493 \n",
       "L 82.790455 62.945103 \n",
       "L 85.792069 63.063 \n",
       "L 88.793683 65.210308 \n",
       "L 91.795297 65.435102 \n",
       "L 97.798524 65.47039 \n",
       "L 100.800138 67.852858 \n",
       "L 106.803365 68.026997 \n",
       "L 109.804979 70.506632 \n",
       "L 112.806593 70.618945 \n",
       "L 118.80982 70.399073 \n",
       "L 121.811434 70.465553 \n",
       "L 124.813048 60.346124 \n",
       "L 127.814662 60.256632 \n",
       "L 130.816276 62.82715 \n",
       "L 133.817889 65.204829 \n",
       "L 136.819503 65.357393 \n",
       "L 139.821117 65.250395 \n",
       "L 142.822731 67.891921 \n",
       "L 145.824344 67.723128 \n",
       "L 148.825958 67.90604 \n",
       "L 151.827572 70.468288 \n",
       "L 154.829186 70.168382 \n",
       "L 157.830799 59.253744 \n",
       "L 160.832413 64.078936 \n",
       "L 166.835641 68.97209 \n",
       "L 169.837255 70.046518 \n",
       "L 172.838868 71.243248 \n",
       "L 175.840482 73.743772 \n",
       "L 178.842096 75.006217 \n",
       "L 181.84371 77.267868 \n",
       "L 184.845323 77.266945 \n",
       "L 190.848551 79.71918 \n",
       "L 193.850165 78.506583 \n",
       "L 196.851779 79.638385 \n",
       "L 199.853392 82.139833 \n",
       "L 202.855006 84.399552 \n",
       "L 205.85662 85.716442 \n",
       "L 208.858234 72.558948 \n",
       "L 211.859847 74.945389 \n",
       "L 214.861461 78.564463 \n",
       "L 220.864689 83.251266 \n",
       "L 226.867916 85.640709 \n",
       "L 232.871144 90.355499 \n",
       "L 235.872758 91.561457 \n",
       "L 238.874371 92.5949 \n",
       "L 244.877599 95.209958 \n",
       "L 247.879213 97.423039 \n",
       "L 250.880826 99.808053 \n",
       "L 253.88244 99.786306 \n",
       "L 256.884054 102.268316 \n",
       "L 262.887281 104.523789 \n",
       "L 265.888895 107.085248 \n",
       "L 274.893737 110.493023 \n",
       "L 277.89535 111.779989 \n",
       "L 280.896964 114.249867 \n",
       "L 286.900192 116.493704 \n",
       "L 289.901805 119.04252 \n",
       "L 292.903419 120.090002 \n",
       "L 295.905033 120.283462 \n",
       "L 298.906647 117.863098 \n",
       "L 301.90826 122.619111 \n",
       "L 304.909874 124.866777 \n",
       "L 307.911488 126.041371 \n",
       "L 310.913102 126.106408 \n",
       "L 313.914716 127.202368 \n",
       "L 316.916329 128.532292 \n",
       "L 322.919557 133.325728 \n",
       "L 325.921171 133.185993 \n",
       "L 328.922784 134.530255 \n",
       "L 331.924398 135.710631 \n",
       "L 334.926012 115.509242 \n",
       "L 337.927626 125.10756 \n",
       "L 343.930853 132.305445 \n",
       "L 346.932467 133.545603 \n",
       "L 349.934081 135.831541 \n",
       "L 358.938922 139.356193 \n",
       "L 361.940536 141.803458 \n",
       "L 367.943763 144.188924 \n",
       "L 370.945377 145.379079 \n",
       "L 376.948605 140.603392 \n",
       "L 379.950219 144.100438 \n",
       "L 382.951832 146.626676 \n",
       "L 385.953446 150.252218 \n",
       "L 388.95506 150.196192 \n",
       "L 391.956674 149.995501 \n",
       "L 394.958287 151.363467 \n",
       "L 397.959901 153.735325 \n",
       "L 400.961515 154.930378 \n",
       "L 403.963129 154.941708 \n",
       "L 415.969584 159.741275 \n",
       "L 418.971198 159.702497 \n",
       "L 421.972811 160.841499 \n",
       "L 424.974425 154.942587 \n",
       "L 427.976039 153.830445 \n",
       "L 430.977653 158.610261 \n",
       "L 433.979266 160.982538 \n",
       "L 436.98088 162.303918 \n",
       "L 439.982494 163.333726 \n",
       "L 451.988949 168.242552 \n",
       "L 454.990563 169.322824 \n",
       "L 457.992177 169.323795 \n",
       "L 460.99379 170.644068 \n",
       "L 466.997018 165.755459 \n",
       "L 469.998632 169.474403 \n",
       "L 473.000245 170.633254 \n",
       "L 476.001859 173.025586 \n",
       "L 482.005087 172.938253 \n",
       "L 491.009928 176.53165 \n",
       "L 494.011542 176.549226 \n",
       "L 500.014769 178.897956 \n",
       "L 506.017997 181.29361 \n",
       "L 512.021224 181.265279 \n",
       "L 515.022838 179.989296 \n",
       "L 518.024452 171.699233 \n",
       "L 521.026066 176.408312 \n",
       "L 524.02768 178.810085 \n",
       "L 533.032521 182.367115 \n",
       "L 536.034135 182.429565 \n",
       "L 539.035748 183.665912 \n",
       "L 542.037362 184.755209 \n",
       "L 548.04059 184.668962 \n",
       "L 551.042203 185.932042 \n",
       "L 554.043817 185.889407 \n",
       "L 557.045431 186.943671 \n",
       "L 560.047045 188.192402 \n",
       "L 563.048659 188.318384 \n",
       "L 566.050272 183.387047 \n",
       "L 569.051886 179.713281 \n",
       "L 569.051886 179.713281 \n",
       "\" clip-path=\"url(#pef52be67e2)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 67.782386 17.28 \n",
       "L 70.784 19.612093 \n",
       "L 73.785614 22.31388 \n",
       "L 76.787228 22.323418 \n",
       "L 79.788841 25.24074 \n",
       "L 82.790455 22.182904 \n",
       "L 85.792069 22.365397 \n",
       "L 88.793683 32.499213 \n",
       "L 91.795297 32.641839 \n",
       "L 94.79691 35.142719 \n",
       "L 97.798524 37.802829 \n",
       "L 103.801752 42.907142 \n",
       "L 115.808207 53.198828 \n",
       "L 118.80982 55.647856 \n",
       "L 121.811434 55.643386 \n",
       "L 124.813048 30.020897 \n",
       "L 127.814662 35.069738 \n",
       "L 130.816276 37.753462 \n",
       "L 133.817889 42.686186 \n",
       "L 136.819503 37.715472 \n",
       "L 139.821117 47.909188 \n",
       "L 142.822731 53.1083 \n",
       "L 145.824344 55.47944 \n",
       "L 148.825958 58.288222 \n",
       "L 151.827572 60.763769 \n",
       "L 154.829186 58.012762 \n",
       "L 157.830799 42.564982 \n",
       "L 160.832413 52.294705 \n",
       "L 163.834027 58.459223 \n",
       "L 166.835641 62.12426 \n",
       "L 169.837255 66.860849 \n",
       "L 172.838868 68.018646 \n",
       "L 178.842096 75.444952 \n",
       "L 184.845323 80.140856 \n",
       "L 187.846937 82.468952 \n",
       "L 190.848551 84.938612 \n",
       "L 193.850165 81.466056 \n",
       "L 196.851779 78.89038 \n",
       "L 199.853392 86.24304 \n",
       "L 202.855006 90.922809 \n",
       "L 205.85662 93.419743 \n",
       "L 208.858234 65.676237 \n",
       "L 211.859847 69.24185 \n",
       "L 214.861461 76.644127 \n",
       "L 217.863075 83.738305 \n",
       "L 220.864689 87.290859 \n",
       "L 223.866302 92.115975 \n",
       "L 226.867916 94.52031 \n",
       "L 229.86953 98.072411 \n",
       "L 235.872758 102.944624 \n",
       "L 238.874371 105.148825 \n",
       "L 244.877599 110.162089 \n",
       "L 247.879213 114.816125 \n",
       "L 250.880826 116.033964 \n",
       "L 253.88244 117.07528 \n",
       "L 256.884054 119.669586 \n",
       "L 259.885668 120.734244 \n",
       "L 262.887281 124.355495 \n",
       "L 265.888895 125.680336 \n",
       "L 271.892123 130.407588 \n",
       "L 274.893737 133.920425 \n",
       "L 277.89535 132.812814 \n",
       "L 280.896964 134.070722 \n",
       "L 283.898578 136.382242 \n",
       "L 289.901805 138.795412 \n",
       "L 292.903419 141.191516 \n",
       "L 295.905033 142.538053 \n",
       "L 298.906647 132.782949 \n",
       "L 301.90826 138.777442 \n",
       "L 304.909874 142.280299 \n",
       "L 307.911488 144.677362 \n",
       "L 310.913102 144.635727 \n",
       "L 316.916329 147.13846 \n",
       "L 319.917943 150.771806 \n",
       "L 322.919557 150.704454 \n",
       "L 325.921171 151.796547 \n",
       "L 328.922784 151.863934 \n",
       "L 331.924398 153.048493 \n",
       "L 334.926012 118.306707 \n",
       "L 337.927626 129.100344 \n",
       "L 340.92924 136.346498 \n",
       "L 346.932467 143.57204 \n",
       "L 352.935695 148.226151 \n",
       "L 355.937308 150.72442 \n",
       "L 361.940536 153.115682 \n",
       "L 364.94215 155.441442 \n",
       "L 370.945377 157.893772 \n",
       "L 373.946991 157.845066 \n",
       "L 376.948605 150.62852 \n",
       "L 379.950219 155.36211 \n",
       "L 382.951832 159.145174 \n",
       "L 388.95506 161.454646 \n",
       "L 391.956674 163.685124 \n",
       "L 394.958287 163.829182 \n",
       "L 400.961515 166.275415 \n",
       "L 403.963129 168.598172 \n",
       "L 406.964742 167.471944 \n",
       "L 409.966356 168.580196 \n",
       "L 412.96797 169.838475 \n",
       "L 421.972811 173.266393 \n",
       "L 424.974425 166.201632 \n",
       "L 427.976039 161.402169 \n",
       "L 430.977653 167.446093 \n",
       "L 436.98088 172.34108 \n",
       "L 442.984108 174.606364 \n",
       "L 445.985721 176.985352 \n",
       "L 451.988949 179.518649 \n",
       "L 454.990563 180.513851 \n",
       "L 457.992177 180.594734 \n",
       "L 460.99379 181.870068 \n",
       "L 463.995404 180.66849 \n",
       "L 466.997018 174.601112 \n",
       "L 469.998632 179.499798 \n",
       "L 473.000245 183.134723 \n",
       "L 479.003473 185.35593 \n",
       "L 482.005087 185.394913 \n",
       "L 488.008314 190.19357 \n",
       "L 491.009928 190.203916 \n",
       "L 494.011542 191.386516 \n",
       "L 497.013156 191.365789 \n",
       "L 500.014769 193.73587 \n",
       "L 503.016383 195.022645 \n",
       "L 506.017997 196.138111 \n",
       "L 509.019611 196.144637 \n",
       "L 512.021224 197.321012 \n",
       "L 515.022838 196.09796 \n",
       "L 518.024452 187.78041 \n",
       "L 521.026066 193.787038 \n",
       "L 527.029293 200.972649 \n",
       "L 533.032521 203.346636 \n",
       "L 536.034135 205.779294 \n",
       "L 539.035748 207.034082 \n",
       "L 542.037362 208.114065 \n",
       "L 545.038976 210.470372 \n",
       "L 554.043817 214.128392 \n",
       "L 557.045431 218.88 \n",
       "L 560.047045 216.459795 \n",
       "L 563.048659 217.741285 \n",
       "L 566.050272 214.041579 \n",
       "L 569.051886 211.594452 \n",
       "L 569.051886 211.594452 \n",
       "\" clip-path=\"url(#pef52be67e2)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 67.782386 50.277482 \n",
       "L 70.784 52.659413 \n",
       "L 76.787228 52.628796 \n",
       "L 79.788841 52.930682 \n",
       "L 82.790455 52.644931 \n",
       "L 85.792069 52.819906 \n",
       "L 88.793683 52.460039 \n",
       "L 91.795297 55.162775 \n",
       "L 97.798524 55.081942 \n",
       "L 100.800138 57.458629 \n",
       "L 103.801752 57.590642 \n",
       "L 112.806593 57.668196 \n",
       "L 115.808207 60.165158 \n",
       "L 118.80982 60.003241 \n",
       "L 121.811434 60.036708 \n",
       "L 124.813048 52.626591 \n",
       "L 127.814662 52.468421 \n",
       "L 130.816276 52.554577 \n",
       "L 133.817889 54.861313 \n",
       "L 136.819503 55.046431 \n",
       "L 139.821117 54.938481 \n",
       "L 142.822731 57.467648 \n",
       "L 145.824344 57.371265 \n",
       "L 148.825958 57.56991 \n",
       "L 151.827572 60.091397 \n",
       "L 154.829186 59.848548 \n",
       "L 157.830799 52.012039 \n",
       "L 160.832413 56.733843 \n",
       "L 163.834027 59.18914 \n",
       "L 166.835641 60.363397 \n",
       "L 169.837255 62.678267 \n",
       "L 172.838868 62.60199 \n",
       "L 175.840482 63.857463 \n",
       "L 178.842096 66.264527 \n",
       "L 184.845323 68.497867 \n",
       "L 187.846937 68.446622 \n",
       "L 190.848551 69.716054 \n",
       "L 193.850165 68.08104 \n",
       "L 196.851779 69.668188 \n",
       "L 202.855006 74.328771 \n",
       "L 205.85662 75.599955 \n",
       "L 208.858234 67.653034 \n",
       "L 211.859847 67.509681 \n",
       "L 214.861461 71.045162 \n",
       "L 220.864689 75.596256 \n",
       "L 226.867916 77.901526 \n",
       "L 232.871144 82.616183 \n",
       "L 235.872758 82.615615 \n",
       "L 238.874371 83.672497 \n",
       "L 241.875985 84.903566 \n",
       "L 244.877599 87.437866 \n",
       "L 247.879213 88.504482 \n",
       "L 250.880826 90.773478 \n",
       "L 253.88244 90.775463 \n",
       "L 256.884054 93.135168 \n",
       "L 259.885668 93.052465 \n",
       "L 262.887281 95.440539 \n",
       "L 265.888895 96.79302 \n",
       "L 268.890509 97.841203 \n",
       "L 289.901805 106.041552 \n",
       "L 292.903419 108.512335 \n",
       "L 295.905033 108.548526 \n",
       "L 298.906647 107.436206 \n",
       "L 301.90826 109.620048 \n",
       "L 304.909874 111.988606 \n",
       "L 307.911488 113.083137 \n",
       "L 310.913102 113.221226 \n",
       "L 313.914716 113.015247 \n",
       "L 316.916329 114.355084 \n",
       "L 319.917943 116.688984 \n",
       "L 322.919557 117.773664 \n",
       "L 325.921171 117.704941 \n",
       "L 328.922784 117.799035 \n",
       "L 331.924398 118.97813 \n",
       "L 334.926012 96.52696 \n",
       "L 337.927626 110.895314 \n",
       "L 346.932467 117.989269 \n",
       "L 352.935695 120.190008 \n",
       "L 355.937308 121.419934 \n",
       "L 358.938922 122.507422 \n",
       "L 361.940536 123.746969 \n",
       "L 364.94215 123.642214 \n",
       "L 367.943763 124.787219 \n",
       "L 370.945377 126.071562 \n",
       "L 373.946991 124.848468 \n",
       "L 376.948605 122.562091 \n",
       "L 379.950219 124.780074 \n",
       "L 382.951832 126.043761 \n",
       "L 385.953446 128.298204 \n",
       "L 388.95506 129.675076 \n",
       "L 391.956674 129.413998 \n",
       "L 394.958287 129.511133 \n",
       "L 397.959901 131.86335 \n",
       "L 400.961515 133.13222 \n",
       "L 406.964742 133.056463 \n",
       "L 415.969584 136.588313 \n",
       "L 421.972811 136.519971 \n",
       "L 424.974425 131.943109 \n",
       "L 427.976039 130.759067 \n",
       "L 430.977653 134.306711 \n",
       "L 433.979266 136.603618 \n",
       "L 436.98088 137.929193 \n",
       "L 439.982494 138.978681 \n",
       "L 445.985721 141.345121 \n",
       "L 448.987335 141.444408 \n",
       "L 454.990563 143.703752 \n",
       "L 457.992177 143.646056 \n",
       "L 460.99379 144.97621 \n",
       "L 463.995404 143.848652 \n",
       "L 466.997018 140.135757 \n",
       "L 469.998632 143.80841 \n",
       "L 476.001859 146.095426 \n",
       "L 479.003473 146.05638 \n",
       "L 491.009928 150.834536 \n",
       "L 494.011542 150.774857 \n",
       "L 497.013156 151.872551 \n",
       "L 500.014769 151.886061 \n",
       "L 506.017997 154.289985 \n",
       "L 509.019611 154.159676 \n",
       "L 512.021224 154.278804 \n",
       "L 515.022838 153.006564 \n",
       "L 518.024452 147.209389 \n",
       "L 521.026066 150.718115 \n",
       "L 524.02768 151.798947 \n",
       "L 527.029293 153.021874 \n",
       "L 530.030907 155.345343 \n",
       "L 533.032521 155.304755 \n",
       "L 536.034135 156.574514 \n",
       "L 539.035748 156.61305 \n",
       "L 545.038976 158.845233 \n",
       "L 548.04059 158.787852 \n",
       "L 551.042203 160.100112 \n",
       "L 554.043817 160.064712 \n",
       "L 557.045431 161.167836 \n",
       "L 560.047045 161.130234 \n",
       "L 563.048659 162.475106 \n",
       "L 566.050272 157.596729 \n",
       "L 569.051886 155.156824 \n",
       "L 569.051886 155.156824 \n",
       "\" clip-path=\"url(#pef52be67e2)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 67.782386 58.521466 \n",
       "L 70.784 61.222136 \n",
       "L 73.785614 62.043999 \n",
       "L 76.787228 64.085852 \n",
       "L 79.788841 63.622376 \n",
       "L 82.790455 64.576341 \n",
       "L 85.792069 66.252156 \n",
       "L 88.793683 67.631463 \n",
       "L 91.795297 70.117837 \n",
       "L 94.79691 65.817853 \n",
       "L 97.798524 68.327764 \n",
       "L 100.800138 70.027826 \n",
       "L 103.801752 73.194646 \n",
       "L 106.803365 74.880966 \n",
       "L 109.804979 75.460049 \n",
       "L 112.806593 77.685165 \n",
       "L 115.808207 78.274889 \n",
       "L 118.80982 81.705312 \n",
       "L 121.811434 83.400119 \n",
       "L 124.813048 85.356616 \n",
       "L 127.814662 86.762653 \n",
       "L 130.816276 92.004752 \n",
       "L 133.817889 91.347259 \n",
       "L 136.819503 92.254683 \n",
       "L 139.821117 82.709808 \n",
       "L 142.822731 86.476088 \n",
       "L 148.825958 91.261191 \n",
       "L 151.827572 94.137836 \n",
       "L 154.829186 95.334189 \n",
       "L 157.830799 98.109173 \n",
       "L 160.832413 99.235649 \n",
       "L 163.834027 101.855164 \n",
       "L 166.835641 103.76031 \n",
       "L 172.838868 107.97342 \n",
       "L 175.840482 110.516854 \n",
       "L 178.842096 111.773536 \n",
       "L 181.84371 113.636735 \n",
       "L 184.845323 99.447295 \n",
       "L 187.846937 105.565137 \n",
       "L 190.848551 109.434138 \n",
       "L 193.850165 113.085733 \n",
       "L 196.851779 114.346565 \n",
       "L 199.853392 117.877396 \n",
       "L 202.855006 87.862506 \n",
       "L 205.85662 90.181495 \n",
       "L 208.858234 94.925529 \n",
       "L 211.859847 99.052404 \n",
       "L 214.861461 102.967596 \n",
       "L 217.863075 101.652082 \n",
       "L 220.864689 106.129336 \n",
       "L 223.866302 110.947877 \n",
       "L 226.867916 114.059573 \n",
       "L 229.86953 115.528044 \n",
       "L 232.871144 99.997606 \n",
       "L 235.872758 107.592708 \n",
       "L 238.874371 113.806272 \n",
       "L 241.875985 118.647516 \n",
       "L 244.877599 119.904258 \n",
       "L 247.879213 121.396393 \n",
       "L 250.880826 125.033428 \n",
       "L 253.88244 126.989928 \n",
       "L 256.884054 130.514991 \n",
       "L 259.885668 132.354445 \n",
       "L 262.887281 132.477498 \n",
       "L 265.888895 134.618927 \n",
       "L 268.890509 138.216975 \n",
       "L 274.893737 140.54357 \n",
       "L 277.89535 132.065168 \n",
       "L 280.896964 134.25629 \n",
       "L 283.898578 139.436981 \n",
       "L 289.901805 143.523379 \n",
       "L 292.903419 144.114826 \n",
       "L 295.905033 145.768276 \n",
       "L 298.906647 147.023473 \n",
       "L 304.909874 151.632428 \n",
       "L 307.911488 150.508437 \n",
       "L 310.913102 152.851484 \n",
       "L 313.914716 153.598028 \n",
       "L 316.916329 156.027631 \n",
       "L 319.917943 156.884073 \n",
       "L 322.919557 146.613593 \n",
       "L 325.921171 150.553928 \n",
       "L 328.922784 152.783204 \n",
       "L 331.924398 156.089724 \n",
       "L 334.926012 159.044769 \n",
       "L 337.927626 150.097747 \n",
       "L 340.92924 156.103012 \n",
       "L 343.930853 158.07329 \n",
       "L 346.932467 159.020555 \n",
       "L 349.934081 161.280215 \n",
       "L 352.935695 160.647626 \n",
       "L 355.937308 163.298517 \n",
       "L 358.938922 164.050411 \n",
       "L 361.940536 165.011531 \n",
       "L 364.94215 167.481285 \n",
       "L 367.943763 166.032274 \n",
       "L 370.945377 169.365732 \n",
       "L 373.946991 168.674782 \n",
       "L 376.948605 169.909217 \n",
       "L 379.950219 172.478531 \n",
       "L 382.951832 148.75888 \n",
       "L 385.953446 151.121568 \n",
       "L 388.95506 153.856591 \n",
       "L 391.956674 156.091521 \n",
       "L 394.958287 159.197385 \n",
       "L 397.959901 159.40282 \n",
       "L 400.961515 162.823198 \n",
       "L 403.963129 163.646711 \n",
       "L 406.964742 164.855628 \n",
       "L 409.966356 165.774754 \n",
       "L 412.96797 165.274341 \n",
       "L 418.971198 170.648326 \n",
       "L 421.972811 171.959079 \n",
       "L 424.974425 174.876005 \n",
       "L 427.976039 156.440378 \n",
       "L 430.977653 161.104551 \n",
       "L 433.979266 164.067857 \n",
       "L 436.98088 165.266545 \n",
       "L 439.982494 169.397143 \n",
       "L 442.984108 167.222853 \n",
       "L 445.985721 169.746865 \n",
       "L 448.987335 171.101079 \n",
       "L 451.988949 170.948324 \n",
       "L 454.990563 173.587594 \n",
       "L 457.992177 172.916972 \n",
       "L 460.99379 176.060522 \n",
       "L 460.99379 176.060522 \n",
       "\" clip-path=\"url(#pef52be67e2)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #bfbf00; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 67.782386 162.579217 \n",
       "L 575.055114 162.579217 \n",
       "L 575.055114 162.579217 \n",
       "\" clip-path=\"url(#pef52be67e2)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 42.41875 228.96 \n",
       "L 42.41875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 600.41875 228.96 \n",
       "L 600.41875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 42.41875 228.96 \n",
       "L 600.41875 228.96 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 42.41875 7.2 \n",
       "L 600.41875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 536.41875 68.35625 \n",
       "L 593.41875 68.35625 \n",
       "Q 595.41875 68.35625 595.41875 66.35625 \n",
       "L 595.41875 14.2 \n",
       "Q 595.41875 12.2 593.41875 12.2 \n",
       "L 536.41875 12.2 \n",
       "Q 534.41875 12.2 534.41875 14.2 \n",
       "L 534.41875 66.35625 \n",
       "Q 534.41875 68.35625 536.41875 68.35625 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 538.41875 19.7 \n",
       "L 548.41875 19.7 \n",
       "L 558.41875 19.7 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- B0005 -->\n",
       "     <g transform=\"translate(566.41875 23.2)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-42\" d=\"M 2975 1375 \n",
       "Q 2975 650 2575 375 \n",
       "Q 2175 100 1550 100 \n",
       "L 300 100 \n",
       "L 300 4375 \n",
       "L 1600 4375 \n",
       "Q 2225 4375 2537 4050 \n",
       "Q 2850 3725 2850 3275 \n",
       "Q 2850 2825 2637 2612 \n",
       "Q 2425 2400 2200 2325 \n",
       "Q 2500 2250 2737 2012 \n",
       "Q 2975 1775 2975 1375 \n",
       "z\n",
       "M 2275 3275 \n",
       "Q 2275 3600 2087 3750 \n",
       "Q 1900 3900 1625 3900 \n",
       "L 875 3900 \n",
       "L 875 2575 \n",
       "L 1600 2575 \n",
       "Q 1875 2575 2075 2737 \n",
       "Q 2275 2900 2275 3275 \n",
       "z\n",
       "M 2375 1375 \n",
       "Q 2375 1775 2112 1937 \n",
       "Q 1850 2100 1525 2100 \n",
       "L 875 2100 \n",
       "L 875 575 \n",
       "L 1450 575 \n",
       "Q 1900 575 2137 750 \n",
       "Q 2375 925 2375 1375 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-35\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <path d=\"M 538.41875 32.989063 \n",
       "L 548.41875 32.989063 \n",
       "L 558.41875 32.989063 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- B0006 -->\n",
       "     <g transform=\"translate(566.41875 36.489063)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-36\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_21\">\n",
       "     <path d=\"M 538.41875 46.278125 \n",
       "L 548.41875 46.278125 \n",
       "L 558.41875 46.278125 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- B0007 -->\n",
       "     <g transform=\"translate(566.41875 49.778125)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-37\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 538.41875 59.567188 \n",
       "L 548.41875 59.567188 \n",
       "L 558.41875 59.567188 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #bfbf00; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- B0018 -->\n",
       "     <g transform=\"translate(566.41875 63.067188)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-42\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-31\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-38\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pef52be67e2\">\n",
       "   <rect x=\"42.41875\" y=\"7.2\" width=\"558\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 800x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def matplot_battery_list(battery_data_list):\n",
    "    color_list = ['b:', 'g--', 'r-.', 'y:']\n",
    "    # 1.创建画布\n",
    "    plt.figure(figsize=(10, 4), dpi=80)\n",
    "    plt.xlabel('循环次数')\n",
    "    plt.ylabel('容量')\n",
    "\n",
    "    # 2.绘制折线图\n",
    "    for index, data in enumerate(battery_data_list):\n",
    "        plt.plot([i for i in range(len(battery_data_list[index]))], battery_data_list[index], color_list[index])\n",
    "\n",
    "    plt.plot([i for i in range(170)], [1.4] * 170)\n",
    "\n",
    "    # 图例\n",
    "    plt.legend([name for name in Battery_list])\n",
    "\n",
    "Battery_data_list = [Battery['B0005'][1], Battery['B0006'][1], Battery['B0007'][1], Battery['B0018'][1]]\n",
    "matplot_battery_list(Battery_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84323438",
   "metadata": {},
   "source": [
    "## 创建评估指标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8358962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:10:09.238801Z",
     "start_time": "2023-11-30T01:10:09.224845Z"
    }
   },
   "outputs": [],
   "source": [
    "# 平均绝对误差、均方根误差\n",
    "def evaluation(y_test, y_predict):\n",
    "    mae = mean_absolute_error(y_test, y_predict)\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_predict))\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# 相对误差\n",
    "# B0005 第125次循环后达到阈值1.4\n",
    "# B0006 第109次循环后达到阈值1.4\n",
    "# B0007 数据集中无任何值小于1.4，所以无法达到阈值1.4\n",
    "# B0018 第97次循环后达到阈值1.4\n",
    "def relative_error(y_test, y_predict, threshold):\n",
    "    true_re, pred_re = len(y_test), len(y_predict)\n",
    "    for i in range(len(y_test) - 1):\n",
    "        if y_test[i] <= threshold >= y_test[i + 1]:\n",
    "            true_re = i + 1\n",
    "            break\n",
    "    for i in range(len(y_predict) - 1):\n",
    "        if y_predict[i] <= threshold >= y_predict[i + 1]:\n",
    "            pred_re = i + 1\n",
    "            break\n",
    "    return abs(true_re - pred_re) / true_re\n",
    "\n",
    "# relative_error(Battery['B0006'][1], Battery['B0006'][1], 1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff09a6",
   "metadata": {},
   "source": [
    "## 构建训练序列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f166cb72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:10:18.339847Z",
     "start_time": "2023-11-30T01:10:18.331847Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构建数据\n",
    "# 采用 留一评估：一组数据为测试集，其他所有数据全部拿来训练\n",
    "# train_x 的维度是 window_size ，总样本数为 421\n",
    "# train_y 的维度是1，总样本数为421\n",
    "# train_data 是模型预测时的真实数据，用来预测下一时刻的容量，长度为 window_size\n",
    "# test_data 是 真实的容量数据，用来检验模型的各种参数\n",
    "\n",
    "def build_seq(text, window_size):\n",
    "    # text:list of capacity\n",
    "    x, y = [], []\n",
    "    for i in range(len(text) - window_size):\n",
    "        sequence = text[i:i + window_size]\n",
    "        target = text[i + 1:i + window_size + 1]\n",
    "        x.append(sequence)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def get_train_test_data(data_list, battery_i, window_size=16):\n",
    "    data_sequence = Battery[Battery_list[battery_i]][1]\n",
    "    train_data, test_data = data_sequence[:window_size], data_sequence[window_size:]\n",
    "    \n",
    "    train_x, train_y = None, None\n",
    "    for i, v in enumerate(data_list):\n",
    "        if i != battery_i:\n",
    "            data_x, data_y = build_seq(text=v, window_size=window_size)\n",
    "            if train_x is None:\n",
    "                train_x = data_x\n",
    "                train_y = data_y\n",
    "            else:\n",
    "                train_x, train_y = np.r_[train_x, data_x], np.r_[train_y, data_y]\n",
    "\n",
    "    return train_x, train_y, list(train_data), list(test_data)\n",
    "\n",
    "def load_capacity_data(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b2708",
   "metadata": {},
   "source": [
    "## 检验 train_iter 数据是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23bd1d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:11:29.303175Z",
     "start_time": "2023-11-30T01:11:29.292207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "tensor([[2.0353, 2.0251, 2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682,\n",
      "         1.9572, 1.9456, 1.9348, 1.9233, 1.9119, 1.9011, 1.8892],\n",
      "        [2.0251, 2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682, 1.9572,\n",
      "         1.9456, 1.9348, 1.9233, 1.9119, 1.9011, 1.8892, 1.8783]])\n",
      "tensor([[2.0251, 2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682, 1.9572,\n",
      "         1.9456, 1.9348, 1.9233, 1.9119, 1.9011, 1.8892, 1.8783],\n",
      "        [2.0133, 2.0133, 2.0005, 2.0139, 2.0131, 1.9688, 1.9682, 1.9572, 1.9456,\n",
      "         1.9348, 1.9233, 1.9119, 1.9011, 1.8892, 1.8783, 1.8676]])\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, train_data, test_data = get_train_test_data(Battery_data_list, 0, window_size=16)\n",
    "train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "train_iter = load_capacity_data((train_x, train_y), 2, is_train=False)\n",
    "\n",
    "# 测试 train_iter 的数据是否正确\n",
    "def validate_train_iter(train_iter):\n",
    "    for x, y in train_iter:\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        \n",
    "        print(x)\n",
    "        print(y)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "validate_train_iter(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29d90d",
   "metadata": {},
   "source": [
    "## 绘制 out 和  tgt_y的对比图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f571c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T06:19:05.501404Z",
     "start_time": "2023-10-20T06:19:05.493426Z"
    }
   },
   "outputs": [],
   "source": [
    "# 绘制 out  tgt_y的对比图\n",
    "def matlab_make(out, tgt_y):\n",
    "    color_list = ['b:', 'g:']\n",
    "    # 1.创建画布\n",
    "    fig = plt.figure(figsize=(7, 2), dpi=80)\n",
    "    plt.xlabel('循环次数')\n",
    "    plt.ylabel('容量')\n",
    "    \n",
    "    data_list = [\n",
    "        {\n",
    "            'name': 'out',\n",
    "            'x': [i for i in range(len(out))],\n",
    "            'y': out\n",
    "        },\n",
    "        {\n",
    "            'name': 'tgt_y',\n",
    "            'x': [i for i in range(len(tgt_y))],\n",
    "            'y': tgt_y\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 2.绘制折线图\n",
    "    for data,color in zip(data_list, color_list):\n",
    "        plt.plot(data['x'], data['y'], color)\n",
    "\n",
    "\n",
    "    # 图例\n",
    "    plt.legend([data['name'] for data in data_list])\n",
    "    \n",
    "    display(fig)\n",
    "    plt.close() \n",
    "\n",
    "# out_t = [1,2,3,4,5,6,7,8,9,10]\n",
    "# tgt_y_t = [11,21,31,41,51,61,71,81,91,110]\n",
    "\n",
    "# matlab_make(out_t, tgt_y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2e8a0",
   "metadata": {},
   "source": [
    "## TCN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c74aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:12:57.829539Z",
     "start_time": "2023-11-30T01:12:57.807598Z"
    }
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106cef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T07:01:58.886526Z",
     "start_time": "2023-10-15T07:01:58.880522Z"
    }
   },
   "source": [
    "## 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8690b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:12:59.705383Z",
     "start_time": "2023-11-30T01:12:59.696406Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 为了禁止hash随机化，使得实验可复现。\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c3db8",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cb0147c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:46:29.675856Z",
     "start_time": "2023-11-30T01:46:29.657905Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 初始化Shape为(max_len, d_model)的PE (positional encoding)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # 初始化一个tensor [[0, 1, 2, 3, ...]]\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # 这里就是sin和cos括号中的内容，通过e和ln进行了变换\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        # 计算PE(pos, 2i)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算PE(pos, 2i+1)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 为了方便计算，在最外面在unsqueeze出一个batch\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 如果一个参数不参与梯度下降，但又希望保存model的时候将其保存下来\n",
    "        # 这个时候就可以用register_buffer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x 为embedding后的inputs，例如(1,7, 128)，batch size为1,7个单词，单词维度为128\n",
    "        \"\"\"\n",
    "        # 将x和positional encoding相加。\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=128, nhead=16, num_encoder_layers=2, dim_feedforward=512, dropout=0.1,\n",
    "                num_channels=[64], kernel_size=7, tcn_dropout=0.1):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 定义TransformerEncoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, \n",
    "                                                    nhead=nhead, \n",
    "                                                    dim_feedforward=dim_feedforward, \n",
    "                                                    dropout=dropout, \n",
    "                                                    batch_first=True)\n",
    "        self.transformerEncoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n",
    "        \n",
    "        self.linear_embedding = nn.Linear(1, d_model)\n",
    "\n",
    "        # 定义位置编码器\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=0)\n",
    "        \n",
    "        # tcn\n",
    "        self.tcn = TemporalConvNet(d_model, num_channels, kernel_size=kernel_size, dropout=tcn_dropout)\n",
    "\n",
    "        # 定义最后的线性层，这里并没有用Softmax，因为没必要。\n",
    "        # 因为后面的CrossEntropyLoss中自带了\n",
    "        self.predictor = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 对 x 进行编码\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "        \n",
    "        x = self.linear_embedding(x)\n",
    "        \n",
    "        # 给x的token增加位置信息\n",
    "        x = self.positional_encoding(x)\n",
    "    \n",
    "        \n",
    "        out = self.transformerEncoder(x)\n",
    "        \n",
    "        \n",
    "        # tcn\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.tcn(out).permute(0, 2, 1) # 输出 out shape: (batch_size, seq_len, d_model * 2)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.predictor(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa74dc",
   "metadata": {},
   "source": [
    "## 测试模型的输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8faef20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:41:31.771388Z",
     "start_time": "2023-11-30T01:41:31.740471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 16, 64])\n",
      "torch.Size([50, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "# 测试模型的输出形状\n",
    "net = Net(d_model=32).to(device)\n",
    "\n",
    "# src = torch.LongTensor([[0, 3, 4, 5, 6, 1, 2, 2]])\n",
    "x = torch.ones((50, 16), dtype=torch.float32).to(device)\n",
    "\n",
    "out = net(x)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0335b",
   "metadata": {},
   "source": [
    "## 一个批次的训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "083c9efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:41:36.071971Z",
     "start_time": "2023-11-30T01:41:36.061973Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss, updater, window_size, Rated_Capacity): \n",
    "    # 将模型设置为训练模式\n",
    "    net.train()\n",
    "    \n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    for x, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        x = torch.reshape(x / Rated_Capacity, (-1, x.shape[-1])).type(torch.float32)\n",
    "        y = torch.reshape(y / Rated_Capacity, (-1, y.shape[-1])).type(torch.float32)\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #print(src.device)\n",
    "        #print(tgt.device)\n",
    "        \n",
    "        out = net(x)\n",
    "        \n",
    "    \n",
    "        #print('111out', out.shape) # (50, 153, 1)\n",
    "        # print('111tgt_y', tgt_y.shape) # (50, 153)\n",
    "        \n",
    "        l = loss(out.reshape(-1), y.reshape(-1))\n",
    "        \n",
    "        #print('222out', out[-1, :, :].cpu().data.numpy().shape) # (50, 153, 1)\n",
    "        #print('222tgt_y', tgt_y.shape) # (50, 153)\n",
    "        \n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc78239",
   "metadata": {},
   "source": [
    "## 总的训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e9d16ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:41:38.553893Z",
     "start_time": "2023-11-30T01:41:38.534945Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed):\n",
    "    net = net.to(device)\n",
    "    \n",
    "    mae_epoch_list, rmse_epoch_list, re_epoch_list, r2_epoch_list = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(net, train_iter, loss, updater, window_size, Rated_Capacity)\n",
    "        \n",
    "        # if (epoch + 1) % 100 == 0:\n",
    "        pre_list = predict(net, train_data, test_data, Rated_Capacity)\n",
    "        test_y = test_data.copy()\n",
    "\n",
    "        mae, rmse, r2 = evaluation(test_data, pre_list)\n",
    "        re = relative_error(test_y, pre_list, threshold=Rated_Capacity * 0.7)\n",
    "\n",
    "        if (len(re_epoch_list) == 0 or (r2_epoch_list[-1] < r2)):\n",
    "            print('seed: {}, 测试集: {}, epoch:{:<4d} , loss:{:<6.10f} , MAE:{:<6.4f} , RMSE:{:<6.4f} , RE:{:<6.4f} , R2:{:<6.4f}'.format(seed, Battery_list[i], epoch + 1, train_loss, mae, rmse, re, r2))\n",
    "            mae_epoch_list.append(mae)\n",
    "            rmse_epoch_list.append(rmse)\n",
    "            re_epoch_list.append(re)\n",
    "            r2_epoch_list.append(r2)\n",
    "\n",
    "\n",
    "        # matlab_make(pre_list, test_y)\n",
    "\n",
    "        # if (train_loss < 1e-3) and len(re_epoch_list) > 0 and 0.0 < re_epoch_list[-1] < 0.2 and (re_epoch_list[-1] < re):\n",
    "        #     break\n",
    "\n",
    "    return mae_epoch_list[-1], rmse_epoch_list[-1], re_epoch_list[-1], r2_epoch_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baa67d",
   "metadata": {},
   "source": [
    "## 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea03f569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:46:20.924277Z",
     "start_time": "2023-11-30T01:46:20.908320Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(net, train_data, test_data, Rated_Capacity):\n",
    "    net = net.eval()\n",
    "    \n",
    "    x = train_data.copy()\n",
    "    x = np.array(x)\n",
    "    x = torch.from_numpy(x).type(torch.float32).to(device)\n",
    "    x = torch.reshape(x / Rated_Capacity, (1, -1)) # shape: (batch_size, input_size)\n",
    "    \n",
    "    pre_list = []\n",
    "    while len(pre_list) < len(test_data):\n",
    "        \n",
    "        \n",
    "        out = net(x)\n",
    "        x = torch.cat([x[:, 1:], out[:, -1]], dim=1)\n",
    "        \n",
    "        pred = out.reshape(-1)\n",
    "        \n",
    "        pred_next_point = pred.cpu().data.numpy()[-1] * Rated_Capacity\n",
    "        \n",
    "        pre_list.append(pred_next_point)\n",
    "        \n",
    "    return pre_list\n",
    "        \n",
    "    \n",
    "# x = train_data.copy()\n",
    "# pred_list = predict(net, train_data, test_data, 2)\n",
    "# print((pred_list))\n",
    "# print((test_data))\n",
    "\n",
    "# print(len(pred_list))\n",
    "# print(len(test_data))\n",
    "# matlab_make(pred_list, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33ee6c",
   "metadata": {},
   "source": [
    "## 以4个评价指标的和为判断函数 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0b9f6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:13:18.216660Z",
     "start_time": "2023-11-30T09:08:13.429595Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************************************\n",
      "当前的 seed 为 1\n",
      "以电池 B0005 为测试数据的 数据集 开始训练\n",
      "seed: 1, 测试集: B0005, epoch:1    , loss:0.3980268538 , MAE:1.1503 , RMSE:1.1642 , RE:0.9908 , R2:-40.9535 , currentSum:0.0000\n",
      "seed: 1, 测试集: B0005, epoch:2    , loss:0.2671018541 , MAE:0.9376 , RMSE:0.9546 , RE:0.9908 , R2:-27.2082 , currentSum:30.0912\n",
      "seed: 1, 测试集: B0005, epoch:3    , loss:0.2004668117 , MAE:0.7497 , RMSE:0.7708 , RE:0.9908 , R2:-17.3934 , currentSum:19.9048\n",
      "seed: 1, 测试集: B0005, epoch:4    , loss:0.1295709312 , MAE:0.5800 , RMSE:0.6071 , RE:0.9908 , R2:-10.4077 , currentSum:12.5856\n",
      "seed: 1, 测试集: B0005, epoch:5    , loss:0.0850141793 , MAE:0.4230 , RMSE:0.4594 , RE:0.9908 , R2:-5.5338 , currentSum:7.4071\n",
      "seed: 1, 测试集: B0005, epoch:6    , loss:0.0554883406 , MAE:0.2813 , RMSE:0.3336 , RE:0.9908 , R2:-2.4454 , currentSum:4.0512\n",
      "seed: 1, 测试集: B0005, epoch:7    , loss:0.0327857099 , MAE:0.2248 , RMSE:0.2846 , RE:0.9908 , R2:-1.5068 , currentSum:3.0070\n",
      "seed: 1, 测试集: B0005, epoch:8    , loss:0.0158688519 , MAE:0.2199 , RMSE:0.2794 , RE:0.9908 , R2:-1.4163 , currentSum:2.9064\n",
      "seed: 1, 测试集: B0005, epoch:9    , loss:0.0228731167 , MAE:0.2158 , RMSE:0.2750 , RE:0.9908 , R2:-1.3406 , currentSum:2.8222\n",
      "seed: 1, 测试集: B0005, epoch:10   , loss:0.0236046650 , MAE:0.2122 , RMSE:0.2709 , RE:0.9908 , R2:-1.2725 , currentSum:2.7465\n",
      "seed: 1, 测试集: B0005, epoch:11   , loss:0.0227312502 , MAE:0.2089 , RMSE:0.2671 , RE:0.9908 , R2:-1.2082 , currentSum:2.6750\n",
      "seed: 1, 测试集: B0005, epoch:12   , loss:0.0184928365 , MAE:0.2056 , RMSE:0.2633 , RE:0.9908 , R2:-1.1457 , currentSum:2.6054\n",
      "seed: 1, 测试集: B0005, epoch:13   , loss:0.0207151789 , MAE:0.2025 , RMSE:0.2596 , RE:0.9908 , R2:-1.0855 , currentSum:2.5384\n",
      "seed: 1, 测试集: B0005, epoch:14   , loss:0.0225606449 , MAE:0.1995 , RMSE:0.2559 , RE:0.9908 , R2:-1.0264 , currentSum:2.4726\n",
      "seed: 1, 测试集: B0005, epoch:15   , loss:0.0220276359 , MAE:0.1966 , RMSE:0.2521 , RE:0.9908 , R2:-0.9681 , currentSum:2.4077\n",
      "seed: 1, 测试集: B0005, epoch:16   , loss:0.0177790262 , MAE:0.1938 , RMSE:0.2484 , RE:0.9908 , R2:-0.9108 , currentSum:2.3438\n",
      "seed: 1, 测试集: B0005, epoch:17   , loss:0.0157712512 , MAE:0.1912 , RMSE:0.2449 , RE:0.9908 , R2:-0.8560 , currentSum:2.2829\n",
      "seed: 1, 测试集: B0005, epoch:18   , loss:0.0219388623 , MAE:0.1887 , RMSE:0.2414 , RE:0.9908 , R2:-0.8032 , currentSum:2.2241\n",
      "seed: 1, 测试集: B0005, epoch:19   , loss:0.0134798475 , MAE:0.1863 , RMSE:0.2378 , RE:0.9908 , R2:-0.7510 , currentSum:2.1659\n",
      "seed: 1, 测试集: B0005, epoch:20   , loss:0.0191003662 , MAE:0.1840 , RMSE:0.2344 , RE:0.9908 , R2:-0.7014 , currentSum:2.1106\n",
      "seed: 1, 测试集: B0005, epoch:21   , loss:0.0168834440 , MAE:0.1818 , RMSE:0.2311 , RE:0.3945 , R2:-0.6533 , currentSum:1.4607\n",
      "seed: 1, 测试集: B0005, epoch:22   , loss:0.0179270320 , MAE:0.1797 , RMSE:0.2279 , RE:0.3945 , R2:-0.6076 , currentSum:1.4097\n",
      "seed: 1, 测试集: B0005, epoch:23   , loss:0.0120568862 , MAE:0.1776 , RMSE:0.2247 , RE:0.3945 , R2:-0.5632 , currentSum:1.3601\n",
      "seed: 1, 测试集: B0005, epoch:24   , loss:0.0156907234 , MAE:0.1758 , RMSE:0.2217 , RE:0.3945 , R2:-0.5213 , currentSum:1.3133\n",
      "seed: 1, 测试集: B0005, epoch:25   , loss:0.0163662527 , MAE:0.1741 , RMSE:0.2188 , RE:0.3945 , R2:-0.4819 , currentSum:1.2693\n",
      "seed: 1, 测试集: B0005, epoch:26   , loss:0.0141151315 , MAE:0.1725 , RMSE:0.2160 , RE:0.3945 , R2:-0.4438 , currentSum:1.2268\n",
      "seed: 1, 测试集: B0005, epoch:27   , loss:0.0126004070 , MAE:0.1710 , RMSE:0.2133 , RE:0.3945 , R2:-0.4084 , currentSum:1.1872\n",
      "seed: 1, 测试集: B0005, epoch:28   , loss:0.0123634711 , MAE:0.1696 , RMSE:0.2107 , RE:0.3945 , R2:-0.3743 , currentSum:1.1491\n",
      "seed: 1, 测试集: B0005, epoch:29   , loss:0.0146083301 , MAE:0.1684 , RMSE:0.2082 , RE:0.3945 , R2:-0.3421 , currentSum:1.1132\n",
      "seed: 1, 测试集: B0005, epoch:30   , loss:0.0098074162 , MAE:0.1673 , RMSE:0.2059 , RE:0.3945 , R2:-0.3122 , currentSum:1.0799\n",
      "seed: 1, 测试集: B0005, epoch:31   , loss:0.0142163839 , MAE:0.1662 , RMSE:0.2037 , RE:0.3945 , R2:-0.2841 , currentSum:1.0484\n",
      "seed: 1, 测试集: B0005, epoch:32   , loss:0.0118100727 , MAE:0.1652 , RMSE:0.2016 , RE:0.3945 , R2:-0.2576 , currentSum:1.0188\n",
      "seed: 1, 测试集: B0005, epoch:33   , loss:0.0091116289 , MAE:0.1643 , RMSE:0.1996 , RE:0.3945 , R2:-0.2328 , currentSum:0.9911\n",
      "seed: 1, 测试集: B0005, epoch:34   , loss:0.0142585412 , MAE:0.1636 , RMSE:0.1977 , RE:0.3945 , R2:-0.2104 , currentSum:0.9662\n",
      "seed: 1, 测试集: B0005, epoch:35   , loss:0.0110971099 , MAE:0.1628 , RMSE:0.1960 , RE:0.3945 , R2:-0.1889 , currentSum:0.9421\n",
      "seed: 1, 测试集: B0005, epoch:36   , loss:0.0086751208 , MAE:0.1620 , RMSE:0.1943 , RE:0.3945 , R2:-0.1690 , currentSum:0.9198\n",
      "seed: 1, 测试集: B0005, epoch:37   , loss:0.0118294777 , MAE:0.1613 , RMSE:0.1928 , RE:0.3945 , R2:-0.1509 , currentSum:0.8995\n",
      "seed: 1, 测试集: B0005, epoch:38   , loss:0.0098226387 , MAE:0.1607 , RMSE:0.1914 , RE:0.3945 , R2:-0.1341 , currentSum:0.8807\n",
      "seed: 1, 测试集: B0005, epoch:39   , loss:0.0126992641 , MAE:0.1602 , RMSE:0.1901 , RE:0.3945 , R2:-0.1186 , currentSum:0.8634\n",
      "seed: 1, 测试集: B0005, epoch:40   , loss:0.0101021212 , MAE:0.1597 , RMSE:0.1889 , RE:0.3945 , R2:-0.1045 , currentSum:0.8475\n",
      "seed: 1, 测试集: B0005, epoch:41   , loss:0.0109619200 , MAE:0.1593 , RMSE:0.1878 , RE:0.3945 , R2:-0.0917 , currentSum:0.8333\n",
      "seed: 1, 测试集: B0005, epoch:42   , loss:0.0099141980 , MAE:0.1590 , RMSE:0.1868 , RE:0.3945 , R2:-0.0800 , currentSum:0.8203\n",
      "seed: 1, 测试集: B0005, epoch:43   , loss:0.0113746133 , MAE:0.1587 , RMSE:0.1859 , RE:0.3945 , R2:-0.0696 , currentSum:0.8087\n",
      "seed: 1, 测试集: B0005, epoch:44   , loss:0.0083228713 , MAE:0.1584 , RMSE:0.1850 , RE:0.3945 , R2:-0.0597 , currentSum:0.7977\n",
      "seed: 1, 测试集: B0005, epoch:45   , loss:0.0097099626 , MAE:0.1582 , RMSE:0.1843 , RE:0.3945 , R2:-0.0512 , currentSum:0.7882\n",
      "seed: 1, 测试集: B0005, epoch:46   , loss:0.0082082655 , MAE:0.1580 , RMSE:0.1836 , RE:0.3945 , R2:-0.0433 , currentSum:0.7794\n",
      "seed: 1, 测试集: B0005, epoch:47   , loss:0.0085942578 , MAE:0.1579 , RMSE:0.1830 , RE:0.3945 , R2:-0.0365 , currentSum:0.7718\n",
      "seed: 1, 测试集: B0005, epoch:48   , loss:0.0101427026 , MAE:0.1577 , RMSE:0.1824 , RE:0.3945 , R2:-0.0302 , currentSum:0.7649\n",
      "seed: 1, 测试集: B0005, epoch:49   , loss:0.0097056646 , MAE:0.1576 , RMSE:0.1820 , RE:0.3945 , R2:-0.0249 , currentSum:0.7590\n",
      "seed: 1, 测试集: B0005, epoch:50   , loss:0.0115633057 , MAE:0.1576 , RMSE:0.1816 , RE:0.3945 , R2:-0.0205 , currentSum:0.7541\n",
      "seed: 1, 测试集: B0005, epoch:51   , loss:0.0102327652 , MAE:0.1576 , RMSE:0.1812 , RE:0.3945 , R2:-0.0162 , currentSum:0.7495\n",
      "seed: 1, 测试集: B0005, epoch:52   , loss:0.0080267210 , MAE:0.1576 , RMSE:0.1809 , RE:0.3945 , R2:-0.0126 , currentSum:0.7455\n",
      "seed: 1, 测试集: B0005, epoch:53   , loss:0.0116014769 , MAE:0.1576 , RMSE:0.1806 , RE:0.3945 , R2:-0.0098 , currentSum:0.7424\n",
      "seed: 1, 测试集: B0005, epoch:54   , loss:0.0103615494 , MAE:0.1577 , RMSE:0.1804 , RE:0.3945 , R2:-0.0072 , currentSum:0.7397\n",
      "seed: 1, 测试集: B0005, epoch:55   , loss:0.0089243781 , MAE:0.1578 , RMSE:0.1802 , RE:0.3945 , R2:-0.0051 , currentSum:0.7376\n",
      "seed: 1, 测试集: B0005, epoch:56   , loss:0.0092122098 , MAE:0.1579 , RMSE:0.1801 , RE:0.3945 , R2:-0.0035 , currentSum:0.7360\n",
      "seed: 1, 测试集: B0005, epoch:57   , loss:0.0068021757 , MAE:0.1580 , RMSE:0.1799 , RE:0.3945 , R2:-0.0021 , currentSum:0.7346\n",
      "seed: 1, 测试集: B0005, epoch:58   , loss:0.0081062224 , MAE:0.1581 , RMSE:0.1798 , RE:0.3945 , R2:-0.0012 , currentSum:0.7337\n",
      "seed: 1, 测试集: B0005, epoch:59   , loss:0.0090385145 , MAE:0.1583 , RMSE:0.1798 , RE:0.3945 , R2:-0.0006 , currentSum:0.7331\n",
      "seed: 1, 测试集: B0005, epoch:60   , loss:0.0085522942 , MAE:0.1584 , RMSE:0.1798 , RE:0.3945 , R2:-0.0002 , currentSum:0.7328\n",
      "seed: 1, 测试集: B0005, epoch:61   , loss:0.0082055032 , MAE:0.1585 , RMSE:0.1797 , RE:0.3945 , R2:-0.0000 , currentSum:0.7327\n",
      "以电池 B0006 为测试数据的 数据集 开始训练\n",
      "seed: 1, 测试集: B0006, epoch:1    , loss:1.7843679190 , MAE:2.6027 , RMSE:2.6120 , RE:0.9892 , R2:-138.9028 , currentSum:0.0000\n",
      "seed: 1, 测试集: B0006, epoch:2    , loss:1.7137186527 , MAE:2.5243 , RMSE:2.5339 , RE:0.9892 , R2:-130.6654 , currentSum:136.7129\n",
      "seed: 1, 测试集: B0006, epoch:3    , loss:1.6803524494 , MAE:2.5105 , RMSE:2.5202 , RE:0.9892 , R2:-129.2423 , currentSum:135.2622\n",
      "seed: 1, 测试集: B0006, epoch:4    , loss:1.6745331287 , MAE:2.4967 , RMSE:2.5065 , RE:0.9892 , R2:-127.8298 , currentSum:133.8223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1, 测试集: B0006, epoch:5    , loss:1.7000737190 , MAE:2.4830 , RMSE:2.4928 , RE:0.9892 , R2:-126.4256 , currentSum:132.3906\n",
      "seed: 1, 测试集: B0006, epoch:6    , loss:1.6630852222 , MAE:2.4692 , RMSE:2.4791 , RE:0.9892 , R2:-125.0304 , currentSum:130.9680\n",
      "seed: 1, 测试集: B0006, epoch:7    , loss:1.6389738321 , MAE:2.4555 , RMSE:2.4654 , RE:0.9892 , R2:-123.6448 , currentSum:129.5550\n",
      "seed: 1, 测试集: B0006, epoch:8    , loss:1.5961599350 , MAE:2.4418 , RMSE:2.4518 , RE:0.9892 , R2:-122.2689 , currentSum:128.1517\n",
      "seed: 1, 测试集: B0006, epoch:9    , loss:1.6258563995 , MAE:2.4282 , RMSE:2.4382 , RE:0.9892 , R2:-120.9036 , currentSum:126.7592\n",
      "seed: 1, 测试集: B0006, epoch:10   , loss:1.5673862696 , MAE:2.4145 , RMSE:2.4246 , RE:0.9892 , R2:-119.5471 , currentSum:125.3754\n",
      "seed: 1, 测试集: B0006, epoch:11   , loss:1.5706871748 , MAE:2.4009 , RMSE:2.4110 , RE:0.9892 , R2:-118.2031 , currentSum:124.0042\n",
      "seed: 1, 测试集: B0006, epoch:12   , loss:1.5652523041 , MAE:2.3873 , RMSE:2.3975 , RE:0.9892 , R2:-116.8692 , currentSum:122.6432\n",
      "seed: 1, 测试集: B0006, epoch:13   , loss:1.4677959681 , MAE:2.3737 , RMSE:2.3840 , RE:0.9892 , R2:-115.5438 , currentSum:121.2908\n",
      "seed: 1, 测试集: B0006, epoch:14   , loss:1.4868396521 , MAE:2.3602 , RMSE:2.3705 , RE:0.9892 , R2:-114.2306 , currentSum:119.9505\n",
      "seed: 1, 测试集: B0006, epoch:15   , loss:1.4592924118 , MAE:2.3467 , RMSE:2.3571 , RE:0.9892 , R2:-112.9278 , currentSum:118.6208\n",
      "seed: 1, 测试集: B0006, epoch:16   , loss:1.4723283052 , MAE:2.3332 , RMSE:2.3437 , RE:0.9892 , R2:-111.6360 , currentSum:117.3021\n",
      "seed: 1, 测试集: B0006, epoch:17   , loss:1.4584544897 , MAE:2.3198 , RMSE:2.3303 , RE:0.9892 , R2:-110.3553 , currentSum:115.9947\n",
      "seed: 1, 测试集: B0006, epoch:18   , loss:1.4573446512 , MAE:2.3064 , RMSE:2.3170 , RE:0.9892 , R2:-109.0846 , currentSum:114.6972\n",
      "seed: 1, 测试集: B0006, epoch:19   , loss:1.4056507349 , MAE:2.2931 , RMSE:2.3037 , RE:0.9892 , R2:-107.8247 , currentSum:113.4107\n",
      "seed: 1, 测试集: B0006, epoch:20   , loss:1.3539339304 , MAE:2.2797 , RMSE:2.2904 , RE:0.9892 , R2:-106.5739 , currentSum:112.1333\n",
      "seed: 1, 测试集: B0006, epoch:21   , loss:1.4529649019 , MAE:2.2665 , RMSE:2.2772 , RE:0.9892 , R2:-105.3368 , currentSum:110.8697\n",
      "seed: 1, 测试集: B0006, epoch:22   , loss:1.3676216602 , MAE:2.2532 , RMSE:2.2640 , RE:0.9892 , R2:-104.1084 , currentSum:109.6148\n",
      "seed: 1, 测试集: B0006, epoch:23   , loss:1.3791698217 , MAE:2.2400 , RMSE:2.2508 , RE:0.9892 , R2:-102.8908 , currentSum:108.3709\n",
      "seed: 1, 测试集: B0006, epoch:24   , loss:1.3352928162 , MAE:2.2268 , RMSE:2.2377 , RE:0.9892 , R2:-101.6829 , currentSum:107.1367\n",
      "seed: 1, 测试集: B0006, epoch:25   , loss:1.3225388527 , MAE:2.2136 , RMSE:2.2246 , RE:0.9892 , R2:-100.4858 , currentSum:105.9133\n",
      "seed: 1, 测试集: B0006, epoch:26   , loss:1.3161838055 , MAE:2.2005 , RMSE:2.2116 , RE:0.9892 , R2:-99.2994 , currentSum:104.7008\n",
      "seed: 1, 测试集: B0006, epoch:27   , loss:1.2881414890 , MAE:2.1875 , RMSE:2.1986 , RE:0.9892 , R2:-98.1226 , currentSum:103.4979\n",
      "seed: 1, 测试集: B0006, epoch:28   , loss:1.3118779659 , MAE:2.1744 , RMSE:2.1856 , RE:0.9892 , R2:-96.9570 , currentSum:102.3063\n",
      "seed: 1, 测试集: B0006, epoch:29   , loss:1.2852889299 , MAE:2.1614 , RMSE:2.1727 , RE:0.9892 , R2:-95.8010 , currentSum:101.1243\n",
      "seed: 1, 测试集: B0006, epoch:30   , loss:1.2236990929 , MAE:2.1485 , RMSE:2.1598 , RE:0.9892 , R2:-94.6546 , currentSum:99.9521\n",
      "seed: 1, 测试集: B0006, epoch:31   , loss:1.2332879305 , MAE:2.1355 , RMSE:2.1469 , RE:0.9892 , R2:-93.5197 , currentSum:98.7914\n",
      "seed: 1, 测试集: B0006, epoch:32   , loss:1.2128059864 , MAE:2.1227 , RMSE:2.1341 , RE:0.9892 , R2:-92.3942 , currentSum:97.6402\n",
      "seed: 1, 测试集: B0006, epoch:33   , loss:1.2289406061 , MAE:2.1098 , RMSE:2.1213 , RE:0.9892 , R2:-91.2789 , currentSum:96.4993\n",
      "seed: 1, 测试集: B0006, epoch:34   , loss:1.2290532589 , MAE:2.0970 , RMSE:2.1086 , RE:0.9892 , R2:-90.1744 , currentSum:95.3692\n",
      "seed: 1, 测试集: B0006, epoch:35   , loss:1.1847043037 , MAE:2.0842 , RMSE:2.0959 , RE:0.9892 , R2:-89.0783 , currentSum:94.2476\n",
      "seed: 1, 测试集: B0006, epoch:36   , loss:1.1704705954 , MAE:2.0715 , RMSE:2.0832 , RE:0.9892 , R2:-87.9921 , currentSum:93.1360\n",
      "seed: 1, 测试集: B0006, epoch:37   , loss:1.1406675577 , MAE:2.0587 , RMSE:2.0706 , RE:0.9892 , R2:-86.9149 , currentSum:92.0334\n",
      "seed: 1, 测试集: B0006, epoch:38   , loss:1.1420691013 , MAE:2.0461 , RMSE:2.0580 , RE:0.9892 , R2:-85.8491 , currentSum:90.9425\n",
      "seed: 1, 测试集: B0006, epoch:39   , loss:1.1494364738 , MAE:2.0335 , RMSE:2.0454 , RE:0.9892 , R2:-84.7929 , currentSum:89.8611\n",
      "seed: 1, 测试集: B0006, epoch:40   , loss:1.1155601740 , MAE:2.0209 , RMSE:2.0329 , RE:0.9892 , R2:-83.7464 , currentSum:88.7894\n",
      "seed: 1, 测试集: B0006, epoch:41   , loss:1.1122391224 , MAE:2.0083 , RMSE:2.0204 , RE:0.9892 , R2:-82.7091 , currentSum:87.7271\n",
      "seed: 1, 测试集: B0006, epoch:42   , loss:1.0999214649 , MAE:1.9958 , RMSE:2.0080 , RE:0.9892 , R2:-81.6818 , currentSum:86.6748\n",
      "seed: 1, 测试集: B0006, epoch:43   , loss:1.0688543320 , MAE:1.9833 , RMSE:1.9956 , RE:0.9892 , R2:-80.6628 , currentSum:85.6310\n",
      "seed: 1, 测试集: B0006, epoch:44   , loss:1.0675311089 , MAE:1.9709 , RMSE:1.9832 , RE:0.9892 , R2:-79.6541 , currentSum:84.5975\n",
      "seed: 1, 测试集: B0006, epoch:45   , loss:1.0748728514 , MAE:1.9585 , RMSE:1.9709 , RE:0.9892 , R2:-78.6551 , currentSum:83.5737\n",
      "seed: 1, 测试集: B0006, epoch:46   , loss:1.0518759489 , MAE:1.9461 , RMSE:1.9586 , RE:0.9892 , R2:-77.6648 , currentSum:82.5588\n",
      "seed: 1, 测试集: B0006, epoch:47   , loss:1.0389403105 , MAE:1.9338 , RMSE:1.9464 , RE:0.9892 , R2:-76.6843 , currentSum:81.5537\n",
      "seed: 1, 测试集: B0006, epoch:48   , loss:1.0567420721 , MAE:1.9215 , RMSE:1.9342 , RE:0.9892 , R2:-75.7134 , currentSum:80.5583\n",
      "seed: 1, 测试集: B0006, epoch:49   , loss:1.0162118673 , MAE:1.9093 , RMSE:1.9220 , RE:0.9892 , R2:-74.7507 , currentSum:79.5712\n",
      "seed: 1, 测试集: B0006, epoch:50   , loss:1.0036518574 , MAE:1.8970 , RMSE:1.9098 , RE:0.9892 , R2:-73.7966 , currentSum:78.5927\n",
      "seed: 1, 测试集: B0006, epoch:51   , loss:0.9683567286 , MAE:1.8848 , RMSE:1.8977 , RE:0.9892 , R2:-72.8516 , currentSum:77.6235\n",
      "seed: 1, 测试集: B0006, epoch:52   , loss:0.9958135486 , MAE:1.8727 , RMSE:1.8857 , RE:0.9892 , R2:-71.9170 , currentSum:76.6647\n",
      "seed: 1, 测试集: B0006, epoch:53   , loss:0.9407824874 , MAE:1.8606 , RMSE:1.8737 , RE:0.9892 , R2:-70.9901 , currentSum:75.7136\n",
      "seed: 1, 测试集: B0006, epoch:54   , loss:0.9881330132 , MAE:1.8486 , RMSE:1.8617 , RE:0.9892 , R2:-70.0741 , currentSum:74.7736\n",
      "seed: 1, 测试集: B0006, epoch:55   , loss:0.9098371267 , MAE:1.8365 , RMSE:1.8498 , RE:0.9892 , R2:-69.1642 , currentSum:73.8397\n",
      "seed: 1, 测试集: B0006, epoch:56   , loss:0.9237838984 , MAE:1.8245 , RMSE:1.8379 , RE:0.9892 , R2:-68.2647 , currentSum:72.9164\n",
      "seed: 1, 测试集: B0006, epoch:57   , loss:0.8889645338 , MAE:1.8126 , RMSE:1.8260 , RE:0.9892 , R2:-67.3731 , currentSum:72.0010\n",
      "seed: 1, 测试集: B0006, epoch:58   , loss:0.9194880724 , MAE:1.8007 , RMSE:1.8142 , RE:0.9892 , R2:-66.4908 , currentSum:71.0949\n",
      "seed: 1, 测试集: B0006, epoch:59   , loss:0.9065873027 , MAE:1.7888 , RMSE:1.8024 , RE:0.9892 , R2:-65.6172 , currentSum:70.1977\n",
      "seed: 1, 测试集: B0006, epoch:60   , loss:0.8839173913 , MAE:1.7770 , RMSE:1.7906 , RE:0.9892 , R2:-64.7514 , currentSum:69.3082\n",
      "seed: 1, 测试集: B0006, epoch:61   , loss:0.8555501699 , MAE:1.7652 , RMSE:1.7789 , RE:0.9892 , R2:-63.8948 , currentSum:68.4282\n",
      "seed: 1, 测试集: B0006, epoch:62   , loss:0.8522871733 , MAE:1.7534 , RMSE:1.7673 , RE:0.9892 , R2:-63.0470 , currentSum:67.5570\n",
      "seed: 1, 测试集: B0006, epoch:63   , loss:0.8553502560 , MAE:1.7417 , RMSE:1.7557 , RE:0.9892 , R2:-62.2075 , currentSum:66.6941\n",
      "seed: 1, 测试集: B0006, epoch:64   , loss:0.8342958689 , MAE:1.7300 , RMSE:1.7441 , RE:0.9892 , R2:-61.3760 , currentSum:65.8393\n",
      "seed: 1, 测试集: B0006, epoch:65   , loss:0.8365073204 , MAE:1.7184 , RMSE:1.7325 , RE:0.9892 , R2:-60.5525 , currentSum:64.9926\n",
      "seed: 1, 测试集: B0006, epoch:66   , loss:0.7883045673 , MAE:1.7068 , RMSE:1.7210 , RE:0.9892 , R2:-59.7367 , currentSum:64.1537\n",
      "seed: 1, 测试集: B0006, epoch:67   , loss:0.7932587266 , MAE:1.6952 , RMSE:1.7095 , RE:0.9892 , R2:-58.9294 , currentSum:63.3234\n",
      "seed: 1, 测试集: B0006, epoch:68   , loss:0.7756355405 , MAE:1.6837 , RMSE:1.6981 , RE:0.9892 , R2:-58.1312 , currentSum:62.5022\n",
      "seed: 1, 测试集: B0006, epoch:69   , loss:0.7817537189 , MAE:1.6722 , RMSE:1.6867 , RE:0.9892 , R2:-57.3410 , currentSum:61.6891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1, 测试集: B0006, epoch:70   , loss:0.7636687160 , MAE:1.6608 , RMSE:1.6754 , RE:0.9892 , R2:-56.5585 , currentSum:60.8839\n",
      "seed: 1, 测试集: B0006, epoch:71   , loss:0.7784452438 , MAE:1.6494 , RMSE:1.6641 , RE:0.9892 , R2:-55.7848 , currentSum:60.0874\n",
      "seed: 1, 测试集: B0006, epoch:72   , loss:0.7534365654 , MAE:1.6380 , RMSE:1.6528 , RE:0.9892 , R2:-55.0181 , currentSum:59.2981\n",
      "seed: 1, 测试集: B0006, epoch:73   , loss:0.7507492900 , MAE:1.6267 , RMSE:1.6416 , RE:0.9892 , R2:-54.2601 , currentSum:58.5176\n",
      "seed: 1, 测试集: B0006, epoch:74   , loss:0.7186045051 , MAE:1.6154 , RMSE:1.6304 , RE:0.9892 , R2:-53.5094 , currentSum:57.7444\n",
      "seed: 1, 测试集: B0006, epoch:75   , loss:0.7157324553 , MAE:1.6041 , RMSE:1.6192 , RE:0.9892 , R2:-52.7660 , currentSum:56.9786\n",
      "seed: 1, 测试集: B0006, epoch:76   , loss:0.7310177088 , MAE:1.5929 , RMSE:1.6081 , RE:0.9892 , R2:-52.0311 , currentSum:56.2214\n",
      "seed: 1, 测试集: B0006, epoch:77   , loss:0.6885945797 , MAE:1.5817 , RMSE:1.5971 , RE:0.9892 , R2:-51.3028 , currentSum:55.4708\n",
      "seed: 1, 测试集: B0006, epoch:78   , loss:0.6802784204 , MAE:1.5706 , RMSE:1.5860 , RE:0.9892 , R2:-50.5825 , currentSum:54.7284\n",
      "seed: 1, 测试集: B0006, epoch:79   , loss:0.6785054207 , MAE:1.5595 , RMSE:1.5750 , RE:0.9892 , R2:-49.8699 , currentSum:53.9937\n",
      "seed: 1, 测试集: B0006, epoch:80   , loss:0.6698511839 , MAE:1.5484 , RMSE:1.5641 , RE:0.9892 , R2:-49.1654 , currentSum:53.2671\n",
      "seed: 1, 测试集: B0006, epoch:81   , loss:0.6666762829 , MAE:1.5374 , RMSE:1.5532 , RE:0.9892 , R2:-48.4683 , currentSum:52.5481\n",
      "seed: 1, 测试集: B0006, epoch:82   , loss:0.6563059092 , MAE:1.5264 , RMSE:1.5423 , RE:0.9892 , R2:-47.7782 , currentSum:51.8362\n",
      "seed: 1, 测试集: B0006, epoch:83   , loss:0.6442531943 , MAE:1.5155 , RMSE:1.5315 , RE:0.9892 , R2:-47.0955 , currentSum:51.1316\n",
      "seed: 1, 测试集: B0006, epoch:84   , loss:0.6172816157 , MAE:1.5046 , RMSE:1.5207 , RE:0.9892 , R2:-46.4204 , currentSum:50.4349\n",
      "seed: 1, 测试集: B0006, epoch:85   , loss:0.6494947076 , MAE:1.4937 , RMSE:1.5100 , RE:0.9892 , R2:-45.7534 , currentSum:49.7463\n",
      "seed: 1, 测试集: B0006, epoch:86   , loss:0.6358607411 , MAE:1.4829 , RMSE:1.4992 , RE:0.9892 , R2:-45.0923 , currentSum:49.0637\n",
      "seed: 1, 测试集: B0006, epoch:87   , loss:0.6382597089 , MAE:1.4721 , RMSE:1.4886 , RE:0.9892 , R2:-44.4391 , currentSum:48.3891\n",
      "seed: 1, 测试集: B0006, epoch:88   , loss:0.6084338427 , MAE:1.4614 , RMSE:1.4779 , RE:0.9892 , R2:-43.7921 , currentSum:47.7207\n",
      "seed: 1, 测试集: B0006, epoch:89   , loss:0.6288793087 , MAE:1.4507 , RMSE:1.4674 , RE:0.9892 , R2:-43.1535 , currentSum:47.0608\n",
      "seed: 1, 测试集: B0006, epoch:90   , loss:0.6008369923 , MAE:1.4400 , RMSE:1.4568 , RE:0.9892 , R2:-42.5213 , currentSum:46.4074\n",
      "seed: 1, 测试集: B0006, epoch:91   , loss:0.5872978568 , MAE:1.4294 , RMSE:1.4463 , RE:0.9892 , R2:-41.8953 , currentSum:45.7602\n",
      "seed: 1, 测试集: B0006, epoch:92   , loss:0.5664914846 , MAE:1.4188 , RMSE:1.4358 , RE:0.9892 , R2:-41.2771 , currentSum:45.1210\n",
      "seed: 1, 测试集: B0006, epoch:93   , loss:0.5439149141 , MAE:1.4082 , RMSE:1.4254 , RE:0.9892 , R2:-40.6654 , currentSum:44.4883\n",
      "seed: 1, 测试集: B0006, epoch:94   , loss:0.5622127652 , MAE:1.3977 , RMSE:1.4150 , RE:0.9892 , R2:-40.0606 , currentSum:43.8626\n",
      "seed: 1, 测试集: B0006, epoch:95   , loss:0.5911179185 , MAE:1.3873 , RMSE:1.4047 , RE:0.9892 , R2:-39.4642 , currentSum:43.2454\n",
      "seed: 1, 测试集: B0006, epoch:96   , loss:0.5238742232 , MAE:1.3768 , RMSE:1.3944 , RE:0.9892 , R2:-38.8718 , currentSum:42.6323\n",
      "seed: 1, 测试集: B0006, epoch:97   , loss:0.5407528877 , MAE:1.3664 , RMSE:1.3842 , RE:0.9892 , R2:-38.2880 , currentSum:42.0278\n",
      "seed: 1, 测试集: B0006, epoch:98   , loss:0.5420435667 , MAE:1.3561 , RMSE:1.3739 , RE:0.9892 , R2:-37.7095 , currentSum:41.4288\n",
      "seed: 1, 测试集: B0006, epoch:99   , loss:0.5103106499 , MAE:1.3458 , RMSE:1.3638 , RE:0.9892 , R2:-37.1383 , currentSum:40.8370\n",
      "seed: 1, 测试集: B0006, epoch:100  , loss:0.5429350734 , MAE:1.3355 , RMSE:1.3536 , RE:0.9892 , R2:-36.5740 , currentSum:40.2524\n",
      "seed: 1, 测试集: B0006, epoch:101  , loss:0.5097173452 , MAE:1.3253 , RMSE:1.3435 , RE:0.9892 , R2:-36.0157 , currentSum:39.6737\n",
      "seed: 1, 测试集: B0006, epoch:102  , loss:0.4761909246 , MAE:1.3151 , RMSE:1.3335 , RE:0.9892 , R2:-35.4629 , currentSum:39.1007\n",
      "seed: 1, 测试集: B0006, epoch:103  , loss:0.4932906926 , MAE:1.3049 , RMSE:1.3235 , RE:0.9892 , R2:-34.9174 , currentSum:38.5350\n",
      "seed: 1, 测试集: B0006, epoch:104  , loss:0.4763658047 , MAE:1.2948 , RMSE:1.3135 , RE:0.9892 , R2:-34.3781 , currentSum:37.9756\n",
      "seed: 1, 测试集: B0006, epoch:105  , loss:0.4785778224 , MAE:1.2847 , RMSE:1.3035 , RE:0.9892 , R2:-33.8448 , currentSum:37.4223\n",
      "seed: 1, 测试集: B0006, epoch:106  , loss:0.4761443734 , MAE:1.2747 , RMSE:1.2937 , RE:0.9892 , R2:-33.3186 , currentSum:36.8761\n",
      "seed: 1, 测试集: B0006, epoch:107  , loss:0.4825497866 , MAE:1.2647 , RMSE:1.2838 , RE:0.9892 , R2:-32.7985 , currentSum:36.3362\n",
      "seed: 1, 测试集: B0006, epoch:108  , loss:0.4753065407 , MAE:1.2547 , RMSE:1.2740 , RE:0.9892 , R2:-32.2847 , currentSum:35.8027\n",
      "seed: 1, 测试集: B0006, epoch:109  , loss:0.4440706372 , MAE:1.2448 , RMSE:1.2643 , RE:0.9892 , R2:-31.7766 , currentSum:35.2749\n",
      "seed: 1, 测试集: B0006, epoch:110  , loss:0.4455654919 , MAE:1.2350 , RMSE:1.2545 , RE:0.9892 , R2:-31.2743 , currentSum:34.7530\n",
      "seed: 1, 测试集: B0006, epoch:111  , loss:0.4530873895 , MAE:1.2251 , RMSE:1.2449 , RE:0.9892 , R2:-30.7779 , currentSum:34.2371\n",
      "seed: 1, 测试集: B0006, epoch:112  , loss:0.4231562614 , MAE:1.2153 , RMSE:1.2352 , RE:0.9892 , R2:-30.2876 , currentSum:33.7274\n",
      "seed: 1, 测试集: B0006, epoch:113  , loss:0.4213113487 , MAE:1.2055 , RMSE:1.2256 , RE:0.9892 , R2:-29.8028 , currentSum:33.2232\n",
      "seed: 1, 测试集: B0006, epoch:114  , loss:0.4179641902 , MAE:1.1958 , RMSE:1.2161 , RE:0.9892 , R2:-29.3247 , currentSum:32.7259\n",
      "seed: 1, 测试集: B0006, epoch:115  , loss:0.4144681096 , MAE:1.1862 , RMSE:1.2066 , RE:0.9892 , R2:-28.8526 , currentSum:32.2346\n",
      "seed: 1, 测试集: B0006, epoch:116  , loss:0.4266917109 , MAE:1.1766 , RMSE:1.1971 , RE:0.9892 , R2:-28.3865 , currentSum:31.7494\n",
      "seed: 1, 测试集: B0006, epoch:117  , loss:0.4138269126 , MAE:1.1670 , RMSE:1.1877 , RE:0.9892 , R2:-27.9260 , currentSum:31.2699\n",
      "seed: 1, 测试集: B0006, epoch:118  , loss:0.4089698493 , MAE:1.1574 , RMSE:1.1783 , RE:0.9892 , R2:-27.4701 , currentSum:30.7950\n",
      "seed: 1, 测试集: B0006, epoch:119  , loss:0.4143181741 , MAE:1.1479 , RMSE:1.1690 , RE:0.9892 , R2:-27.0209 , currentSum:30.3270\n",
      "seed: 1, 测试集: B0006, epoch:120  , loss:0.3743685782 , MAE:1.1384 , RMSE:1.1596 , RE:0.9892 , R2:-26.5755 , currentSum:29.8628\n",
      "seed: 1, 测试集: B0006, epoch:121  , loss:0.3811555505 , MAE:1.1290 , RMSE:1.1504 , RE:0.9892 , R2:-26.1370 , currentSum:29.4055\n",
      "seed: 1, 测试集: B0006, epoch:122  , loss:0.3768073320 , MAE:1.1196 , RMSE:1.1412 , RE:0.9892 , R2:-25.7040 , currentSum:28.9540\n",
      "seed: 1, 测试集: B0006, epoch:123  , loss:0.3937921226 , MAE:1.1102 , RMSE:1.1320 , RE:0.9892 , R2:-25.2770 , currentSum:28.5085\n",
      "seed: 1, 测试集: B0006, epoch:124  , loss:0.3340431452 , MAE:1.1009 , RMSE:1.1228 , RE:0.9892 , R2:-24.8534 , currentSum:28.0663\n",
      "seed: 1, 测试集: B0006, epoch:125  , loss:0.3672963381 , MAE:1.0916 , RMSE:1.1137 , RE:0.9892 , R2:-24.4367 , currentSum:27.6314\n",
      "seed: 1, 测试集: B0006, epoch:126  , loss:0.3596697152 , MAE:1.0824 , RMSE:1.1047 , RE:0.9892 , R2:-24.0254 , currentSum:27.2018\n",
      "seed: 1, 测试集: B0006, epoch:127  , loss:0.3353909254 , MAE:1.0732 , RMSE:1.0957 , RE:0.9892 , R2:-23.6187 , currentSum:26.7768\n",
      "seed: 1, 测试集: B0006, epoch:128  , loss:0.3429339230 , MAE:1.0641 , RMSE:1.0867 , RE:0.9892 , R2:-23.2180 , currentSum:26.3581\n",
      "seed: 1, 测试集: B0006, epoch:129  , loss:0.3301742375 , MAE:1.0549 , RMSE:1.0778 , RE:0.9892 , R2:-22.8219 , currentSum:25.9439\n",
      "seed: 1, 测试集: B0006, epoch:130  , loss:0.3123616576 , MAE:1.0459 , RMSE:1.0689 , RE:0.9892 , R2:-22.4314 , currentSum:25.5355\n",
      "seed: 1, 测试集: B0006, epoch:131  , loss:0.3141445220 , MAE:1.0369 , RMSE:1.0601 , RE:0.9892 , R2:-22.0459 , currentSum:25.1321\n",
      "seed: 1, 测试集: B0006, epoch:132  , loss:0.3168796003 , MAE:1.0279 , RMSE:1.0513 , RE:0.9892 , R2:-21.6656 , currentSum:24.7341\n",
      "seed: 1, 测试集: B0006, epoch:133  , loss:0.3197627366 , MAE:1.0189 , RMSE:1.0426 , RE:0.9892 , R2:-21.2900 , currentSum:24.3408\n",
      "seed: 1, 测试集: B0006, epoch:134  , loss:0.3065240085 , MAE:1.0100 , RMSE:1.0339 , RE:0.9892 , R2:-20.9195 , currentSum:23.9527\n",
      "seed: 1, 测试集: B0006, epoch:135  , loss:0.2902833521 , MAE:1.0012 , RMSE:1.0252 , RE:0.9892 , R2:-20.5540 , currentSum:23.5696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1, 测试集: B0006, epoch:136  , loss:0.3064168692 , MAE:0.9923 , RMSE:1.0166 , RE:0.9892 , R2:-20.1934 , currentSum:23.1916\n",
      "seed: 1, 测试集: B0006, epoch:137  , loss:0.2992795408 , MAE:0.9835 , RMSE:1.0080 , RE:0.9892 , R2:-19.8369 , currentSum:22.8177\n",
      "seed: 1, 测试集: B0006, epoch:138  , loss:0.2973685563 , MAE:0.9748 , RMSE:0.9995 , RE:0.9892 , R2:-19.4864 , currentSum:22.4500\n",
      "seed: 1, 测试集: B0006, epoch:139  , loss:0.2890983224 , MAE:0.9661 , RMSE:0.9910 , RE:0.9892 , R2:-19.1392 , currentSum:22.0856\n",
      "seed: 1, 测试集: B0006, epoch:140  , loss:0.2879835367 , MAE:0.9574 , RMSE:0.9826 , RE:0.9892 , R2:-18.7983 , currentSum:21.7276\n",
      "seed: 1, 测试集: B0006, epoch:141  , loss:0.2679902911 , MAE:0.9488 , RMSE:0.9742 , RE:0.9892 , R2:-18.4606 , currentSum:21.3728\n",
      "seed: 1, 测试集: B0006, epoch:142  , loss:0.2700072229 , MAE:0.9402 , RMSE:0.9658 , RE:0.9892 , R2:-18.1278 , currentSum:21.0231\n",
      "seed: 1, 测试集: B0006, epoch:143  , loss:0.2685838342 , MAE:0.9317 , RMSE:0.9575 , RE:0.9892 , R2:-17.8002 , currentSum:20.6786\n",
      "seed: 1, 测试集: B0006, epoch:144  , loss:0.2590157986 , MAE:0.9232 , RMSE:0.9492 , RE:0.9892 , R2:-17.4769 , currentSum:20.3386\n",
      "seed: 1, 测试集: B0006, epoch:145  , loss:0.2477099597 , MAE:0.9147 , RMSE:0.9410 , RE:0.9892 , R2:-17.1582 , currentSum:20.0031\n",
      "seed: 1, 测试集: B0006, epoch:146  , loss:0.2524851263 , MAE:0.9063 , RMSE:0.9328 , RE:0.9892 , R2:-16.8432 , currentSum:19.6715\n",
      "seed: 1, 测试集: B0006, epoch:147  , loss:0.2475061119 , MAE:0.8979 , RMSE:0.9247 , RE:0.9892 , R2:-16.5334 , currentSum:19.3452\n",
      "seed: 1, 测试集: B0006, epoch:148  , loss:0.2322045416 , MAE:0.8896 , RMSE:0.9166 , RE:0.9892 , R2:-16.2278 , currentSum:19.0232\n",
      "seed: 1, 测试集: B0006, epoch:149  , loss:0.2285203189 , MAE:0.8813 , RMSE:0.9085 , RE:0.9892 , R2:-15.9267 , currentSum:18.7058\n",
      "seed: 1, 测试集: B0006, epoch:150  , loss:0.2176144123 , MAE:0.8730 , RMSE:0.9005 , RE:0.9892 , R2:-15.6292 , currentSum:18.3920\n",
      "seed: 1, 测试集: B0006, epoch:151  , loss:0.2375586927 , MAE:0.8648 , RMSE:0.8926 , RE:0.9892 , R2:-15.3370 , currentSum:18.0836\n",
      "seed: 1, 测试集: B0006, epoch:152  , loss:0.2377990633 , MAE:0.8566 , RMSE:0.8847 , RE:0.9892 , R2:-15.0484 , currentSum:17.7789\n",
      "seed: 1, 测试集: B0006, epoch:153  , loss:0.2385426015 , MAE:0.8485 , RMSE:0.8768 , RE:0.9892 , R2:-14.7642 , currentSum:17.4788\n",
      "seed: 1, 测试集: B0006, epoch:154  , loss:0.2189694494 , MAE:0.8404 , RMSE:0.8690 , RE:0.9892 , R2:-14.4839 , currentSum:17.1825\n",
      "seed: 1, 测试集: B0006, epoch:155  , loss:0.2062122077 , MAE:0.8324 , RMSE:0.8612 , RE:0.9892 , R2:-14.2071 , currentSum:16.8898\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m以电池 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mBattery_list[i]\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 为测试数据的 数据集 开始训练\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m#train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity)\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m mae, rmse, re, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRated_Capacity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m mae_s\u001b[38;5;241m.\u001b[39mappend(mae)\n\u001b[0;32m     83\u001b[0m rmse_s\u001b[38;5;241m.\u001b[39mappend(rmse)\n",
      "Cell \u001b[1;32mIn[55], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\u001b[0m\n\u001b[0;32m      9\u001b[0m pre_list \u001b[38;5;241m=\u001b[39m predict(net, train_data, test_data, Rated_Capacity)\n\u001b[0;32m     10\u001b[0m test_y \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 12\u001b[0m mae, rmse, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m re \u001b[38;5;241m=\u001b[39m relative_error(test_y, pre_list, threshold\u001b[38;5;241m=\u001b[39mRated_Capacity \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m     14\u001b[0m currentSum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mevaluation\u001b[1;34m(y_test, y_predict)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation\u001b[39m(y_test, y_predict):\n\u001b[1;32m----> 3\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_predict)\n\u001b[0;32m      5\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m sqrt(mean_squared_error(y_test, y_predict))\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\_regression.py:204\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    141\u001b[0m     {\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m ):\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    208\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    100\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    104\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\programs\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "def train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed):\n",
    "    net = net.to(device)\n",
    "    \n",
    "    mae_epoch_list, rmse_epoch_list, re_epoch_list, r2_epoch_list = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(net, train_iter, loss, updater, window_size, Rated_Capacity)\n",
    "        \n",
    "        # if (epoch + 1) % 100 == 0:\n",
    "        pre_list = predict(net, train_data, test_data, Rated_Capacity)\n",
    "        test_y = test_data.copy()\n",
    "\n",
    "        mae, rmse, r2 = evaluation(test_data, pre_list)\n",
    "        re = relative_error(test_y, pre_list, threshold=Rated_Capacity * 0.7)\n",
    "        currentSum = 0\n",
    "        lastSum = 0\n",
    "        \n",
    "        if (len(re_epoch_list) > 0):\n",
    "            currentSum = re + mae + rmse - r2\n",
    "            lastSum = re_epoch_list[-1] + mae_epoch_list[-1] + rmse_epoch_list[-1] - r2_epoch_list[-1]\n",
    "\n",
    "        if (len(re_epoch_list) == 0 or (currentSum < lastSum)):\n",
    "            print('seed: {}, 测试集: {}, epoch:{:<4d} , loss:{:<6.10f} , MAE:{:<6.4f} , RMSE:{:<6.4f} , RE:{:<6.4f} , R2:{:<6.4f} , currentSum:{:<6.4f}'.format(seed, Battery_list[i], epoch + 1, train_loss, mae, rmse, re, r2, currentSum))\n",
    "            mae_epoch_list.append(mae)\n",
    "            rmse_epoch_list.append(rmse)\n",
    "            re_epoch_list.append(re)\n",
    "            r2_epoch_list.append(r2)\n",
    "\n",
    "\n",
    "        # matlab_make(pre_list, test_y)\n",
    "\n",
    "        # if (train_loss < 1e-3) and len(re_epoch_list) > 0 and 0.0 < re_epoch_list[-1] < 0.2 and (re_epoch_list[-1] < re):\n",
    "        #     break\n",
    "\n",
    "    return mae_epoch_list[-1], rmse_epoch_list[-1], re_epoch_list[-1], r2_epoch_list[-1]\n",
    "\n",
    "\n",
    "# 电池额定容量\n",
    "Rated_Capacity = 2.0\n",
    "\n",
    "# 超参数\n",
    "d_model = 16\n",
    "nhead = 4\n",
    "num_encoder_layers = 2\n",
    "dim_feedforward = 32\n",
    "num_channels = [1]\n",
    "kernel_size = 2\n",
    "\n",
    "batch_size = 60\n",
    "lr = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 500\n",
    "window_size = 16\n",
    "\n",
    "# 获取数据集，生成train_iter\n",
    "# 使用留一评估\n",
    "re_seed_all, mae_seed_all, rmse_seed_all, r2_seed_all = [], [], [], []\n",
    "for seed in range(1, 10):\n",
    "    print('*******************************************************************************************************************')\n",
    "    print('当前的 seed 为', seed)\n",
    "    setup_seed(seed)\n",
    "    mae_s, rmse_s, re_s, r2_s = [], [], [], []\n",
    "    for i in range(4):\n",
    "    # for i in range(1):\n",
    "        train_x, train_y, train_data, test_data = get_train_test_data(Battery_data_list, i, window_size=window_size)\n",
    "        train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "        train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "        train_iter = load_capacity_data((train_x, train_y), batch_size, is_train=True)\n",
    "\n",
    "        # 模型、损失函数、优化器\n",
    "        net = Net(d_model=d_model, nhead=nhead,\n",
    "                  num_encoder_layers=num_encoder_layers, \n",
    "                  dim_feedforward=dim_feedforward,\n",
    "                  num_channels=num_channels,\n",
    "                  kernel_size=kernel_size)\n",
    "        loss = nn.MSELoss()\n",
    "        updater = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # 开始训练\n",
    "        print(f'以电池 { Battery_list[i] } 为测试数据的 数据集 开始训练')\n",
    "        #train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity)\n",
    "        mae, rmse, re, r2 = train(net, train_iter, train_data, test_data, batch_size, loss, num_epochs, updater, window_size, Rated_Capacity, i, seed)\n",
    "        mae_s.append(mae)\n",
    "        rmse_s.append(rmse)\n",
    "        re_s.append(re)\n",
    "        r2_s.append(r2)\n",
    "\n",
    "    print('---------------------------------')\n",
    "    print('re_s', re_s)\n",
    "    print('---------------------------------')\n",
    "    print(f're mean: {np.array(re_s).mean()}')\n",
    "    print(f'mae mean: {np.array(mae_s).mean()}')\n",
    "    print(f'rmse mean: {np.array(rmse_s).mean()}')\n",
    "    print(f'r2 mean: {np.array(r2_s).mean()}')\n",
    "    print('---------------------------------')\n",
    "    \n",
    "    re_seed_all.append(np.array(re_s).mean())\n",
    "    mae_seed_all.append(np.array(mae_s).mean())\n",
    "    rmse_seed_all.append(np.array(rmse_s).mean())\n",
    "    r2_seed_all.append(np.array(r2_s).mean())\n",
    "\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "print('------------   平均值   ---------------------')\n",
    "print(f're mean: {np.array(re_seed_all).mean()}')\n",
    "print(f'mae mean: {np.array(mae_seed_all).mean()}')\n",
    "print(f'rmse mean: {np.array(rmse_seed_all).mean()}')\n",
    "print(f'r2 mean: {np.array(r2_seed_all).mean()}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "print('------------   最小值   ---------------------')\n",
    "print(f're min: {np.array(re_seed_all).min()}')\n",
    "print(f'mae min: {np.array(mae_seed_all).min()}')\n",
    "print(f'rmse min: {np.array(rmse_seed_all).min()}')\n",
    "print(f'r2 max: {np.array(r2_seed_all).max()}')\n",
    "print('---------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
