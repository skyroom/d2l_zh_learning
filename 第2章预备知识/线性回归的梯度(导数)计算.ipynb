{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3cca2b",
   "metadata": {},
   "source": [
    "## 定义X,w,b,y_hat\n",
    "X 表示数据集的特征矩阵\n",
    "\n",
    "w 表示权重\n",
    "\n",
    "b 表示偏置\n",
    "\n",
    "y_hat 表示预测的y值\n",
    "\n",
    "**目的是计算w对于损失函数loss的导数，这里的loss采用平方误差**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57458682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9bb6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.,1.], [2.,3.], [4.,5.]]).reshape(3, 2)\n",
    "# w = torch.tensor([2, -3.4]).reshape(2, 1)\n",
    "w = torch.tensor([0., 0.]).reshape(2, 1)\n",
    "w.requires_grad_(True)\n",
    "b = torch.tensor(4.2, requires_grad=True)\n",
    "y_hat = torch.tensor([0., 1., 2.]).reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0dca447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2000],\n",
       "        [4.2000],\n",
       "        [4.2000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算y值\n",
    "y = torch.matmul(X, w) + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ae8ba",
   "metadata": {},
   "source": [
    "## 计算损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0831ee9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.8200],\n",
      "        [5.1200],\n",
      "        [2.4200]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = 0.5 * ((y_hat - y) ** 2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a90d84",
   "metadata": {},
   "source": [
    "## 调用torch内置的backward函数，计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b74910f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15.2000],\n",
      "        [24.8000]])\n"
     ]
    }
   ],
   "source": [
    "loss.sum().backward(retain_graph=True)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1333ac",
   "metadata": {},
   "source": [
    "## 用手动计算的公式求得梯度，其中X@w的导数为X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033b0d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  4.2000],\n",
      "        [ 6.4000,  9.6000],\n",
      "        [ 8.8000, 11.0000]], grad_fn=<MulBackward0>)\n",
      "tensor([[15.2000, 24.8000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss_d = (y_hat - X@w - b) * X * (-1)\n",
    "print(loss_d)\n",
    "print(loss_d.sum(0, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142b251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15.2000, 24.8000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss_d = (y_hat - b) * X * (-1)\n",
    "print(loss_d.sum(0, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c7b3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7\n",
      "4.43\n",
      "4.186999999999999\n",
      "3.9682999999999993\n",
      "3.7714699999999994\n",
      "3.5943229999999993\n",
      "3.4348906999999995\n",
      "3.2914016299999997\n",
      "3.1622614669999995\n",
      "3.0460353202999997\n",
      "2.9414317882699996\n",
      "2.847288609443\n",
      "2.7625597484987\n",
      "2.68630377364883\n",
      "2.617673396283947\n",
      "2.555906056655552\n",
      "2.500315450989997\n",
      "2.450283905890997\n",
      "2.4052555153018975\n",
      "2.364729963771708\n",
      "2.328256967394537\n",
      "2.2954312706550835\n",
      "2.2658881435895752\n",
      "2.239299329230618\n",
      "2.215369396307556\n",
      "2.1938324566768004\n",
      "2.1744492110091205\n",
      "2.1570042899082082\n",
      "2.1413038609173873\n",
      "2.1271734748256486\n",
      "2.1144561273430837\n",
      "2.1030105146087754\n",
      "2.092709463147898\n",
      "2.083438516833108\n",
      "2.075094665149797\n",
      "2.0675851986348173\n",
      "2.0608266787713356\n",
      "2.054744010894202\n",
      "2.0492696098047816\n",
      "2.0443426488243035\n",
      "2.039908383941873\n",
      "2.0359175455476857\n",
      "2.032325790992917\n",
      "2.0290932118936253\n",
      "2.026183890704263\n",
      "2.0235655016338367\n",
      "2.021208951470453\n",
      "2.0190880563234077\n",
      "2.017179250691067\n",
      "2.0154613256219602\n",
      "2.013915193059764\n",
      "2.0125236737537877\n",
      "2.011271306378409\n",
      "2.0101441757405683\n",
      "2.0091297581665115\n",
      "2.0082167823498605\n",
      "2.0073951041148743\n",
      "2.0066555937033868\n",
      "2.005990034333048\n",
      "2.005391030899743\n",
      "2.004851927809769\n",
      "2.004366735028792\n",
      "2.003930061525913\n",
      "2.0035370553733216\n",
      "2.0031833498359894\n",
      "2.0028650148523903\n",
      "2.002578513367151\n",
      "2.002320662030436\n",
      "2.0020885958273924\n",
      "2.001879736244653\n",
      "2.0016917626201876\n",
      "2.0015225863581687\n",
      "2.001370327722352\n",
      "2.001233294950117\n",
      "2.001109965455105\n",
      "2.000998968909595\n",
      "2.0008990720186355\n",
      "2.000809164816772\n",
      "2.0007282483350948\n",
      "2.0006554235015854\n",
      "2.000589881151427\n",
      "2.0005308930362844\n",
      "2.000477803732656\n",
      "2.0004300233593906\n",
      "2.0003870210234513\n",
      "2.000348318921106\n",
      "2.0003134870289956\n",
      "2.000282138326096\n",
      "2.000253924493486\n",
      "2.0002285320441375\n",
      "2.0002056788397238\n",
      "2.0001851109557514\n",
      "2.0001665998601763\n",
      "2.0001499398741585\n",
      "2.000134945886743\n",
      "2.0001214512980683\n",
      "2.0001093061682615\n",
      "2.000098375551435\n",
      "2.000088537996292\n",
      "2.000079684196663\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "y = 0.5 * ((x - 2) ** 2) + 2\n",
    "y_d = x - 2\n",
    "for i in range(100):\n",
    "    x = x - 0.1 * (x-2)\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cpu",
   "language": "python",
   "name": "pytorch-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
